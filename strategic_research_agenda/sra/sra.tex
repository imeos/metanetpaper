%                                     MMMMMMMMM
%
%  MMA    MM   MMMMMM  MMMMMMM   MM    MMMMMMMM   MMA   MM  MMMMMMM MMMMMMM
%  MMMA AMMM   MM        MM     MMMM              MMMM  MM  MM        MM
%  MM MMM MM   MMMMMM    MM    IM  MI   MMMMMMM   MM MMxMM  MMMMMM    MM
%  MM  M  MM   MM        MM   .MMMMMM.            MM  MMMM  MM        MM
%  MM     MM   MMMMMM    MM   MM    MM            MM   MMM  MMMMMMM   MM
%
%
%          - META-NET Strategic Research Agenda | English SRA -
% 
% ----------------------------------------------------------------------------

\documentclass[10pt, plain]{../../metanetpaper}

\usepackage{acronym}
\usepackage{rotating}

%!TEX TS-program = xelatex
\RequireXeTeX %Force XeTeX check

\input{sra_preamble}

\begin{document}

\maketitle

\cleardoublepage

\pagenumbering{roman}
\makefundingnotice

\cleardoublepage

% ----------------------------------------------------------------------------

\ssection*[What Europe says]{What Europe says}

% FIXME: Comment from Arle: The "WHAT EUROPE SAYS" section I find quite problematic. I laud the idea and understand the impulse to show that there is indeed wide support and that people think nice things about the SRA, but there are four pages of comments, most of which are rather uninspired quotes. I would expect that a single page, which obviously would not cover all the countries, but which contains substantive statements, would be more useful. As it is, if I hadn't been asked to read the statements, I would simply have skipped this section entirely, deeming it a bunch of fluff.

\textbf{Croatia:} ``Language technologies play a crucial role in showcasing the linguistic richness of Europe.'' --- Milena Žic Fuchs (Fellow of the Croatian Academy of Sciences and Arts, Chair of the Standing Committee for the Humanities of the European Science Foundation)

\medskip \textbf{Czech Republic:} ``META-NET brings a significant contribution to the technological support for languages of Europe and as such will play an indispensable role in the development of multilingual European culture and society.'' --- Ivan Wilhelm (Deputy Minister for Education, Youth and Sport)

\medskip \textbf{Denmark:} ``If we have the ambition to use the Danish language in the technological universe of the future, an effort must be made now to maintain and further develop the knowledge and expertise that we already have. Otherwise we run the risk that only people who are fluent in English will profit from the new generations of web, mobile and robot technology which are up and coming.'' --- Sabine Kirchmeier-Andersen (Director of the Danish Language Council)

% \medskip ``Given the right attention, the diversity of the European languages can enrich the cultural and commercial development in Europe.  However, if not properly addressed the linguistic diversity can be a serious threat to Europe’s global economic growth. The META-NET SRA makes way for essential discussions and initiatives. May it be read by many!'' --- Bo Vincents (CEO, Ankiro)

% \medskip ``A focus on language technology is one of the most important tools for preserving the linguistic diversity that is one of the core values of the EU. This is why META-NET is so important. After all, multilingualism in Europe contributes to exactly what the EU wishes to stand for: Democracy, equality and transparency. The increased focus on the development of language technology underpins these core values in a digital age. Communication between businesses, between organisations, and within the public sector across borders is highly dependent on language technology. There is also an indisputable democratic aspect to language technology in that it offers all inhabitants in the EU the opportunity to contribute economically, politically and socially to the European project, which affects all of our lives. Language technology will be essential to breaking down the linguistic and cultural barriers which are otherwise bound to develop.'' --- Sanne Hoffensetz Andresen (Ordbogen)

\medskip \textbf{Estonia:} ``If we do not implement the development plan for language technology or do not cooperate with other countries in the same direction, in the future Estonian will be marginalised in information society.'' --- Development Plan of the Estonian Language 2011--2017

\medskip \textbf{Finland:} ``Without languages we could not communicate. The META-NET network is a valuable support for a multilingual Europe.'' --- Alexander Stubb (Minister for European Affairs and Foreign Trade)

% \medskip ``The big issues are handled well. This is a good agenda!'' --- Niko Papula (Managing Director, Multilizer)

\medskip \textbf{France:} ``META-NET provides an invaluable contribution to the development of a genuine European strategy in support to multilingualism, based on existing technologies while encouraging the development of new innovative technologies.'' --- Xavier North (Délégué Général à la Langue Française et aux Langues de France)

% \medskip ``The SRA is a very important document!'' --- Max Silberztein (Université de Franche-Comté)

% \medskip ``I am very happy to have been able to read the [\dots] SRA.'' --- Antonio Balvet (Université Lille~3)

\medskip \textbf{Germany:} ``Europe's multilingualism and our scientific expertise are the perfect prerequisites for significantly advancing the challenge that language technology poses. META-NET opens up new opportunities for the development of ubiquitous multilingual technologies.'' --- Annette Schavan (Minister of Education and Research)

% \medskip ``Thanks to all of you for putting together such an impressive document!'' --- Miriam Butt (University of Konstanz)

% \medskip ``The [SRA] represents myself and also my area of research very well. I would like to thank you for all the hard work and effort you put into this!'' --- David Schlangen (University of Bielefeld)

% \medskip ``Thank you for the excellent SRA.'' --- Günther Roscher (ICS Dr.~G.~Roscher GmbH)

% \medskip ``META-NET have laid out a highly compelling vision of how Europe can bridge the digital and the analog, the computer and the human, thus strengthening the communication between us humans -- while preserving our cultural diversity. And not only do they have the vision; their SRA shows that clearly do they have the means, too. For us as a company building social media research tools for the knowledge workers of tomorrow, their research themes are bound to feed right into the success of our core products.'' --- Matthias Bärwolff (Tazaldoo)

% \medskip ``The SRA is a really good piece of work.'' --- Caterina Berbenni-Rehm (FUTUREtec)

\medskip ``Global communications are a significant success factor for a globally active company. Accordingly, their importance is steadily increasing with the increased globalisation and growing complexity of international business. In this context, the design of effective and efficient language management processes makes an important contribution. The development of language technologies already plays a decisive role today and will continue to do so in the future. META-NET makes a pivotal contribution in the area of reseach and maintenance of networks with developers and users of language technologies.'' ---
Johannes Bursch (Head of Corporate Language Management, Daimler AG)

\medskip \textbf{Greece:} ``Further support to language technologies safeguards the presence of Greek language and culture in the digital environment, while at the same time promoting development and fostering communication among citizens within the Information Society.'' --- George Babiniotis (Minister of Education, Lifelong Learning and Religious Affairs)

\medskip \textbf{Hungary:} ``META-NET is making a significant contribution to innovation, research and development in Europe and to an effective implementation of the European idea.'' --- Valéria Csépe (Deputy General Secretary of Hungarian Academy of Sciences)

% \medskip ``I am happy that such a paper and a common effort for research is planned in such a way and I [am] excited about this common effort.'' --- Attila Törcsvári (Arcanum Development)

\medskip \textbf{Iceland:} ``Language technology is an essential tool in a variety of linguistic research, and supports the official Icelandic policy of promoting the national language in all aspects of communication.'' --- Guðrún Kvaran (Chair of the Icelandic Language Council)

\medskip \textbf{Ireland:} ``Language technology is no longer a luxury for most European languages -- it is now essential to their survival as viable means of expression across the whole range of areas from business to the arts, and this is as much the case for Irish as any other European language.'' --- Ferdie Mac an Fhailigh (CEO, Foras na Gaeilge)

% \medskip \textbf{Israel:} ``Congratulations on the [\dots] SRA. This is an impressive document.'' --- Ilan Kernerman (CEO, K Dictionaries)

\medskip \textbf{Latvia:} ``For such small languages like Latvian keeping up with the ever increasing pace of time and technological development is crucial. The only way to ensure future existence of our language is to provide its users with equal opportunities as the users of larger languages enjoy. Therefore being on the forefront of modern technologies is our opportunity.'' --- Valdis Dombrovskis (Prime Minister of Latvia)

\medskip \textbf{Lithuania:} ``Conserving Lithuanian for future generations is a responsibility of the whole of the European Union. How we proceed with developing information technology will pretty much determine the future of the Lithuanian language.'' --- Andrius Kubilius (Prime Minister of the Republic of Lithuania)

% \medskip \textbf{Luxembourg:} ``This is a European challenge of enormous importance!'' --- Roman Jansen-Winkeln (CTO, Belingoo Media Group)

\medskip \textbf{Malta:} ``The technology support for the Maltese language should serve our language to be continuously cultivated, used and placed on the same level as other languages.'' --- Dolores Cristina (Minister for Education and Employment)

% \medskip ``The SRA is very stimulating, exhaustive and effective.'' --- Ray Fabri (National Council for the Maltese Language)

% \medskip \textbf{Netherlands:} 
``In the current vision of the European Union the citizen has become the focal point, namely the multilingual citizen. The Dutch Language Union does not just stand by and watch.  One can refer to the cooperation in the area of human language technology.'' --- Frank Vandenbroucke (Flemish Minister of Education and chair of the Committee of Ministers of the Dutch Language Union, 2004--2005)

% ``I like the vision described very much and the research priorities formulated.'' --- Alice Dijkstra (Nederlandse Organisatie voor Wetenschappelijk Onderzoek)

% \medskip ``There is a large increase in the number of applications and services that are supposed to make our lives easier. Most of them unfortunately do not speak Dutch. To sustain the position of the Dutch language, HLT research and development for Dutch needs continued support.'' --- Linde van den Bosch (General Secretary of the Dutch Language Union, 2004--2012)

% \medskip ``The SRA provides an interesting and stimulating outlook for the years ahead in a quickly evolving landscape.'' --- Marc Kemps-Snijders (Meertens Instituut)

\medskip \textbf{Poland:} ``Language technologies are more and more present in our everyday life. For their presence to be rational and functional, for it to serve the needs of the economy, as well as the social and cultural life well, further large-scale work in this area is needed.'' --- Michał Kleiber (President of the Polish Academy of Sciences)

\medskip \textbf{Portugal:} ``Language technology is of utmost importance for the consolidation of Portuguese as a language of global communication in the information society.'' --- Pedro Passos Coelho (Prime Minister of Portugal)

\medskip \textbf{Romania:} ``Linguistic technologies represent a central element of the EU, because languages themselves occupy a central place in the functioning of the EU.'' --- Leonard Orban (former European Commissioner for Multilingualism)

\medskip \textbf{Slovenia:} ``It is imperative that language technologies for Slovene are developed systematically if we want Slovene to flourish also in the future digital world.'' --- Danilo Türk (President of the Republic of Slovenia)

% \medskip \textbf{Spain:} ``I like the spirit of the agenda!'' --- Juanjo Bermudez (Founder, Lingua e-Solutions SL)

\medskip \textbf{Sweden:} ``High-quality language technology may be the most effective means of preserving the linguistic diversity of Europe. Being able to use all languages fully in modern society is a question of democracy. In this connection META-NET fulfils a central, even crucial, function.'' --- Lena Ekberg (Swedish Language Council)

% \medskip ``A joint Nordic challenge is the development of language technology for texting and reading subtitles. The Nordic countries are small language areas, and therefore the market is not driving the development of language technology by itself. However, the need for reading subtitles is large, because we in the Nordic countries have a tradition of subtitling foreign broadcasts instead of dubbing them, as in many other countries.'' --- Rickard Domeij (head of the Swedish Language Council)

% \medskip ``Thank you for authoring this text! The SRA will provide great support for many interesting and necessary research and development projects in the near future!'' --- Jussi Karlgren (CEO, Gavagai)

% \medskip ``The Priority Research Themes hit the bull's eye. Let's all hope for the best for the report.'' --- Jens Erik Rasmussen (New Business Manager, Mikro Værkstedet)

% \medskip ``Thank you for the work that went into compiling the SRA. It is impressive and clearly shows coverage of the LT area hot topics.'' --- Olga Caprotti (University of Gothenburg)

% \medskip \textbf{Turkey:} ``This agenda is excellent.'' --- Erhan Mengusoglu (Mantis Software)

\medskip \textbf{UK:} ``The work of META-NET is an important step towards a future in which Language Technology will be all around us, allowing us to collaborate, conduct business and share knowledge with friends and colleagues, whether or not we speak the same language.'' --- David Willets (Minister of State for Universities and Science, Department for Business, Innovation and Skills)

\medskip \textbf{European Commission:} ``Having worked on automatic media analysis for many years and in tens of languages, we are painfully aware of the lack of text analysis tools and resources in most languages. META-NET's analysis is very accurate. Language Technology is a key enabling ingredient for future generations of IT. Languages for which no tools and resources will exist soon will not participate in the next major technological developments.'' --- Ralf Steinberger (Joint Research Centre, 
IPSC -- GlobeSec -- Open-Source Text Information Mining and Analysis, Ispra, Italy)

\smallskip \centerline{\small See \url{http://www.meta-net.eu/whitepapers/all-quotes-and-testimonials} for additional quotes and testimonials.}

~

\vfill

\centerline{\normalsize\fbox{\parbox{\dimexpr 0.85\linewidth - 2\fboxrule - 2\fboxsep}{``The Commission will [\dots] work with stakeholders to develop a new generation of web-based applications and services, including for multilingual content and services, by supporting standards and open platforms through EU-funded programmes.'' -- \emph{A Digital Agenda for Europe} \cite{DA2010}, p.~24}}}

\bigskip
\centerline{\normalsize\fbox{\parbox{\dimexpr 0.85\linewidth - 2\fboxrule - 2\fboxsep}{``Everybody must have the chance to communicate efficiently in the enlarged EU. This does not only affect those who already are multilingual but also those who are monolingual or linguistically less skilled.\newline
%
The media, new technologies and human and automatic translation services can bring the increasing variety of languages and cultures in the EU closer to citizens and provide the means to cross language barriers. They can also play an important role to reduce those barriers and allow citizens, companies and national administrations to exploit the opportunities of the single market and the globalising economy.\newline
%
Faced with the globalising online economy and ever-increasing information in all imaginable languages, it is important that citizens access and use information and services across national and language barriers, through the internet and mobile devices. Information and communication technologies (ICT) need to be language-aware and promote content creation in multiple languages.'' -- \emph{Multilingualism: An Asset for Europe and a Shared Commitment} \cite{EC2}, p.~12\,f.}}}

\bigskip
\centerline{\normalsize\fbox{\parbox{\dimexpr 0.85\linewidth - 2\fboxrule - 2\fboxsep}{``The Council of the European Union [\dots] encourage[s] the development of language technologies, in particular in the field of translation and interpretation, firstly by promoting cooperation between the Commission, the Member States, local authorities, research bodies and industry, and secondly by ensuring convergence between research programmes, the identification of areas of application and the deployment of the technologies across all EU languages.'' -- \emph{Council Resolution of 21 November 2008 on a European strategy for multilingualism} \cite{ecouncil2008}}}}

\bigskip
\centerline{\normalsize\fbox{\parbox{\dimexpr 0.85\linewidth - 2\fboxrule - 2\fboxsep}{``The language of Europe is translation.'' -- Umberto Eco (1993)}}}

\vfill

~

\clearpage

% ----------------------------------------------------------------------------

\ssection*{Table of Contents}

\renewcommand\contentsname{}
\tableofcontents

\addtocontents{toc}{\protect\thispagestyle{empty}\protect}
\addtocontents{toc}{{\protect\vspace*{-20mm}\protect}}

\cleardoublepage

% --------------------------------------------------------------------------
% --------------------------------------------------------------------------
% --------------------------------------------------------------------------
% Content begins here.
% --------------------------------------------------------------------------
% --------------------------------------------------------------------------
% --------------------------------------------------------------------------

\setcounter{page}{1}
\pagenumbering{arabic} 
\pagestyle{scrheadings}

% FIXME: Comment from RC: "the final version must include a punchy executive summary, possibly co-signed by prominent figures in the field; a long list of organisations (private and public, especially private!) contributing/commenting/endorsing the SRA; (tabular) elements of the implementation roadmaps (I guess 1 per priority theme): chart, phases of work, intended intermediate and final deadlines with major outputs/spinoffs, likely size/scale of effort."

% --------------------------------------------------------------------------

\ssection*[Key Messages]{Key Messages}
\phantomsection
\addcontentsline{toc}{section}{\protect\hspace*{5.7mm}Key Messages}

% FIXME: Story ok? Subsections ok? Any important points missing?

\begin{multicols}{2}
  \begin{itemize}
  \item[] \textbf{Europe and its Languages}
  \item Europe is and will remain a multilingual, integrative and inclusive society. Geographical Europe has more than 80 languages, including the EU's 23 official and minority as well as immigrant languages.
  \item Our language diversity is a value and opportunity.
  % The EU has 23 official languages and geographical Europe has more than 60 languages. Minority and immigrant languages push the number well beyond 80.
  % \item Europe has been very successful in tearing down barriers, both political and financial. The last remaining barriers are those of language.
  \item Language is a business issue and enabler for economic, political, and humanitarian activities.
  \item Our many languages are hindering the free flow of information, goods, discussion, and innovation.
  \medskip

  \item[] \textbf{Europe and Language Technology}
  \item Language barriers are a severe problem and must be torn down for economic, political, societal reasons.
  \item Language technology can help solve this problem.
  \item European research has a tradition of excellence in language technology.
  \item While good technologies exist for English, the other European languages are seriously under-supported.
  \medskip

  \item[] \textbf{Overcoming Language Barriers}
  \item If the European community makes a dedicated push, we can get rid of many language barriers by 2020.
  \item The modest investment required will deliver tremendous benefits in many business and social domains.
  \item The single digital market will become a reality.
  \item Europeans will be able to communicate with one another through technology (both spoken and written).
  % \item Technologies will enable Europeans to discuss important questions at the European level instead of in the confines of their respective language communities.
%\columnbreak
  \medskip

  \item[] \textbf{META-NET's Recommendations}
  \item The EU/EC should start a shared, transnational research programme.
  % \item We suggest a shared programme between the EU, member states and associated countries.
  \item We suggest three priority research themes: \emph{Translingual Cloud}; \emph{Social Intelligence and e-Participation}; \emph{Socially Aware Interactive Assistants}.
  \item Our technologies will be a quantum leap for the development of the EU, Europe and the whole planet.
  % \item Our technologies will be available in the cloud through a multilingual service ecosystem.
  \item Our technologies will revolutionise communication over mobile devices. They will enable us to analyse and make efficient use of social media and to transform text into knowledge. They will enable us to interact with machines through spoken language. They are a prerequisite for handling, exploiting and analysing Open Data, Big Data and the Semantic Web.
  \item Language is \emph{the} common denominator of digital technologies and communication. If we as Europeans decide not to bring about the situation in which \emph{our} languages are supported through \emph{our} technologies (including a plethora of research and business opportunities), \emph{others} will -- at inferior quality, higher total costs and added risks. Can Europe afford a technology lock-in in this crucial infrastructure?
  \end{itemize}
\end{multicols}

\begin{itemize}
\item[] \textbf{About META-NET}
\vspace*{-3mm}
\end{itemize}
\begin{multicols}{2}
  \begin{itemize}
  \item META-NET is a network of excellence consisting of 60 research centres in 34 countries. Our open technology alliance META has more than 650 members.
  \item META-NET cooperates with many companies, research organisations, European projects, language communities and industry associations.
  \end{itemize}
\end{multicols}

\cleardoublepage

% --------------------------------------------------------------------------

\ssection*[Executive Summary]{Executive Summary}
\phantomsection
\addcontentsline{toc}{section}{\protect\hspace*{5.7mm}Executive Summary}
\addtocontents{toc}{\protect\medskip}

\begin{multicols}{2}
The unique multilingual setup of our European society imposes grand societal challenges in political, economic and social integration and inclusion, especially in the creation of the single digital market and unified information space targeted by the Digital Agenda \cite{DA2010}.

As many as 21 European languages face digital extinction \cite{LWP2012}. They run the risk of becoming victims of the digital age as they are under-represented online and under-resourced with respect to language technologies. Also, huge market opportunities remain untapped because of language barriers \cite{EC3, EC6}. If no action is taken, many European citizens will find that speaking their mother tongue is a social and economic disadvantage. Future-proofing our languages requires a modest investment which will turn into a strong competitive advantage, since the technologies needed to overcome language barriers and support languages in the digital age are key enabling technologies for the next revolution in IT. 

Language technology is the missing piece of the puzzle towards the single digital market. Almost every digital product uses and is dependent on language -- this is why language technology is not optional. It is the key enabler and solution to boosting Europe's future growth and to strengthen our competitiveness in a field that is getting more and more important. The key question is: will Europe decide to participate in this future market? 

% Maybe cut this out? >>>>>
Although we use computers to write, phones to chat and the web to search for knowledge, IT does not have access to the meaning, purpose and sentiment behind our trillions of written and spoken words. Language technology will bridge this rift that separates IT and the human mind through sophisticated technologies for understanding. 
% <<<<<
Recent language technology innovations such as Google’s web search, Autonomy’s text analytics, Nuance’s speech tools, online translation services, IBM Watson’s question answering and Apple's Siri have given us but a first glimpse of the massive potential behind this emerging key technology. Today’s computers cannot understand texts and questions well enough to provide translations, summaries or reliable answers, but in less than ten years such services will be offered for many languages. Technological mastery of human language will enable a host of innovative IT products and services in commerce, administration, government, education, health care, entertainment, tourism and other sectors.

Europe is the most appropriate place for arriving at the fundamental and applied research and technology breakthroughs needed. Our continent has half a billion citizens speaking more than 60 European languages and many non-European ones as their mother tongue \cite{eurobarometer2012}. Europe has more than 2,500 small and medium sized enterprises in language, knowledge and interface technologies, and more than 5,000 enterprises providing language services that can be improved and extended by technology. It also has a longstanding research tradition with more than 800 centres of scientific and technological research on all European and many non-European languages. 

Europe's Language Technology community is dedicated to fulfilling the requirements of our multilingual society and turning the needs and business opportunities into competitive advantages for our economy. Recognising Europe’s exceptional demands and opportunities, 60 leading IT research centres in 34 European countries joined forces in META-NET, a European Network of Excellence (supported through a total of four EU/EC-funded projects) dedicated to the technological foundations of the multilingual, inclusive, innovative and reflective European society.

META-NET assembled the Multilingual Europe Technology Alliance (META) with more than 650 organisations and experts representing stakeholders such as research, industries that provide or use language technologies, professional associations, public administrations and language communities. Working together with numerous additional stakeholder organisations and experts from a variety of fields, META/META-NET has developed this Strategic Research Agenda (SRA). Our recommendations for Multilingual Europe 2020, as specified in this document, are based on a thorough planning process involving more than one thousand experts. 

The META Technology Council predicts, in line with many other forecasts, that the next generation of IT will be able to deal with human language, knowledge and emotion in competent and meaningful ways (see Chapter~\ref{sec:lt2020}). These new competencies will enable an endless stream of novel services that will improve communication and understanding. 
% Maybe cut this out? >>>>>
Many services will help people to learn and understand the world including history, technology, economy and nature. Others will help us to better understand each other across language and knowledge boundaries. They will also enable many other services including programmes for commerce, localisation, personal assistance, and enable robots to understand what their users want and need.
% <<<<<

We want to provide monolingual, crosslingual and multilingual technology support for all languages spoken in Europe. To this end, we recommend to focus on a small set of selected priority research themes that are tightly coupled to novel application scenarios that will enable European research and development in this field to compete with other markets and will bring about multiple benefits for the European society and citizen as well as a multitude of opportunities for our economy and future growth. We are confident that upcoming funding programmes, specifically Horizon 2020 \cite{H2020} and Connecting Europe Facility \cite{CEF2011}, combined with national and regional funding, can provide the necessary resources to realise our joint vision.

A recent policy brief \cite{bruegel12} recommends that Europe specialises in new ICT sectors and firms as a means for post-crisis recovery. According to the analysis, the problem in Europe appears not to be so much in the generation of new ideas, but rather in bringing ideas successfully to market. Among the main barriers are the lack of a single digital market and an absence of ICT clusters. Veugelers suggests that the EU policy framework, particularly the Innovation Union and the Digital Agenda, should better leverage the growth power of new ICT markets. This is exactly the goal we are trying to achieve with this SRA.

Our recommendations foresee five action lines for large-scale research and innovation (Chapter~\ref{sec:pts}):

\begin{itemize}
\item \textbf{Three Priority Research Themes} along with powerful application scenarios to drive research and innovation. These will demonstrate novel technologies in show-case solutions with high economic and societal impact. They will open up numerous new business opportunities for European companies.
\begin{enumerate}
\item \textbf{Translingual Cloud}: generic and specialised federated cloud services for reliable spoken and written translation among all European and major non-European languages.
\item \textbf{Social Intelligence and e-Participation}: understanding and dialogue within and across communities of citizens, customers, clients and consumers to enable e-participation and more effective processes for preparing, selecting and evaluating collective decisions.
\item \textbf{Socially Aware Interactive Assistants}: socially aware pervasive assistants that learn and adapt and that provide proactive and interactive support tailored to specific situations, locations and goals of the user through verbal and non-verbal multimodal communication.
\end{enumerate}
\item \textbf{Core technologies and resources for Europe's languages}: a system of shared, collectively maintained, interoperable tools and resources. They will ensure that our languages will be sufficiently supported and represented in the next generations of IT solutions.
\item \textbf{European language technology platform} for supporting research and innovation by testing and showcasing results, integrating research and operational services including professional human services. This e-infrastructure will allow providers from research and industry to offer components and services. 
\end{itemize}

The priority research themes have been designed with the aim of turning our joint vision into reality and letting Europe benefit from a technological revolution that will overcome barriers of understanding between people of different languages, between people and technology, and between people and the knowledge of mankind. The themes connect societal needs with LT applications and concrete roadmaps for the organisation of research, development and scientific innovation. They cover the main functions of language: storing, sharing and using information and knowledge; improving social interaction among humans; enabling social interaction between humans and technology. As multilingualism is at the core of European culture and becoming a global norm, one theme is devoted to overcoming language barriers.

The SRA recommends ways in which research and innovation need to be organised in order to achieve the targeted research breakthroughs and to benefit from the immense economic opportunities \cite{bruegel12} they create. Core components of the strategy are novel modes of large-scale collective research and interaction among the major stakeholder constituencies: researchers in several disciplines, technology providers, technology users, policy makers and language communities.

% Maybe cut this out? >>>>>
Of central importance is a rapid and effectual flow of intermediate results into solutions of societal and economic impact contributing to the fertile culture of technological, social and cultural innovation targeted by the Digital Agenda \cite{DA2010} as well as the programmes Horizon 2020 and Connecting Europe Facility (CEF).
% <<<<<
\end{multicols}

\cleardoublepage

% --------------------------------------------------------------------------

\ssection[Introduction]{Introduction}

% FIXME (Arle): I think the INTRODUCTION goes into too much detail about funding frameworks and so forth and is too long. I've tried to streamline a version but cutting about 25% of the text (I think it needs more, actually) and removing the graphic, which isn't really crucial. I have also added internal headers to try to make it more accessible. I would strongly recommend trying to cut it to two punchy pages with less detail even than what it now has. If someone wants that level of detail, they will read the body, but I'm afraid it is easy to get lost in the intro as it now stands.

\begin{multicols}{2}
During the last 60 years, Europe has become a distinct political and economic structure. Culturally and linguistically it is rich and diverse. However, from Portuguese to Polish and Italian to Icelandic, everyday communication between Europe's citizens, enterprises and politicians is inevitably confronted with language barriers. They are an invisible and increasingly problematic threat to economic growth as several recent studies have shown \cite{economist12}.

The EU's institutions spend about \emph{one billion Euros per year} on translation and interpretation to maintain their policy of multilingualism \cite{EC7} and the overall European market for translation, interpretation, software localisation and website globalisation was estimated at 5.7 billion Euros in 2008. Are these expenses necessary? Are they even sufficient? Despite this high level of expenditure, only a fraction of the information is translated that is available to the whole population in countries with a single predominant language, such as the USA or China.

Language technology and linguistic research, as well as related fields such as the digital humanities, social sciences and psychology, can significantly contribute to overcoming linguistic barriers. Combined with intelligent devices and applications, a European language technology platform will help European citizens to talk and do business together even if they do not speak a mutual language.

The economy benefits from the European single market. But language barriers can bring business to a halt, especially for SMEs who do not have the financial means to compete on a European or global level. The only (unacceptable) alternative to a multilingual Europe \cite{lre2011} would be to allow a single language to take a predominant position and replace all other languages in transnational communication. Another way to overcome language barriers is to learn foreign languages, an area in which language technologies can play a key role.

Given the 23 official EU languages plus 60 or more other languages spoken in Europe \cite{eurobarometer2012}, language learning on its own cannot solve the problem of cross-border communication or commerce \cite{economist12}. Without technological support such as machine translation, our linguistic diversity will be an insurmountable obstacle for the entire continent. Only about half of the 500 million people who live in the European Union speak English! It is evident that there is no such thing as a lingua franca shared by the vast majority of the population of our continent.

Less than 10\% of the EU's population are willing or able to use online services in English which is why multilingual services based on language technologies are badly needed to support and to move the EU online market from more than 20 language-specific sub-markets to a unified single digital market with more than 500 million users and consumers. The main goal, foreseen in the Digital Agenda EU policy framework \cite{DA2010}, is to build a single digital market in which content and services can flow freely. In order to support cross-border exchanges between users, consumers, countries and regions \cite{economist12}, robust and high-quality cross- and multilingual language technologies need to be developed urgently. In fact, the current situation with ``many fragmented markets'' is considered one of the main obstacles that seriously undermine Europe's efforts to exploit ICT fully \cite{DA2010}! A truly functioning single digital market can only be established once the language barrier has fallen, something that can be achieved only through research, development and wide deployment of language technologies (see Figure~\ref{fig:single-digital-market}). The single digital market functions poorly because multilingual Europe itself functions poorly.

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.8\textwidth]{../_media/single-digital-market}
  \caption{Language Technology unlocks the Single Digital Market}
  \label{fig:single-digital-market}
\end{figure*}

Language technology is a key enabler for sustainable, cost-effective and socially beneficial solutions to overcome language barriers. It will offer European stakeholders tremendous advantages, not only within the European market, but also in trade relations with non-European countries, especially emerging economies. One prerequisite to develop these solutions was a systematic survey of the linguistic particularities of all European languages and the current state of language technology support for them. With the publication of the META-NET White Paper Series ``Europe's Languages in the Digital Age'' \cite{LWP2012} this important step has now been taken (see also Chapter~\ref{sec:lwp}, p.~\pageref{sec:lwp}\,ff., and Appendix~\ref{vision-evolution}, p.~\pageref{vision-evolution} for an overview of the timeline and history of this document).

There are two main axes around which language technologies are needed and able to bring about the next IT revolution: \emph{communication} and \emph{data analysis}. Communication includes support for activities such as talking, conversing, carrying out dialogues and debates (both spoken and written), authoring and further processing (summarising, categorising etc.) of texts ranging from instant messages to complex documents, and also translation. Data analysis includes organising, structuring and understanding data, extracting information and relations between entities. The term data here refers to arbitrary types of unstructured data as well as any type of text. In the medium-to-long term we want to realise technologies for socially-aware and context-aware natural language understanding and generation, including translation.

In the late 1970s the EU realised the profound relevance of language technology as a driver of European unity and began funding its first research projects, such as EUROTRA. After a longer period of sparse funding \cite{laz1,euromap}, the European Commission set up a department dedicated to language technology and machine translation a few years ago; in an internal reorganisation this department was recently integrated into a new unit called ``Data Value Chain'', part of Directorate G, ``Media \& Data'', in the EC Directorate General for ``Communications Networks, Content and Technology'' (DG Connect). In the past ca.~five years, the EU has been supporting projects such as EuroMatrix and EuroMatrix+ (since 2006) and iTranslate4 (since 2010), which use basic and applied research to generate resources for establishing high-quality solutions for all European languages.

These selective funding efforts have led to a number of valuable results. For example, the EC's translation services now use the Moses open source machine translation software, which has been mainly developed in European research projects. However, these projects never led to a concerted European effort through which the EU and its member states systematically pursue the common goal of providing technology support for all European languages. Figure~\ref{fig:languages-in-research} depicts the languages that have been studied by Language Technology researchers in 2010, taking into account major conferences and journals. It illustrates how research has focussed primarily on English followed by Chinese, German, French, and a few other bigger languages. Many European languages were not studied at all, e.\,g., Slovak, Maltese, Lithuanian, Irish, Albanian, Croatian, Macedonian, Montenegrin, Romansh, Galician, Occitan, or Frisian.

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.71\textwidth]{../_media/Languages-in-LT-Research}
  \caption{Languages treated in research published in the 2010 edition of the Journal of Computational Linguistics and the conferences of ACL, EMNLP and COLING (internal, unpublished study)}
  \label{fig:languages-in-research}
\end{figure*}

Research activities have tended to be isolated and while they have delivered valuable results, they have had difficulty making a decisive impact on the market. In many cases research funded in Europe eventually bore fruit outside Europe; enterprises such as Google and Apple have been noteworthy beneficiaries. In fact, many of the predominant actors in the field today are based in the US.

%%%%%%%
%
% This bit commented out as suggested by Volker Steinbiss et al.
%
%Statistical methods have been succesful, scaling to many languages and application domains but in many cases reached a performance plateau and inclusion of and combination with deep linguistic methods and insights is seen as a promising a way forward.
%
%In the pure statistical approach, sentences are automatically translated by comparing each new sentence against thousands of sentences previously translated by humans; the quality of the output largely depends on the size and quality of the available data. While the automatic translation of simple sentences in languages with sufficient amounts of available textual data can achieve useful results, statistical methods are likely to fail in the case of languages with a much smaller body of sample data or in the case of new sentences with complex structures. Analysing the deeper structural properties of languages is a promising avenue if we want to build applications that perform well across the entire range of European languages.
%
%%%%%%%

Europe now has a well-developed research base. Through initiatives such as CLARIN and META-NET the research community is well connected and engaged in a long term agenda that aims gradually to strengthen language technology's role. At the same time, our position is worse when compared to other multilingual societies. Despite having fewer financial resources, countries like India (22 official languages) and South Africa (11 official languages) have set up long-term national programmes for language research and technology development. What is missing in Europe is awareness, political determination and political will that would take us to a leading position in this technology area through a concerted funding effort. This major dedicated push needs to include the political determination to modify and to adopt a shared, EU-wide language policy that foresees an important role for language technologies. 

Drawing on the insights gained so far, today’s hybrid language technology mixing deep processing with statistical methods could be able to bridge the gap between all European languages and beyond. In the end, high-quality language technology will be a must for all of Europe's languages for supporting the political and economic unity through cultural diversity. Language technology can help tear down existing barriers and build bridges between Europe’s languages. In the digital age, communication with people and machines, as well as the unrestricted access to the knowledge of the world should be possible for all languages. The European LT community is dedicated to fulfilling the technology demands of the multilingual European society and to turn these needs and emerging business opportunities into competitive advantages. To this end, we have developed this Strategic Research Agenda (see Appendix~\ref{vision-evolution}, p.~\pageref{vision-evolution}).

In the first chapters we analyse the multilingual technology needs arising from the multicultural setup of our continent with its emerging single digital market. We also discuss the current state of technologies for European languages. The two core chapters of this document summarise our shared vision of the role of language technology in the year 2020 in non-technical terms (Chapter~\ref{sec:lt2020}, p.~\pageref{sec:lt2020}\,ff.) and outline three priority themes for large-scale research and innovation (Chapter~\ref{sec:pts}, p.~\pageref{sec:pts}\,ff.):

\begin{enumerate}
\item \textbf{Translingual Cloud} -- Services for instantaneous reliable spoken and written translation among all European and major non-European languages
\item \textbf{Social Intelligence and e-Participation} -- understanding and dialogue within and across communities of citizens, customers, clients, consumers
\item \textbf{Socially Aware Interactive Assistants} -- analysis and synthesis of non-verbal, speech and semantic signals
\end{enumerate}
 
These thematic directions have been designed with the aim of turning our joint vision into reality and to letting Europe benefit from a technological revolution that will overcome barriers of understanding between people of different languages, between people and technology and between people and the accumulated knowledge of mankind. The themes build the bridge between societal needs, applications, and roadmaps for the organisation of research, development and scientific innovation. They cover the main functions of language: storing, sharing and using information and knowledge, as well as improving social interaction among humans and enabling social interaction between humans and technology.

We also present ways in which research and innovation need to be organised in order to achieve the targeted breakthroughs and to benefit from the immense economic opportunities they create. Core components of the sketched strategy are novel modes of large-scale collective research and interaction among the major stakeholder constituencies including research in several disciplines, technology providers, technology users, policy makers and language communities. Effective schemes for sharing resources such as data, computational language models and generic base technologies are also an integral part of our strategy. Of central importance is a rapid flow of intermediate results into commercially viable solutions of societal impact contributing to the fertile culture of technological, social and cultural innovation targeted by the Digital Agenda \cite{DA2010} and the programmes Connecting Europe Facility (CEF) \cite{CEF2011} and Horizon 2020 \cite{H2020}.

The three priority research themes are mainly aimed at Horizon 2020 (2014--2020). The more infrastructural aspects, platform design and implementation and concrete language technology services are aimed at CEF. Our suggestion for integrating multilingual technologies into the wider CEF framework is to develop innovative solutions that enable providers of online services to offer their content and services in as many EU languages as possible, in a most cost effective way. These are to include public services, commercial services and user-generated content. An integral component of our strategic plans are the member states and associated countries: it is of utmost importance to set up, under the overall umbrella of our SRA and priority research themes, a coordinated initiative both on the national (member states, regions, associated countries) and international level (EC/EU), including research centres as well as small, medium and large enterprises who work on or with language technologies. Only through an agreement and update of our national and international language policy frameworks, close cooperation between all stakeholders, and tightly coordinated collaboration can we realise the ambituous plan of researching, designing, developing and putting into practice a European platform \cite{bruegel12} that supports all citizens of Europe, and beyond, by providing, among others, sophisticated services for communication across language barriers.  
\end{multicols}

\clearpage

% --------------------------------------------------------------------------

\ssection[Multilingual Europe: Facts, Challenges, Opportunities]{Multilingual Europe:\newline Facts, Challenges, Opportunities}

\begin{multicols}{2}

\subsection{Europe's Languages in the Networked Society}
\label{sec:status-europes-languages}

Europe’s more than 80 languages are one of its richest and most important cultural assets, and a vital part of its unique social model \cite{EC2,eurobarometer2012}. While languages such as English and Spanish are likely to thrive in the emerging digital marketplace, many European languages could become marginal in a networked society. This would weaken Europe’s global standing, and run counter to the goal of ensuring equal participation for every European citizen regardless of language. A recent UNESCO report on multilingualism states that languages are an essential medium for the enjoyment of fundamental rights, such as political expression, education and participation in society \cite{Unesco1,maaya2012,ifa2008,ifa2011}. From the very beginning, Europe had decided to keep its cultural and linguistic richness and diversity alive during the process of becoming an economic and political union. For maintaining the policy of multilingualism, the EU’s institutions spend about one billion Euros a year on translating texts and interpreting spoken communication. For all European economies the translation costs for compliance with the laws and regulations are much higher.

A single European market that secures wealth and social well-being is possible, but linguistic barriers still severely limit the free flow of goods, information, services, debates and innovation. With the increased number of EU members and the general trend towards timely trans-border interaction, everyday communication between Europe’s citizens, within business and among politicians is more and more becoming confronted with language barriers. Many Europeans find it difficult to interact with online services and participate in the digital economy. According to a recent study, 57\% of internet users in Europe purchase goods and services in languages that are not their native language (English is the most common foreign language followed by French, German and Spanish). 55\% of users read content in a foreign language while only 35\% use another language to write e-mails or post comments on the web \cite{EC1}. A few years ago, English might have been the lingua franca of the web -- the vast majority of content on the web was in English -- but the situation has now drastically changed. The amount of online content in other European as well as Asian and Middle Eastern languages has exploded \cite{Ford11}. Already today, more than 55\% of web-based content is not in English. One language is especially becoming more and more dominant: a recent study by the UN Broadband Commission reports that Chinese internet users will overtake English language users by 2015 \cite{chinese2012}.

Figure~\ref{fig:european-languages-in-twitter} shows the European language communities of Twitter: the map was created by identifying automatically the languages millions of tweets are written in and placing them onto a map using their GPS-coordinates \cite{fisher11}. To a large degree the resulting map replicates Europe's language borders -- and barriers.

% Figure removed, it doesn't add anything. Suggestion by Peter Spyns.
% 
%\begin{figure*}[htb]
%  \colorrule{grey3}{\textwidth}{1.5pt}
%  \center
%  \includegraphics[width=0.9\textwidth]{../_media/Language-Graph}
%  \caption{Language graph of the web}
%  \label{fig:language-graph-of-the-web}
%  \colorrule{grey3}{\textwidth}{1.5pt}
%\end{figure*}

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.9\textwidth]{../_media/twitter-languages-europe}
  \caption{Language communities of Twitter (European detail) \cite{fisher11}}
  \label{fig:european-languages-in-twitter}
\end{figure*}

Surprisingly, this ubiquitous digital divide due to language borders and language barriers has not gained much public attention up until our recent press campaign in which we informed the public about the findings of our META-NET study ``Europe's Languages in the Digital Age'' (see Chapter~\ref{sec:lwp}, p.~\pageref{sec:lwp}\,ff.). In this study, published in our META-NET White Paper Series \cite{LWP2012}, more than 200 experts from all over Europe found that at least 21 of the 30 languages examined are in serious danger of facing digital extinction. A pressing question raises: which European languages will thrive in the networked information society, and which are doomed to disappear?

The European market for translation, interpretation and localisation was estimated to be 5.7 billion Euros in 2008. The subtitling and dubbing sector was at 633 million Euros, language teaching at 1.6 billion Euros. The overall value of the European language industry was estimated at 8.4 billion Euros and expected to grow by 10\% per year, i.\,e., resulting in ca.~16.5 billion Euros in 2015 \cite{EC3}. (The global speech technology market is even bigger, it will reach ca.~20.9 billion US-Dollars by 2015 and ca.~31.3 billion US-Dollars by 2017 \cite{gia2012}.) Yet, this existing capacity is not enough to satisfy current and future needs, e.\,g., with regard to translation \cite{csa2009}. Already today, Google Translate translates the same volume per day that all human translators on the planet translate in one year \cite{och12}.

Despite recent improvements, the quality, usability and integration of machine translation into other online services is far from what is needed. If we rely on existing technologies, automated translation and the ability to process a variety of content in a variety of languages -- a key requirement for the future internet -- will be impossible. The same applies to information services, document services, media industries, digital archives and language teaching. There is an urgent need for innovative technologies that help save costs while offering faster and better language services to the European citizen.

The most compelling solution for ensuring the breadth and depth of language usage in tomorrow's Europe is to use appropriate technology. Still, despite recent improvements, the quality and usability of current technologies is far from what is needed. The META-NET study mentioned above shows that, already today, especially the smaller European languages suffer severely from under-representation in the digital realm. There are tremendous deficits in technology support and significant research gaps for all languages. For example, machine translation support for 23 out of the studied 30 languages was evaluated as having very limited quality and performance, which is an alarming result!

Another important aspect related to the European discourse. Especially the one on innovation has become determined by the English language, and the media reporting in that language. As Mark Vanderbeeken, a Belgian who lives in Italy noted in a widely read essay \cite{vanderbeeken2012}, this sheer dominance of English carries with it an accompanying perspective of Europe, both in terms of stereotypes and in terms of relevance to the Anglo-Saxon world. This puts European businesses and countries at a serious disadvantage that they are not even aware of. It also disadvantages businesses in the English-speaking world, which are perhaps not aware that they are receiving an abbreviated picture of innovation in Europe. Vanderbeeken calls this phenomenon ``the non-English disadvantage''. It is another example of a disadvantage which can be successfully addressed through multilingual technologies.

\subsection{How can Language Technology help?}
\label{sec:how-can-language-technology-help}

One way to overcome language barriers is to learn foreign languages. Yet without technological support, mastering the EU's 23 official languages and some 60 other European languages is an insurmountable obstacle for Europe’s citizens, economy, scientific progress, and political debate \cite{ombudsman2012}. The solution is to build key enabling technologies: language technologies will offer all European stakeholders tremendous advantages and benefits, not only in the single market, but also in trade relations with non-European countries.

Language technology is also a key enabler for the knowledge society. It supports humans in everyday tasks, such as writing e-mails, searching for information online or booking a flight. It is often used behind the scenes of other software applications. We benefit when we use spelling checkers, browse recommendations in an online shop, hear the spoken instructions of a navigation system or translate web pages with an online service.

Several popular language technology services are provided by US companies, some of them free of charge. The recent success of Watson, an IBM computer system that won against human candidates in the game show Jeopardy, illustrates the immense potential. As Europeans, we urgently have to ask ourselves a few crucial questions:

\begin{itemize}
\item Can we afford our information, communication and knowledge infrastructure to be highly dependent upon monopolistic services provided by US companies (technological lock-in)?
\item What is Europe's fallback plan in case the language-related services provided by US companies that we rely upon are suddenly switched off or if serious access or security issues arise?
\item Are we actively making an effort to compete in the global landscape for research and development in language technology?
\item Can we expect third parties from other continents to solve our translation and knowledge management problems in a way that suits our specific communicative, societal and cultural needs?
\item Can the European cultural background help shape the knowledge society by offering better, more secure, more precise, more innovative and more robust high-quality language technology?
\end{itemize}

We believe that \emph{Language Technology made in Europe for Europe} will significantly contribute to future European cross-border and cross-language communication, economic growth \cite{economist12} and social stability while establishing for Europe a worldwide, leading position in technology innovation, securing Europe's future as a world-wide trader and exporter of goods, services and information.

\subsection{Societal Challenges}
\label{sec:what-soci-challenges}

Information technology is bringing people speaking different languages together in new ways. Highly popular social networks and social media such as Wikipedia, Facebook, Twitter, YouTube, Google+, Pinterest, and Instagram are only the tip of the iceberg.

Many societal changes and economic as well as technological trends confirm the urgent need to include sophisticated language technology in our European ICT infrastructure. Research, development and innovation efforts in LT must increase to go beyond what is possible today.

\textbf{Language Barriers.} A study on online commerce shows that language barriers are economic barriers \cite{EC4}. Only 59\% of retailers can handle transactions in more than one language. Translation and localisation costs must be drastically lowered before Europe’s single digital market is a reality. Multilingual language technology is the key, especially for SMEs. At the same time, 81\% of all internet users think that websites run in their country should also be available in other languages. 44\% of European users think they miss out on interesting information because websites are not available in a language they understand \cite{EC1}. These facts can no longer be ignored. Reliable LT can help establish a vast market for information as well as consumer and entertainment goods in any language.

\textbf{Ageing Population.} Demographic changes bring about a need for more assistive technologies, especially for spoken language access. An ageing population requires technology that can help master everyday situations, provide proactive guidance and that could answer the question, “Where did I leave my glasses?” Also, more health care services and support systems will be required. Ambient assisted living (AAL) technologies can greatly benefit from a personalised, spoken method of interaction.

\textbf{People with Disabilities.} New technologies can help us reach the ambitious goal of achieving equal opportunities and promoting independent living. Language technologies already help people with disabilities to participate in society. Noteworthy examples include screen readers, dictation systems and voice-activated services. In addition to the social aspect there is a huge commercial market for future technologies such as, for example, full dialogue systems and interactive assistants, sign language recognition and synthesis, automatic translation, summarisation and content simplification. Approximately 10\% of Europeans (50 million citizens) have permanent disabilities.

\textbf{Immigration and Integration.} According to the United Nations' International Migration Report 2002, 56 million migrants lived in Europe in 2000 \cite{UN1}. This number has grown to ca.~60 million people today. Facilitating communication, providing access to information in foreign languages and helping people learn European languages can help better integrate migrants into European society. In fact, speech and language technologies can dramatically improve the integration process by providing intelligent language learning environments, automatic subtitling and translation services in real time.

\textbf{Personal Information Services and Customer Care.} In our 24/7 ``always on'' economy we expect quick and reliable answers as well as engaging and timely online news broadcasts. However, information overload still poses a serious problem. Citizens, governments and industries would greatly benefit from new technologies that help get the situation under control again. Language-enabled mobile applications will become personal assistants to everyone, offering automatic and intelligent question answering and dialogue capabilities, as well as automatic, personalised and trusted text and speech processing of messages, news items and other content.

\textbf{Global Cooperation and Human Communication.} Companies need to address new markets where multiple languages are spoken and support multinational teams at multiple locations. Many jobs cannot be filled today because linguistic barriers exclude otherwise qualified personnel. Improvements in language technology can enable richer interactions and provide more advanced tele and video conferencing services. Future technologies like a 3D internet can enable new modes of collaboration as well as support more realistic training and education scenarios. We will soon be able to participate in virtual events as new forms of entertainment, cultural exchange and tourism. Combining virtual worlds and simulations with multilingual language technology including translation, automatic minute taking, video indexing and searching will let us experience being European in a new way.

\textbf{Preservation of Cultural Heritage and Linguistic Diversity.} According to the principles of the UN-endorsed World Summit on the Information Society \cite{worldsummit2003}, the “Information Society should be founded on and stimulate respect for cultural identity, cultural and linguistic diversity.” Much effort has been put into digital archives such as Europeana that help promote our cultural heritage. However, digitisation is only the first step. The sheer amount of information and language barriers hinder access of our cultural treasures. Language technology can make this content accessible, e.\,g., through cross-lingual search and machine translation. Likewise, communication skills need to be trained. This is underlined by the UNESCO Information for All Programme, which seeks to “foster the availability of indigenous knowledge through basic literacy and ICT literacy training” \cite{Unesco2}.

\textbf{Social Media and e-Participation.} Social networks have a significant impact on all areas of society and life. They can help us solve technical problems, research products, learn about interesting places or discover new recipes. Recent developments in North Africa demonstrate their ability to bring citizens together to express political power. Social media will play a key role in the discussion of important, future topics for Europe like a common energy strategy and foreign policy. However, certain groups are becoming detached from these developments. One can even speak of a broken link regarding communication cultures. This is an issue since bottom-up movements are highly relevant for politicians, marketing experts, and journalists who would like to know what customers or citizens think about initiatives, products, or publications. However, it is not possible to process manually the sheer amount of information generated in multiple languages on social networks. We need language technologies that are able to analyse these streams in real time.

\textbf{Market Awareness and Customer Acceptance.} Language technology is a key part of business and consumer software but often hidden inside other, more visible products. Customer acceptance of LT has recently been shown to be high. For example, market research by the Ford Motor Company indicates that their voice control system, Ford SYNC, is widely accepted \cite{ford}. 60\% of Ford vehicle owners use voice commands in their cars. Non-Ford owners report a three-fold increase in their willingness to consider Ford models while 32\% of existing customers admit that the technology played an important role in their purchase decision. Language technology has a tremendous market potential.

\textbf{One Market, Many Languages.} Support for the 23 official languages of the EU has major economic, social and political implications. Europe currently lags behind countries such as India (22 official languages) and South Africa (11 national languages). Government programmes in these two countries actively foster the development of language technology for a significant number of official languages \cite{india2012,sa2012}. Mobile devices are an even more important bridge between humans and information technology. Google already provides free translation services in 3,306 different language pairs as well as voice input for 16 languages and speech output for 24 languages. Apple's App Store has demonstrated how premium content and products can be marketed for free and for a fee. Europe must address this global competition.

\textbf{Secure Europe.} The effective persecution of illegal online activities such as fraud and identity theft requires automatic tools that can help detect crimes and monitor offenders. Language technology can help to build systems that can monitor, analyse and summarise large amounts of text, audio and video data in different languages and from different sources.

This collection of solutions was influenced by bigger trends (see Chapter~\ref{sec:ict-trends}). Many of these products and services are only available online. For example, Facebook and Twitter enabled recent political developments in North Africa. In Europe, the idea of social innovation has recently sparked an interest as it “offers an effective approach to respond to social challenges by mobilising people's creativity to develop solutions and make a better use of scarce resources” \cite{EC5}. Social innovation is part of Europe’s 2020 strategy and critically relies on active involvement of citizens, which in turn calls for supportive multilingual language technologies.

Multilingualism has become the global norm rather than the exception \cite{maaya2012}. Future applications that embed information and communication technology require sophisticated language technologies. Fully speech-enabled autonomous robots could help in disaster areas by rescuing travellers trapped in vehicles or by giving first aid. Language technology can significantly contribute towards improving social inclusion. Language technology can help us provide answers to urgent social challenges while creating genuine business opportunities.  Language technology can now automate the very processes of translation, content production, and knowledge management for all European languages. It can also empower intuitive language/speech-based interfaces for household electronics, machinery, vehicles, computers and robots.

In addition to these vertical societal challenges there are multiple horizontal properties that future language technologies need to exhibit. One of these properties is situation or context awareness. Many or even most applications sketched above need to exhibit a certain level of situation or context awareness. The challenge is to design and implement a paradigm in which language technologies are no longer static applications but able to adapt themselves to specific situations, trends and contexts such as, for example, user preferences or user interests. Security applications need to be aware of criminal or violent tendencies in communication patterns. E-participation systems need to be aware of interest in societal issues and need to have access to internet debates and the opinion of large online communities towards certain topics. Tools for the analysis of market awareness need methods for reputation mining, customer relationship systems need algorithms for attitude analysis.

\subsection{Market Opportunities}
\label{sec:market-opportunities}

% FIXME: This is LT Innovate's official take on META-NET: "The  META-NET Strategic Research Agenda provides a valuable set of indications with regard to medium- to long-term technology breakthroughs in the field of LT. LT-Innovate seeks to contribute to META-NET's vision by providing a complementary demand-driven vision, based on LT industry customers’ needs and expectations. From these demand-driven scenarios, LT-Innovate will derive innovation opportunities, which in-turn will require research input. Thus, by converging from opposite ends, LT-Innovate and META-NET will identify the key LT R&D&I challenges and opportunities for the next decade".

The market offers tremendous business potential for European language technology companies, especially for online retailers, language services, LT usage in key markets, data intensive scenarios and selected devices and environments. (This section is partially based on \cite{lti2012}).

Most online retailers are limited to small segments, the largest of which scarcely exceeds 60 million in population \cite{iws2012}: 82\% of European retailers operate in only a single language, 11\% in only two, and only 2\% provide services in five or more languages; only 21\% of European retailers support cross-border transactions. Although 51\% of European retailers sell via the internet, a vanishing small number of Europeans currently engage in online cross-border purchases. Language technology that lowers the burden and costs of translation and localisation for European languages would not only open the European market to European businesses, but enable them to access the estimated population of one billion individuals world-wide who speak one of Europe’s major languages, with accompanying economic benefit for European companies.

The market for LT software is currently expected to grow to 30 billion Euros by 2015 (versus 20 billion Euros today). European enterprises -- particularly the more than 500 active European SMEs -- have the potential to dominate the field if they can offer compelling solutions to Europe’s needs for online businesses and other fields.

Aside from the sales potential for online retailers, deployment of LT would increase overall demand for language-related services, currently worth ca.~5 billion Euros in Europe (expected to grow to ca.~8 billion Euros by 2015). As translation becomes the norm rather than the exception, the translation market, one which Europe currently dominates, would be expected to see substantially faster growth than anticipated.

In addition, dedicated LT-intense services will gain importance. Examples are technical translation supported by LT in the automotive domain, automatic interpreting for tourism and culture, or speaker verification for financial services and banking. The European LT industry is in a good position to serve these markets, since European LT companies specialise in these domains. 

The business role of LT can be characterised in terms of its relation to the Big Data market (estimated at ca.~4 billion Euros in 2012, expected to grow to ca.~13 billion Euros by 2015), cloud-based models for distribution and computation (expected to reach 45 billion Euros in the near future) or business data intelligence gathering and analysis (currently a 27 billion Euros market). In all these areas LT will be crucial for assuring high quality and meaningful use of data and data infrastructures. 

Finally, certain types of systems and devices will require LT for core functionality. Mobile devices currently drive 43\% of current IT growth; embedded systems are currently an 800 billion Euros p.\,a.~industry. At the moment U.S.-based companies have a lead in these areas, but their offerings often do not consider multilingualism as a base requirement. This will create a market opportunity in the billions of euros for European LT companies.
\end{multicols}

\clearpage

% --------------------------------------------------------------------------

\ssection[Major Trends in Information and Communication Technologies]{Major Trends in Information and Communication Technologies}

\begin{multicols}{2}

\subsection{The Current State}
\label{sec:ict-trends}

Networked computers are ubiquitous. They come in different shapes and forms (desktop, laptop, mobile phones, tablets, ebook readers, etc.) or are embedded in devices, objects, and systems such as, for example, cameras, washing machines, televisions, cars, heating systems, robots, traffic control systems. Software is usually available in multiple human languages. Global standardisation efforts such as Unicode solved the problem of representing and displaying different alphabets and special characters. 

Mobile devices and social media are reshaping how and when we communicate with one another using the tools and devices we use both in business and private life. The way we interact with computers is no longer restricted to graphical interfaces and keyboards, but it is being extended through touch screens, voice interfaces and dialogue systems, and mobile devices with accelerometers that tell the device how it is held by the user.

Language technology is currently not well integrated into applications and interfaces -- to the end user, spelling, grammar checking and maybe search seem to be the only notable exceptions.  Apple’s introduction of the mobile assistant Siri on the iPhone and a similar product by Google illustrate the trend towards more intelligent language-based interaction.

The web represents much of our knowledge. It emerged as a collection of static documents. Nowadays it is first and foremost a collection of systems and databases that can be queried through APIs, and applications such as Google Mail, Facebook, eBay and Amazon. Many people only need one application on their computers: a web browser. Others use netbooks whose operating system more or less \emph{is} the browser (Chromium OS). Behind the scenes, there is already a considerable amount of language technology incorporated in web applications such as search engines, dialogue systems, or machine translation services but these are not immediately visible or recognisable by the user as language technologies as such.

% =========================================================================================

\subsection{Hardware and Software}
\label{sec:hardware-software}

Networked computers come in many shapes and forms, from mobile phones to tablets, netbooks, ultra-portable laptops, small desktop computers and ebook readers to devices such as radios, televisions, gaming consoles and other entertainment devices with built-in wireless and access to, for example, RSS feeds, internet radio stations or youtube, cameras or house-hold appliances such as fridges, coffee machines or scales that push the user's weight to the cloud from where it can be monitored using an app on the smartphone. The next hardware revolution will be wearable computers. Google has already demonstrated a prototype of their Google Glasses product in which the computer visuals are projected into a head-up display. This approach can be used to provide the user with a true augmented reality perspective and a hands-free computing environment which immediately brings up the question how to interact with this device -- by using only your voice?

The shape and size of computers is no longer determined by the shape and size of their internal hardware components. Due to breakthroughs in miniaturisation, their form now truly follows their function. While computers and devices with embedded systems get smaller and smaller, the distributed data centres around the world get bigger and bigger -- both in terms of number and size. The concept of cloud computing and storing data in dedicated data centres from where the data can be accessed by multiple devices, is already mainstream and used by millions of consumers world-wide. An important reason for the cloud's success is the fact that, by now, people tend to have more than one computer. A not too unusual setup may include a laptop, a smartphone, a tablet and another computer as a dedicated media centre. Cloud services are ideal for synchronising data between many devices.

The trends in the software area are much more multi-dimensional. Here we can only scratch the surface and highlight several recent developments and current trends.

\textbf{Communication:} A cornerstone of today's computer use is communication, be it more direct communication via traditional e-mail, instant messaging, text-based chat systems, video chat between two people or larger groups or indirect communication and staying in touch with friends, acquaintances and colleagues via social networks such as Twitter, Facebook, LinkedIn, Instagram or social media such as blogs, YouTube, or Pinterest. Millions of people world-wide are always online using several different networked devices including their phones. 

\textbf{Search and Information Services:} An important use case of any type of device is to search for information and to make use of information services. Important applications are web search engines, online encyclopedias, news sites, digital libraries such as Europeana, meta-search engines and RSS feed aggregators etc.

\columnbreak

\textbf{Location-based Services:} Search queries are often coupled to the user's location. Location-based services enable the user to search for information in his or her geographic area, to make use of online maps, navigation systems, recommender systems or to find tweets or photos from the neighbourhood.

\textbf{Media monitoring:} Search and retrieval enable users to find information they already know about or suspect exist. Both are about finding the needles in the haystack. Media monitoring and applications with a certain level of situation awareness are not about finding documents or items, they are about keeping track of the state of the world. Applications for this purpose are coming to the market at a rapid pace.

\textbf{E-Commerce and Shopping:} World-wide billions of Euros are spent each year using general online shops such as Amazon or eBay or shops run by specific brands or services, reservation and booking, online banking and brokering services etc. 

\textbf{Media and Entertainment:} Different types of media (photos, videos, music, sounds, text and multimedia documents, audio and video podcasts, ebooks, films, tv programmes etc.) play an important role. Not only personal media such as photos or videos and other user-generated content are often posted to social networks, songs, photos or videos created by third parties are also often shared using social networks. Almost all of the media mentioned above can be purchased in online stores, for consumption on any device. Another important software category is games, from online Flash games to games that are embedded into social networks, location-based games, multi-player games with millions of users to very simple but also very successful casual games such as Angry Birds.

\textbf{App and Media Stores:} The success of ecommerce platforms \cite{bruegel12}, online shopping and the increased use of digital media led to app and media stores. By now it is possible to buy or rent almost every movie ever made, to buy music, to stream music from the cloud onto your device and to buy software and mobile apps through dedicated stores without any need to ship physical media. An important development is in-app purchasing, especially on mobile devices: with a single tap of a finger it is possible to buy, within a specific app, additional modules, components or data sets for a small price.

\textbf{Personal Information Management:} With the ever increasing number of personal and professional contacts (including social networks), meetings and personal errands to run, there is a big trend towards personal information management. This includes address and contacts databases that are often integrated into larger applications such as Google Contacts (embedded in, among others, Google Mail) or Apple's AddressBook (used in Apple Mail). Cloud-integration is an important feature, so that contact information (including names, email addresses, phone numbers, photos etc.), calendar entries and ``to do'' items are always available on all devices. 

\textbf{Office Applications:} The classic office applications --~word processors, spreadsheets, presentations~-- are still important in the professional context and also in home use. Nowadays, there are several applications to choose from including open source software, cloud-based services and applications for Apple's iOS. Almost all office suites use the cloud to enable the user to, for example, finish work on a presentation at the desktop computer where the document is automatically pushed to the cloud and to continue working on the presentation on a mobile device on the way home.

One of the most basic common denominators of all pieces of software is language which plays a central and integral part in practically every single tool or application. However, language technology as such (including text analysis, information retrieval and extraction, spelling and grammar checking, speech recognition and synthesis, dialogue systems etc.) is usually completely hidden, integrated into bigger applications, working behind the scenes. There is, however, a clear trend to embed language technologies not only at the level of the single application but on the level of the operating system. Another important factor of current computing is communicating and interacting with other people or groups of people, both on the personal level and also for business purposes.  A third crucial ingredient of computing today is information, especially structured information which is annotated based on specific standards (see, for example, the family of standards around XML, Semantic Web, Linked Open Data, Web Services, Big Data etc.).

\subsection{Current Trends and Mega-Trends}
\label{sec:major-trends}

In the following we sketch some of the current trends and mega-trends, grouped into three sections.

\textbf{Internet:} The internet will continue to be \emph{the} main driving force behind future developments in information and communication technologies. There are several mega-trends tightly coupled to the internet and network technologies: among these are cloud computing and cloud services, including cloud storage, as well as linked open data and the semantic web. Social media and social networks will continue to change everything and to penetrate the market further, including niche markets, driven by location-based services. With the predominance of social networks we expect a certain convergence of digital identities that will enable users to have and to maintain one central digital identity that feeds into their multiple social network profiles. Exchanging and distributing personal data and information (photos, videos, music etc.) in a secure way will become easier. We further expect more broad deployment and general acceptance of services in the areas of e-democracy and e-government (including open data portals) and a continued increase of e-commerce platforms \cite{bruegel12} and services. A perceived general information overload will continue to be a problem, although modern search engines, aggregation services and user interfaces help a lot. New business models and ways to distribute content or services to the end-user will continue to emerge (see the different app stores and approaches such as in-app purchases).

\textbf{People:} Information and communication technologies are used by people -- the predominance of social networks and being always-on using smartphones, tablets and laptops, is responsible for the fact that the way people interact, communicate and do business with one another will continue to be redefined and reshaped completely, including novel approaches for participation and public deliberation processes. Communication tools such as email, twitter, facebook etc.~are mainstream by now and used across all age groups. This trend will continue. The trend to use social networks and location-based services to find ``faces and places'', items or places of interest or new acquaintances with similar hobbies will continue (along with a more in-depth discussion of privacy issues). We expect a tighter connection between the data stored in social networks as well as tools for personal information management and the linked open data cloud.

\textbf{Hardware and Software:} Many internet companies operate under the slogan ``mobile first''. Accessing the web on mobile devices will overtake the use of desktops and laptops very soon. There is also a tendency for completely novel mobile devices with Apple's iPad and Google's Glasses being two prime examples. More and more household-appliances get connected to the internet (tv, radio, gaming consoles, refrigerator, scales, coffee machine, lamps etc.), ultimately leading to the Internet of Things. Many of these devices will not have displays but voice-driven interfaces. We expect a seamless integration of mobile devices into the hardware landscape at home including simplified data and application transfer and exchange among arbitrary mobile or stationary devices, playing music or movies on displays or video projectors etc. Very soon there will not be a need anymore for the average user to own a laptop or desktop computer because mobile devices will cover all basic needs. The capacity and bandwidth of networks will continue to grow, mobile telecommunication networks will gradually become more important than, for example, ADSL lines. The quality of voice or video calls will continue to improve, phones and all other devices will continue to become faster, have more storage as well as 3D-capable displays that offer more intricate modes of interaction. Mobile phones will have built-in facilities to replace credit cards for payment purposes, effectively replacing the wallet. Finally, the market for apps, especially mobile apps, will continue to grow. Nowadays many companies, services and events have their own app that users can interact with and that usually offer added value when compared to the respective website. Usability will continue to be a decisive factor: only those apps will be successful that users can interact with intuitively right away.

To sum up, information and communication technologies will continue to be ubiquitous, available wherever and whenever needed. These technologies will be services that combine widely distributed applications, resources and data. They will be able to adapt to the location, situation and needs of the user including current emotions, habits and goals. As can be seen by the success of Wikipedia and other collaboratively edited knowledge bases, it is only a matter of time until a gigantic digital model of our world (or many bigger and smaller digital models) will exist that consists of interlinked and overlapping components. Naturally, languages and especially the automatic processing of languages using language technologies will play a key role in this development. Now is the time to realise the needed breakthroughs. High performance, robust machine translation and related language technology services are urgently needed. There is a huge window of opportunity for consumer-oriented language technology.

Large global platforms for end-user-services have become the predominant innovation drivers for language technology solutions. Well known examples are web services such as Google Search, now integrating the new Knowledge Graph concept network, speech-enabled search \cite{meisel12}, web translation services but also social networks such as Twitter and Facebook. Combinations of hardware and operating systems such as iOS for Apple's mobile devices or Android can also be considered platforms. The trend towards widely used platforms will drastically facilitate the spreading of innovative language technologies. LT has a good chance of becoming \emph{the} essential feature for the success of the next generation of platforms and services. At closer inspection, the integration of sophisticated LT in current platforms is very limited, scratching only the surface of what will be possible in the near future.

% FIXME: delete this sentence?
While the LT-related aspects will be further discussed in the following chapters, we provide a more in-depth discussion of two selected trends in the next two Sections.

\subsection[Selected Trend: Big Data, Linked Open Data and the Data Challenge]{Selected Trend:\newline Big Data, Linked Open Data and the Data Challenge}
\label{sec:linked-data-open}

There are two important trends concerning data on the web. First, the web is becoming translingual, with content and knowledge being accessible across languages, allowing users to search for and interact with knowledge, but also with devices which are part of the Web of Things, accessible for everybody in their own language. Second, more and more amounts of data -- \emph{Big Data} -- are being made available online. Big data leads to new challenges in terms of scalability, but also to many new innovations and application scenarios. 

The Translingual Web will enable world wide, borderless communication and commerce. Linked Open Data based on the Semantic Web will be able to support language technologies for improved quality, e.\,g., in machine translation or crosslingual search. On the other hand, language technology can support Linked Open Data. It provides the means to create inter- and intra language links and relations to textual knowledge.

Our three priority themes (see Chapter~\ref{sec:pts}) are related to the Translingual Web and data. The Translingual Cloud will benefit from data available across languages. Translation technologies will also help to address data challenges, like building and cleaning data sets that span across languages or providing links between data sets within one or between languages. Multilingual access is an important requirement for a European vision of e-government and e-participation services. On the one hand, language technology can make use of open, governmental data that is made available on portals such as \url{data.gov.uk} or within the upcoming European data portal. On the other hand, improving language technologies is inevitable for realising multilingual access to public sector data for all European citizens, as recommended by the European Interoperability Framework for European public services \cite{EIF2010}: the sheer amount of data and language barriers between data sets are obstacles that can only be removed with language technologies (e.\,g., machine translation, crosslingual information access and information extraction). Finally, one application scenario of Socially-Aware Interactive Assistants are multilingual virtual meetings that make use of shared data sets that provide information about individuals, organisations and interaction settings. 
 
In order to be able to overcome language barriers, data infrastructures need to be made available, while carefully taking licensing and data provenance into account. Existing language and localisation resources (e.\,g., terminological, lexical data or translation memories) need to be transformed into linked open data. Only then will they be able to play a key role for creating truly multilingual linked open data.  Standardisation is crucial when it comes to implementing the infrastructure. So are reference implementations that deal with standardised data and metadata for human language in LT, localisation, CMS, CAT and TMS tools, to assure that standards can be put into action easily and get wide adoption.

Language Technology will also play a key role for Big Data. Building future-proof solutions for big data analysis is impossible without Language Technology. Big data analysis will not be slightly better if we include language technology -- it simply will not happen. We cannot download big data into a database and then build applications on top of it -- we will need to process it sensibly and that sense will need to be based on language. This challenge not only relates to structured big data but also to any type of unstructured data including text documents and social media streams, esentially any sequential symbolic process of meaningful information. LT will build bridges from big data to knowledge, from unstructured data to structured data, and can finally lead to what some people are already referring to as Big Semantics. Language Technology will become the foundation for organising, analysing and extracting data in a truly useful way.

To achieve success in these trends, various prerequisites need to be fulfilled. Linked open data sets need to be enriched with multilingual information. For textual knowledge we can expect that the enrichment will trigger a bootstrapping process. Here, bootstrapping means that existing Semantic Web vocabularies and data sets will be enriched with multilingual information in a first step. They can then be exploited as background knowledge for improved text analysis. Afterwards they can be fed back into the world of linked open data. Models such as, e.\,g., Lemon for enriching ontologies with multilingual, linguistic information will lead to richer resources and quality in the areas of machine translation, question answering, information extraction or textual entailment. This will create a synergetic cycle, in which the Semantic Web and deep text analysis benefit from each other, effectively bootstrapping the Translingual Web. For realising these synergies, methodologies need to be developed both for high quality, manually created linked open data resources and for big data, e.\,g., analysing activities of billions of users on the global, multilingual social web.

Another pre-requisite for the convergence of data and Language Technology is the availability of free, open and interoperable data sources. Existing resources such as Wikipedia, DBpedia, Wikidata, Yago and OpenStreetMap need to be consolidated, based on standardised vocabularies to support interoperability and re-use. Core ontology vocabularies need to be translated into different languages. Tools have to be developed for cleaning up data, as well as mechanisms that can aggregate, summarise and repurpose content. Again the functionalities will be adapted to both small as well as big data sets.

For all Language Technology applications that interact with data, the regulation of intellectual property rights is a problem that needs to be resolved soon. The web is a global information space, and Europe has to find a legal approach that supports both local R\&D while fostering global competitiveness.

In the Seventh Framework Programme, projects and efforts such as DBpedia, Monnet, Wikidata and META-NET's META-SHARE have started tackling problems in the data-related trends discussed above. Organisations like ISO TC37 SC4, GALA and the World Wide Web Consortium  support this work by providing standardised building blocks for application development and data sharing. Europe is in a good position to be in the driver's seat of the data challenge, both for human knowledge and big data, effectively creating multiple new data value chains.

\subsection[Selected Trend: From Cloud Computing to Sky Computing]{Selected Trend:\newline From Cloud Computing to Sky Computing}
\label{sec:cloud-sky-computing}

A major megatrend is known as cloud computing. A large proportion of IT solutions is already offered through the internet, forecasts predict that it will increase rapidly. Computing may be offered on different levels of abstraction ranging from Infrastructures as a Service (IaaS) via Platforms as a Service (PaaS) to the powerful concept of providing any suitable software product as an internet service (Software as a Service, SaaS). Especially the latter concept has far-reaching, mainly beneficial, implications for distribution, support, customisation, maintenance and pricing. It also opens new opportunities for software evolution by emerging dynamic schemes of integration, evaluation, adaptation and scaling. A well-known example are the Google Docs office applications. In language technology an increasing number of solutions are already offered as free or commercial web services, among them machine translation, language checking and text-to-speech conversion.

A special challenge for cloud computing is the need for trust. Since the services are rendered outside their sphere of control, customers demand sufficient safeguards securing performance, data protection, and persistence. Large European users of translation technology do not send their corporate language data to the existing large online translation services because the service providers do not offer a trust mechanisms. The situation is even more severe for business intelligence applications where the confidentiality of the collected information can be mission critical for planning and decision processes.  

The most far-reaching development within the cloud computing trend is the inter-cloud or sky computing paradigm. Although the cloud metaphor originated from the widely used graphical icon for the internet symbolising the entire global network outside the user’s computer, soon the term became applied to any computing service provided on the internet. The term sky computing extends the notion of cloud computing. It was coined for a setup in which clouds are combined into complex services, environments with workflows realising functionalities that exceed the capabilities of the individual services. A new line of research and development is dedicated to the creation of sky computing platforms that permit such integration.

Language technologies are prime candidates for sky computing setups since they are often a component of complex applications such as services supporting knowledge discovery, business intelligence or text production. Taking into account the large number of languages, language variants and subject domains, a sky computing setup can provide a much larger number of language and task-specific workflows through service composition than a traditional software product. Small and medium technology enterprises will be able much more easily to enter the market, stay on the market and improve their services without having to cast all demanded service combinations into their product family or into a range of bilateral OEM partnerships.

\subsection[The Future Role of Language Technology]{The Future Role of Language Technology}
\label{sec:}

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.9\textwidth]{../_media/Gartner-2012-Hype-Cycle.jpeg}
  \caption{Gartner's 2012 Hype Cycle for Emerging Technologies \cite{gartner2012}}
  \label{fig:hype-cycle}
\end{figure*}

% http://www.gartner.com/it/page.jsp?id=2124315

In the next years language technology will play a major and decisive role, as explained and demonstrated by the discussion of megatrends and selected trends above. 

The IT research and advisory company Gartner publishes the ``Gartner Hype Cycle'' every year. These studies are meant to provide strategists and planners with an assessment of the maturity, business benefit and future direction of more than 1,900 technologies, grouped into 92 areas \cite{gartner2012}. Among the ones most prominently featured by the report are big data, 3D printing, activity streams, Internet TV, Near Field Communication (NFC) payment, cloud computing and media tablets. The Gartner analysts also mention several significant scenarios, that appear to be extremely promising on multiple levels but for which more enabling technologies are needed before they can be put into practice. Among them are  ``smarter things'' and, most notably, ``the human way to interact with technology''. In fact, if we take a closer look at the 2012 hype cycle, reproduced in Figure~\ref{fig:hype-cycle}, we notice that a total of 13 of the 48 technologies listed are language technologies, many of which are in the early ``technology trigger'' phase. Among the top emerging and key enabling technologies of 2012 and the coming years are, to list only a few, Automatic Content Recognition, Natural-Language Question Answering, Speech-to-Speech Translation, Complex Event-Processing, Social Analytics, Text Analytics and Speech Recognition. This assessment clearly shows that now is the time to invest in strategic research in the area of language technology and to go for a major, continent-wide push. One thing is certain: these technologies \emph{will} come -- they will be responsible for the biggest revolution in IT since the introduction of the graphical user interface and they will generate many jobs and countless business as well as social opportunities. Europe can now decide if it wants to play only a minor role, following the US and Asia, or it wants to move ahead and take the lead itself.
\end{multicols}

\clearpage

% --------------------------------------------------------------------------

\ssection[Language Technology 2012: Current State and Opportunities]{Language Technology 2012:\newline Current State and Opportunities}
\label{sec:lwp}

\begin{multicols}{2}

\subsection{Current State of European Language Technology}
\label{sec:what-current-state}

Answering the question on the current state of a whole R\&D field is both difficult and complex. For language technology, even though partial answers exist in terms of business figures, scientific challenges and results from educational studies, nobody has collected these indicators and provided comparable reports for a substantial number of European languages yet. In order to arrive at a comprehensive answer, META-NET prepared the White Paper Series ``Europe's Languages in the Digital Age'' that describes the current state of language technology support for 30 European languages \cite{LWP2012}. This immense undertaking has been in preparation since mid 2010 and was published in the Summer of 2012. More than 200 experts from academia and industry participated to the 30 volumes as co-authors and contributors. White Papers were written for the following 30 European languages (including all 23 official EU languages):

\medskip
\centerline{\fbox{\parbox{\dimexpr 0.91\linewidth - 2\fboxrule - 2\fboxsep}{Basque, Bulgarian, Catalan, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hungarian, Icelandic, Irish, Italian, Latvian, Lithuanian, Maltese, Norwegian, Polish, Portuguese, Romanian, Serbian, Slovak, Slovene, Spanish, Swedish}}}

\medskip 
The current state of support through language technology varies considerably from one language community to another. In order to compare the situation between languages, the META-NET White Paper Series introduces an evaluation based on two sample application areas (Machine Translation and Speech Processing) and one underlying technology (Text Analytics) as well as basic Language Resources needed for building LT applications (for example, very large collections of texts for machine learning purposes). For each language, support through language technology was categorised using a five-point scale (1.~excellent support; 2.~good support; 3.~moderate support; 4.~fragmentary support; 5.~weak or no support) and measured according to the following key criteria:

\textbf{Machine Translation:} quality of existing technologies, number of language pairs covered, coverage of linguistic phenomena and domains, quality and size of parallel corpora, amount and variety of applications.

\textbf{Speech Processing:} quality of existing speech recognition and synthesis technologies, coverage of domains, number and size of existing corpora, amount and variety of available applications.

\textbf{Text Analytics:} quality and coverage of existing technologies (morphology, syntax, semantics), coverage of linguistic phenomena and domains, amount and variety of available applications, quality and size of (annotated) corpora, quality and coverage of lexical resources (e.\,g., WordNet) and grammars.

\textbf{Resources:} quality and size of text corpora, speech corpora and parallel corpora, quality and coverage of lexical resources and grammars.

The more than 200 co-authors of and contributors to the White Papers prepared initial language-specific assessments of technology support by assessing ca.~25 different applications, tools and resources along seven different axes and criteria. Later on, the 30 individual and language-specific matrices were condensed in order to arrive at a single score per language and area. 

Figure~\ref{fig:europes-languages} demonstrates that the differences in technology support between the various European languages and areas are both dramatic and alarming. In all four areas, English is ahead of the other languages but even support for English is far from being perfect. While there are good quality software and resources available for a few larger languages and application areas, others, usually smaller or very small languages, have substantial gaps. Many languages lack even basic technologies for text analytics and essential language resources. Others have basic tools and resources but the implementation of, for example, semantic methods is still far away. Therefore, a large-scale effort is needed to attain the ambitious goal of providing high-quality language technologies for all European languages.

\begin{figure*}[htbp]
  \footnotesize
  \centering
  \begin{tabular}
  { % defines color for each column.
  m{0.02\linewidth}
  >{\columncolor{corange5}}m{.16\linewidth}@{\hspace{.035\linewidth}}
  >{\columncolor{corange4}}m{.16\linewidth}@{\hspace{.035\linewidth}}
  >{\columncolor{corange3}}m{.16\linewidth}@{\hspace{.035\linewidth}}
  >{\columncolor{corange2}}m{.16\linewidth}@{\hspace{.035\linewidth}}
  >{\columncolor{corange1}}m{.16\linewidth} 
  }
  & 
  \multicolumn{1}{>{\columncolor{white}}c@{\hspace{.035\linewidth}}}{\textbf{Support: excellent}} & 
  \multicolumn{1}{@{}>{\columncolor{white}}c@{\hspace{.035\linewidth}}}{\textbf{good}} &
  \multicolumn{1}{@{}>{\columncolor{white}}c@{\hspace{.035\linewidth}}}{\textbf{moderate}} &
  \multicolumn{1}{@{}>{\columncolor{white}}c@{\hspace{.035\linewidth}}}{\textbf{fragmentary}} &
  \multicolumn{1}{@{}>{\columncolor{white}}c}{\textbf{weak/none}} \\ \addlinespace

% Machine Translation
\rotatebox{90}{\textbf{Machine Translation}} &
& \vspace*{0.5mm} English
& \vspace*{0.5mm} French, Spanish
& \vspace*{0.5mm} Catalan, Dutch,\newline German, Hungarian,\newline Italian, Polish,\newline Romanian
& \vspace*{0.5mm} ~\newline Basque, Bulgarian,\newline Croatian, Czech,\newline Danish, Estonian,\newline Finnish, Galician,\newline Greek, Icelandic, \newline Irish, Latvian, \newline Lithuanian, Maltese,\newline Norwegian,\newline Portuguese,\newline Serbian, Slovak,\newline Slovene, Swedish\newline \\ \addlinespace

% Speech Processing
\rotatebox{90}{\textbf{Speech}} & 
& \vspace*{0.5mm} English
& \vspace*{0.5mm} Czech, Dutch,\newline Finnish, French,\newline German, Italian,\newline Portuguese, Spanish
& \vspace*{0.5mm} ~\newline Basque, Bulgarian,\newline Catalan, Danish,\newline Estonian, Galician,\newline Greek, Hungarian,\newline Irish, Norwegian,\newline Polish, Serbian,\newline Slovak, Slovene,\newline Swedish\newline
& \vspace*{0.5mm} Croatian, Icelandic,\newline Latvian, Lithuanian,\newline Maltese, Romanian \\ \addlinespace

% Text Analytics
\rotatebox{90}{\textbf{Text Analytics}} & 
& \vspace*{0.5mm} English
& \vspace*{0.5mm} Dutch, French,\newline German, Italian,\newline Spanish
& \vspace*{0.5mm} ~\newline Basque, Bulgarian,\newline Catalan, Czech,\newline Danish, Finnish,\newline Galician, Greek,\newline Hungarian,\newline Norwegian, Polish,\newline Portuguese,\newline Romanian, Slovak,\newline Slovene, Swedish\newline
& \vspace*{0.5mm} Croatian, Estonian,\newline Icelandic, Irish,\newline Latvian, Lithuanian,\newline Maltese, Serbian \\ \addlinespace

% Speech and Text Resources
\rotatebox{90}{\textbf{Language Resources}} & 
& \vspace*{0.5mm} English
& \vspace*{0.5mm} Czech, Dutch,\newline French, German,\newline Hungarian, Italian,\newline Polish, Spanish,\newline Swedish
& \vspace*{0.5mm} ~\newline Basque, Bulgarian,\newline Catalan, Croatian,\newline Danish, Estonian,\newline Finnish, Galician,\newline Greek, Norwegian,\newline Portuguese,\newline Romanian, Serbian,\newline Slovak, Slovene \newline
& \vspace*{0.5mm} Icelandic, Irish,\newline Latvian, Lithuanian,\newline Maltese  \\

\end{tabular}
\caption{State of language technology support for 30 European languages in four different areas}
\label{fig:europes-languages}
\end{figure*}

The White Paper Series contains assessments for each of the 30 languages. Currently no language, not even English, has the technological support it deserves. Also, the number of badly supported and under-resourced languages is unacceptable if we do not want to give up the principles of solidarity and subsidiarity in Europe.

\subsection{The Danger of Digital Language Extinction}
\label{sec:digital-language-extinction}

On the occasion of the European Day of Languages 2012, September 26, we announced the results of our ``Europe's Languages in the Digital Age'' study to the public through a press release translated into 30 languages. The headline was: \emph{At Least 21 European Languages in Danger of Digital Extinction -- Good News and Bad News on the European Day of Languages}. 

We were overwhelmed by the immediate, very big interest in the topic and our findings. The first articles appeared online only hours after we sent out the first press releases. We also received many requests for radio and television interviews. Journalists called to collect additional statements and to enquire about specific details. 

By now we estimate ca.~550 mentions in the online press in Europe and also multiple mentions in the international press (from Mexico to New Zealand). We also estimate that our press release generated more than 75 mentions in traditional newspapers. Representatives of META-NET took part in about 45 radio interviews (for example, in Germany, Greece, Iceland, Ireland, Latvia, Norway). We estimate that an additional 25 radio and more than 25 television programmes (including coverage in, for example, Iceland and Latvia) reported on our findings. 

A few significant newspapers and blogs that reported on the study: Der Standard (Austria); Politiken, Berlingske Tidende (Denmark); Tiede (Finland); Heise Newsticker, Süddeutsche Zeitung (Germany); in.gr, Πρώτο Θέμα, Καθημερινή (Greece); Fréttablaðið, Morgunblaðið (Iceland); Wired (Italy); Computerworld (Norway); Delo, Dnevnik, De\-mo\-kra\-cija (Slovenia); El Mundo (Spain); Huffington Post (UK); Mashable, NBC News, Reddit (USA). A full list is available online at \url{http://www.meta-net.eu/whitepapers/press-coverage}. 

The immediacy and size of the echo generated by our press release shows that Europe is very passionate about its languages, concerned about digital language extinction and that it is also very interested in the idea of establishing a solid language technology base for overcoming language barriers. 

\subsection{Education and Training}
\label{sec:improved-edu-and-training}

An indispensable prerequisite for innovative research and technology development are highly qualified researchers and software developers. In the ca.~two years it took us to prepare this agenda, we talked to representatives of many companies. With almost no exceptions these industry representatives mentioned the lack of qualified personnel to be a significiant problem for their further growth and diminishing factor for producing innovative technologies. Europe's academic programmes in Natural Language Processing, Computational Linguistics, Language Technologies, Language-Oriented Information Processing etc.~need to be further strengthened and advertised on an international level and made more attractive for potential students. In a later implementation phase of this agenda we plan to introduce coordinated training programmes for IT professionals and software developers who are not yet familiar with language technologies so that they are made aware of our tools, resources and technologies and learn how to make use of them in their own IT landscapes. The lack of skilled personnel --~from students to senior software engineers~-- currently is a, if not \emph{the} major bottleneck for many small and medium companies and also research centres.

\subsection{Challenges and Chances}
\label{sec:challenges-chances}

As with most technologies, the first language applications such as voice-based user interfaces and dialogue systems were developed for highly specialised domains and purposes, and often exhibited rather limited performance. By now, however, there are huge market opportunities in the communication, collaboration, education and entertainment industries for integrating language technologies into general information and communication technologies, games, cultural heritage sites, edutainment packages, libraries, simulation environments and training programmes. Mobile information services, computer-assisted language learning software, e-learning environments, self-assessment tools and plagiarism detection software are just a few application areas in which language technology can and will play an important role in the years to come. The success of social networks such as Twitter and Facebook demonstrates a further need for sophisticated language technologies that can monitor posts, summarise discussions, suggest opinion trends, detect emotional responses, identify copyright infringements or track misuse.

Language technology represents a tremendous opportunity for the European Union. It can help address the complex issue of multilingualism in Europe. Citizens need to communicate across language borders, criss-crossing the European common market -- language technology can help overcome this final barrier while supporting the free and open use of individual languages. Looking even a bit further into the future, innovative European multilingual language technology could provide a benchmark for other multilingual communities in the world \cite{maaya2012,ifa2008,ifa2011}. This, in turn, would generate additional market opportunities for European companies.

The automated translation and speech processing tools currently available fall short of the envisaged goals. The dominant actors in the field are primarily companies based in the US. As early as the late 1970s, the EU realised the profound relevance of LT as a driver of European unity, and began funding its first research projects. At the same time, national projects were set up that generated valuable results, but never led to a concerted European effort. In contrast to these highly selective funding efforts, other multilingual societies such as India (22 official languages) and South Africa (11 official languages) have recently set up long-term national programmes for language research and technology development.

Today the predominant actors in language technology rely on statistical approaches, but rule-based approaches reach comparable performance in a different way. Not surprisingly, cross-fertilisation between these approaches has been sought and reached already. Both in combination and in separation there are promising ideas to advance these approaches. On the one hand, analysing the deeper structural properties of languages in terms of syntax and semantics as well as making use of different types of knowledge and inferencing is a promising way forward if we want to build applications that perform well across the entire range of European languages. On the other hand, we need statistical models that go beyond the current ones and extract more dependencies from the data. They can be related to existing linguistic theories, but they might also be very much different. The dependencies have to be deeply integrated and require research on statistical decision theory and machine learning along with efficient algorithms and implementations.

The European Union is funding projects such as EuroMatrix and EuroMatrix+ (since 2006) and iTranslate4 (since 2010), that carry out basic and applied research and also generate resources for establishing high quality language technology solutions for several European languages. European research in the area of language technology has already achieved a number of outstanding successes. For example, the translation services of the EU now use the Moses open source machine translation software, which has been mainly developed in European research projects \cite{moses}. In addition, national funding used to have huge impact. For example, the Verbmobil project, funded by the German Ministry of Education and Research (BMBF) between 1993 and 2000, pushed Germany to the top position in the world in terms of speech translation research for a time. Rather than building on the important results and success stories generated by these projects, Europe has tended to pursue isolated research activities with a less pervasive impact on the market. The economic value of even the earliest efforts can be seen in the number of spin-offs: a company such as Trados, founded back in 1984, was sold to the UK-based SDL in 2005.

Today’s hybrid language technology mixing deep processing with statistical methods will be able to bridge the gap between all European languages and beyond. But as we have described above, there is a dramatic difference between Europe’s languages in terms of both the maturity of the research and the state of readiness with respect to language technology solutions. 

Three key ingredients are needed to realise the technology visions described in the next chapter: the right actors, a shared vision and strategic programme and a certain level of support and commitment. Until recently the European community of language technologists and language professionals had to be considered highly fragmented at best. In early 2010 META-NET (see appendix~\ref{sec:app-meta-net}, p.~\pageref{sec:app-meta-net}) has started to bring the fragmented community together and to assemble researchers from the different subfields involved in language technology and also related scientific fields (humanities, psychology, social sciences etc.), universities, research centres, the language communities, national language institutions, smaller and medium companies (including several startups) as well as large enterprises, officials, administrators, politicians under one roof: META (Multilingual Europe Technology Alliance). By now META has more than 650 members in more than 50 countries (roughly one third of META's membership base are companies). 

Now that the European language technology community has been brought together we can present our technology vision and strategic research agenda as illustrated in this very document. The whole META community has shaped this SRA through participating in many discussions around the ideas, approaches, technology visions and strategic goals described in this agenda (see, among others, the list of key contributors on p.~\pageref{sec:list-of-contributors}\,f.). 

META-NET hopes to raise enough awareness, enthusiasm and, eventually, support to develop and, finally, to bring about a truly multilingual Europe based on sophisticated language technologies. To this end, we suggest to set up a shared and coordinated programme with the goal of concentrating our research efforts on the three priority research themes described in Chapter~\ref{sec:pts}. This shared and coordinated programme is foreseen to span all member states and associated countries and also the EU/EC. 
\end{multicols}

\clearpage

% --------------------------------------------------------------------------

\ssection[Language Technology 2020: The META-NET Technology Vision]{Language Technology 2020:\newline The META-NET Technology Vision}
\label{sec:lt2020}

\begin{multicols}{2}
\subsection{The Next IT Revolution}
\label{sec:introduction-vision}

People communicate using the languages they have known since early childhood, yet computers remained ignorant of their users’ languages for a long time. It took many years until they could reliably handle scripts of languages other than English. It took even longer until computers could check the spelling of texts and read them aloud for the visually impaired.
 
On the web we can now get rough translations and search for texts containing a word, even if the word occurs in a different form from the one we search for. But when it comes to interpreting certain input and responding correctly, computers only “understand” simple artificial languages such as Java, C++ and HTML.
 
In the next IT revolution computers will master our languages. Just as they already understand measurements and formats for dates and times, the operating systems of tomorrow will know human languages. They may not reach the linguistic performance of educated people and they will not yet know enough about the world to understand everything, but they will be much more useful than they are today and will further enhance our work and life.

\subsection{Communication Among People}
\label{sec:comm-among-people}

Language is our most natural medium for interpersonal communication, but computers cannot yet help much with regular conversation. With thousands of languages spoken on our planet, however, we will find ourselves in situations where language breaks down. In such situations we must rely on technology to help bridge the gap. While current translation technologies have been successfully demonstrated for limited numbers of languages and themes, computers have not yet fulfilled the dream of automatic translation. By the year 2020, however, with sufficient research effort on high-quality automatic translation and robust accurate speech recognition, reliable dialogue translation for face-to-face conversation and telecommunication will be possible for at least hundreds of languages, across multiple subject fields and text types, both spoken and written.

Today we use computers for producing and reading texts (emails, instant messages, novels, technical documents etc.), checking spelling and grammar, and finding alternatives for words. Enterprises already use LT products for checking conformance to corporate terminology and style guidelines. In 2020 authoring software will also check for appropriate style according to genre and purpose and help evaluate comprehensibility. It will flag potential errors, suggest corrections, and use authoring memories to proactively suggest completions of started sentences or even whole paragraphs.
 
Google Translate and other translation services provide access to information and knowledge for hundreds of millions of users across language boundaries. This technology is important for personal use and for numerous professional applications, e.\,g., intelligence jobs in which analysts search large bodies of text for relevant information. The European Commission uses similar translation technology provided by European research projects, but the translations produced by these technologies can only be used internally due to poor quality. Despite tremendous progress, it cannot yet help with the skyrocketing costs of outbound translation. Many translation services have started using machine translation, but further economic breakthroughs through increased translation quality are still ahead of us and will come in stages over the next ten years as the existing barriers for quality are overcome by new technologies that get closer to the structure and meaning behind human language.
 
For example, by 2020 tele-meetings utilising large displays and comfortable technology will be the norm for professional meetings. LT will be able to record, transcribe, and summarise meetings. Brainstorming will be facilitated by semantic lookup and structured display of relevant data, proposals, charts, pictures, and maps. This technology will simultaneously translate (interpret) the contributions of participants into as many languages as needed, and incrementally drafted summaries will be used for displaying the state of the discussion, including intermediate results and open issues. The software will be guided by partial understanding of the contents, i.\,e., by its semantic association with concepts in semantic models of domains and processes. 

Language technology will have a major role in helping with the ever-growing volume of correspondence. Automatic authoring techniques will actively help users draft messages. Many organisations already employ e-mail response management software to filter, sort, and route incoming email and to suggest replies for recognised types of requests. By 2020, business email will be embedded in semantically structured process models to automate standardised communication. Even before 2020, email communication will be semantically analysed, checked for sentiment indicators, and summarised in reports. LT will also help to integrate content across all communication channels: telecommunication, meetings, email and chat, etc. Semantic integration into work processes, threading, and response management will be applied across channels, as will machine translation and analytics.
 
The rise of Web 2.0 (social networks and user-generated content) has confronted LT with a new set of challenges. Every user can become a content producer and large numbers of people can participate in communications. Some of these multi-directional mass communications have turned into effective instruments to solicit support, put pressure on leaders and decisions makers, create ideas, and find solutions. Communities can emerge in a matter of hours or days around admired works of art, shared preferences, or social issues. Citizen action movements, international NGOs, self-help groups, expert circles, and communities of concerned consumers can all organise using these technologies.

The social web cannot reach its potential because the large volumes of user-generated content quickly become unmanageable and difficult to understand. Participants, outside stakeholders, and concerned decision makers find it difficult to stay on top of new developments. Much of the often-cited wisdom of the crowds and their motivation and efforts are wasted because of information overload. With focused research efforts leading up to 2020, LT will be able to harness this deluge to monitor, analyse, summarise, structure, document, and visualise social media dynamics. Democracy and markets will be enriched by powerful new mechanisms for developing improved collective solutions and decisions.

Language technology can also help by converting language between different modes. Early examples are dictation systems and text-to-speech tools that convert between spoken and written language. These technologies are already successful in limited areas but within the next few years they will reach full maturity, opening up much larger markets. They will be complemented by reliable conversion from spoken or written language into sign language and vice versa. LT will also be utilised for improved methods of supported communication and for conversion of everyday language into greatly simplified language for special types of disabilities.

\subsection{Communication with Technology}
\label{sec:comm-with-techn}

Through language technology, human language will become the primary medium for communication between people and technology. Today’s voice-control interfaces to smartphones and search engines are just the modest start of overcoming the communication barrier between humankind and the non-human part of the world.

This world consists of plants, animals, and other natural and man-made objects. The realm of man-made things ranges from small, simple objects to machines, appliances, and vehicles and more complex units such as robots, airplanes, buildings, traffic systems, and even entire cities. The artificially created world also consists of information and knowledge contained in books, films, recordings, and digital storage. Virtually all information and knowledge will soon be available in digital form and as a result the volumes of information about the world are growing exponentially. The result is a gigantic distributed digital model of our world that is continuously growing in complexity and fidelity. Through massive networking of this information and the linking of open data, this “second world” is getting more useful as a resource for information, planning, and knowledge creation.
 
We have a clear distinction between intelligent beings (humans, artificial agents with some autonomous behaviour) and all other kinds of objects. We can easily communicate with people and we would like to communicate with computers and robots, but we usually do not feel a pressing need to speak with a cup or with a power drill. However, as more and more products are equipped with sensors, processors, and information services such as descriptions, specifications, or manuals, this expectation is changing rapidly: only a few years ago the idea of talking to a car to access key functions would have seemed absurd, yet it is now commonplace. Many everyday objects are already connected to the internet (Internet of Things) or at least represented on the web (Web of Things) -- eventually we can and will communicate with such objects.
 
Depending on the function, complexity, relevance, and autonomy of man-made objects, the nature of desired communication can vary widely. Some objects will come with interesting information, often represented in the second world, that we would like to query and explore (such as manuals and consumer information). Other objects will provide information on their state and will have their own individual memory that can be queried. Objects than can perform actions, such as vehicles and appliances, will accept and carry out voice commands.

Recently the concept of a personal digital assistant has increased in popularity due to Siri on the iPhone and a similar product by Google. We will soon see much more sophisticated virtual personalities with expressive voices, faces, and gestures. They will become an interface to any information provided online. An assistant could speak about or even to machines, locations, the weather, the Empire State Building, or the London Stock Exchange. The metaphor of a personal assistant is powerful and extremely useful, since such an assistant can be made sensitive to the user’s preferences, habits, moods, and goals. It can even be made aware of socio-emotional signals and learn appropriate reactions from experience.  
 
Realising this ambitious vision will require a dedicated and thoughtfully planned massive effort in research and innovation. By the year 2020 we could have a highly personalised, socially aware and interactive virtual assistant. Having been trained on the user’s behaviour, digital information, and communication space, it will proactively offer valuable unrequested advice. Voice, gender, language, and mentality of the virtual character could be adjusted to the user’s preferences. The agent will be able to speak in the language and dialect of the user but also digest information in other natural and artificial languages and formats. The assistant will translate or interpret without the user even needing to request it. In the future, many providers of information about products, services, or touristic sites will try to present their information with a specific look and feel. The personality and functionality of the interface may also depend on the user type: there may be special interfaces for children, foreigners, and persons with disabilities.
 
By the year 2020 there will be a competitive landscape of intelligent interfaces to all kinds of objects and services employing human language and other modes, such as manual and facial gestures, for effective communication. Depending on the needed functions and available information, language coverage will range from simple commands to sophisticated dialogues. Many interface services will be offered as customisable cloud-based middleware, while others may be completely customised. The technologies needed for such interfaces to machines, objects, and locations are all part of the socially aware virtual assistant, so our priority theme also proposes creating enabling technologies for other interface products.
 
Two large application domains stand out in their demands and need for additional technologies: robotics and knowledge services.
 
Although robots have already taken over large parts of industrial production, the real era of robots is still ahead of us. Within this decade, specialised mobile robots will be deployed for personal services, rescue missions, household chores, and tasks of guarding and surveillance. Natural language is by far the best communication medium for natural human-robot interaction. By 2020 we will have robots around us that can communicate with us in human language, but their user friendliness and acceptance will largely depend on progress in LT research in the coming years. Since human language is very elaborate when speaking about perception, motion, and action in space and time, interaction with the physical world poses enormous challenges to LT. Some of these challenges can be addressed within the priority theme of the digital assistant, but without additional LT research in robotics, the communication skills of robots will lag behind their physical capabilities for a long time.
 
Communication with knowledge services raises a different set of problems: the inherent complexity of the represented knowledge requires considerable advances in technology. This complexity arises from the intricate structures of the subject domains and the richness of linguistic expressivity, in particular the great variety of options to implicitly or explicitly express the same fact or question. Moreover, much of the information that we can learn from a text stands between the lines. For us it follows from the text, but for language technology it needs to be derived by applying reasoning mechanisms and inference rules along with large amounts of explicitly encoded knowledge about the world.
 
From watching Star Trek, we have come to expect that one day we will be able to just say “Computer,” followed by any question. As long as an answer can be found or derived from the accumulated knowledge of mankind, it will come back in a matter of milliseconds. In the Jeopardy game show, IBM’s Watson was able to find correct answers that none of its human competitors could provide, which might lead one, erroneously, to think that the problem of automatic question answering is solved. Undoubtedly Watson is a great achievement that demonstrates the power of LT, but some of the questions that were too hard for the human quiz champions were actually rather easy for a machine that has ready access to handbooks, decades of news, lexicons, dictionaries, bibles, databases, and the entire Wikipedia. With clever lookup and selection mechanisms for the extraction of answers, Watson could actually find the right responses without a full analysis of the questions.
 
Outside the realm of quiz shows, however, most questions that people might ask cannot be answered by today’s technology, even if it has access to the entire web, because they require a certain degree of understanding of both the question and the passages containing potential answers. Research on automatic question answering and textual inferencing progresses is progressing rapidly and by 2020 we will be able to use internet services that can answer huge numbers of non-trivial questions. One prerequisite for this envisaged knowledge access through natural communication are novel technologies for offline processing of large knowledge repositories and massive volumes of other meaningful data which will be discussed in the following subsection.  

\subsection{Processing Knowledge and Information}
\label{sec:proc-knowl-inform}

Most knowledge on the web, by far, is formulated in human language. However, machines cannot yet automatically interpret the texts containing this knowledge. Machines can interpret knowledge represented in databases but databases are too simple in structure to express complex concepts and their relations. The logical formalisms of semanticists that were designed to cope with the complexity of human thought, on the other hand, proved too unwieldy for practical computation. Therefore computational logicians developed simpler logic representation languages as a compromise between desired expressivity and required computability. In these languages, knowledge engineers can create formal models of knowledge domains and ontologies, describing the concepts of the domains by their properties and their relations to other concepts. Ontologies enable knowledge engineers to specify which things, people, and places in the world belong to which concepts. Such a domain model can be queried like a database. Its contents can be automatically analysed and modified. 
 
The encoding of knowledge seemed to be a promising alternative to the current web, so that the vision of the Semantic Web was born. Its main bottleneck, however, remains the problem of knowledge acquisition. The intellectual creation of domain models turned out to be an extremely demanding and time-consuming task, requiring well-trained specialists that prepare new ontologies from scratch or base their work on existing taxonomies, ontologies, or categorisation systems. It is unrealistic to expect typical authors of web content to encode knowledge in Semantic Web languages based on description logics, nor will there be any affordable services for the manual conversion of large volumes of content.
 
Since LT did not have any means for automatically interpreting texts, language technologists had developed methods for extracting at least some relevant pieces of information. A rather simple task is the recognition of all person and company names, time and date expressions, locations and monetary expressions (named entity extraction). Much harder is the recognition of relations such as the one between company and customer, company and employee, or inventor and invention. Even more difficult are many-place relations such as the four-place relation of a wedding between groom and bride at a certain date and time. Events are typical cases of relations. However, events can have many more components, such as the causes, victims and circumstances of accidents. Although research in this area is advancing, a reliable recognition of relations is not yet possible. Information extraction can also be used for learning and populating ontologies. Texts and pieces of texts can be annotated with extracted data. These metadata can serve as a bridge between the semantic portions of the web and the traditional web of unstructured data. LT is indispensable for the realisation of a semantic web.
 
LT can perform many other tasks in the processing of knowledge and information. It can sort, categorise, catalogue, and filter content and it can deliver the data for data mining in texts. LT can automatically connect web documents with meaningful hyperlinks and it can produce summaries of larger collections of texts. Opinion mining and sentiment analysis can find out what people think about products, personalities, or problems and analyse their feelings about such topics.

Another class of techniques is needed for connecting between different media in the multimedia content of the web. Some of the needed tasks are annotating pictures, videos, and sound recordings with metadata, interlinking multimedia files with texts, semantic linking and searching in films and video content, and cross-media analytics, including cross-media summarisation.
 
In the next few years we will see considerable advances for all these techniques. For large parts of research and application development, language processing and knowledge processing will merge. The most dramatic innovations will draw from progress in multiple subfields. The predicted and planned use of language and knowledge technologies for social intelligence applications, one of our three priority areas, will involve text and speech analytics, translation, summarisation, opinion mining, sentiment analysis, and several other technologies. If the planned massive endeavour in this direction can be realised, it will not only result in a new quality of collective decision-making in business and politics. In 2020, LT will enable forms of knowledge evolution, knowledge transmission, and knowledge exploitation that speed up scientific, social, and cultural development. The effects for other knowledge-intensive application areas such as business intelligence, scientific knowledge discovery, and multimedia production will be immense.

\subsection{Learning Language}
\label{sec:learning-language}

Soon almost every citizen on Earth will learn a second language, many will learn a third. A few will go beyond this by acquiring additional languages. Learning a language after the period of early childhood is hard. It is very different from acquiring scientific knowledge because it requires repetitious practicing by actual language use. The more natural the use, the more effective the practice is.
 
IT products that help to ease and speed up language learning have a huge market. Already today, the software market for computer-assisted language learning (CALL) is growing at a fast rate. While current products are helpful complements to traditional language instruction, they are still limited in functionality because the software cannot reliably analyse and critique the language produced by the learner. This is true for written language and even more so for spoken utterances. Software producers are trying to circumvent the problem by greatly restricting the expected responses of the user, something that helps for many exercises, but it still rules out the ideal interactive CALL application: an automatic dialogue partner ready around the clock for error-free conversation on many topics. Such software would analyse and critique the learner’s errors and adapts its dialogue to the learner’s problems and progress. LT cannot yet provide such functionality.
 
This lack of flexibility is the reason why research on CALL applications has not yet come into full bloom. As research on language analysis, understanding and dialogue systems progresses, we predict a boom in this promising and commercially attractive application area. Research toward the missing technologies is covered by our priority themes. We expect a strong increase in CALL research between 2015 and 2020.

\subsection{Learning Through Language}
\label{sec:learn-thro-lang}

Since most K-12, academic, and vocational instruction happens through language, spoken in classroom and read in textbooks, LT can and will play a central role in learning. Currently LT is already applied at a few places in the preparation of multiple-choice tests and in the assessment of learners’ essays. As soon as dialogue systems can robustly conduct nearly error-free dialogues based on provided knowledge, research can design ideal tutoring systems. But long before LT research will reach this point, we will be able to create systems that test for knowledge by asking questions and that provide knowledge to the learner by answering questions. Thus even adaptive loops of analytic knowledge diagnosis and customised knowledge transmission as they form the core of an effective learning system will become possible through LT. Knowledge structuring and question answering is covered by our priority themes. The transfer to research and development toward educational applications should happen through close cooperation with the active research scene in e-learning. We predict that e-learning technology will have become much more effective and learner-friendly by that time through the integration of advanced LT.

\addtocontents{toc}{\protect\pagebreak}

\subsection{Creative Contents and Creative Work}
\label{sec:lt-creative-contents}

A major cost issue for European tv and film production is subtitling and dubbing \cite{eurobarometer2011}. Whereas some countries with multiple official languages or with strict legislation mandating subtitling or sign-language display have a long tradition in providing these services, producers in many other countries still leave all subtitling and dubbing to importing distributors or media partners. With a single digital market, the increase in productions for multiple language communities, and with the strengthening of inclusion policies \cite{medier12}, the demand for fast and cost-effective subtitling and dubbing will grow significantly.

The automatic translation of subtitles is easier than the translation of newspaper articles because of shorter and simpler sentences in spoken language. Some commercial services have already started using machine translation for subtitles and audio description. If monolingual subtitling becomes the norm demanded by law, automated subtitle translation could be deployed at large scale.
 
Open challenges are the automatic production of sign-language translations and dubbing. Especially automatic dubbing will be a hard task since it requires the interpretation of the intonation in the source language, the generation of the adequate intonation in the target language, and finally lip synchronisation. An easier method would be automatic voice-over. In 2020 we will see wide use of automatic subtitling and first successful examples of automatic voice over for a few languages.
 
Language can also be a medium for creative work. In fine arts, creation mainly happens by a direct production of visual objects or images in two or three-dimensional space through drawing, constructing, painting, or photographing. In creative writing, the creation happens in language. In many other areas of creative work, the creation happens \emph{through} languages, ranging from musical notation to programming languages. Here the created work is specified in some suitable notation. Often natural language is used, for instance in the formulation of scripts for movies or in the design of processes or services.

In computer science, the idea of writing programmes in natural language is as old as programming itself. This approach would require the translation of natural language into a programming language. However, the inherent ambiguity, vagueness and richness of natural language has remained a major problem. Computer scientists have created a number of easily learnable scripting languages, whose syntax resembles simple sentence structures of English. We expect that the concept of programming in natural language will bear fruit through progress in the semantic interpretation of natural language with respect to formal ontologies.  The ontology-based interpretation of natural language statements will also permit the specification of processes, services, and objects which will then be translated into formal descriptions and finally into actions, models, workflows or physical objects. By 2020 we can expect examples of natural language scripting and specification in a few application areas.

\subsection{Diagnosis and Therapy}
\label{sec:diagnosis-therapy}

Psychological and medical conditions affecting language are among the most severe impairments from which people can suffer. Deficiencies in language can also be strong indicators for other conditions that are harder to detect directly, such as damage to the brain, nerves, or articulatory system. LT has been utilised for diagnosing the type and extent of brain damage after strokes. Since diagnosis and therapy are time critical for successful recovery of brain functions, software can support the immediate detection and treatment of stroke effects. Language technology can also be applied to the diagnosis and therapy of aphasia resulting from causes other than strokes, e.\,g., from infections or physical injuries.

Another application area is the diagnosis and therapy of innate or acquired speech impairments, especially in children. Dyslexia is a widespread condition affecting skills in reading and orthography. Some effects of dyslexia can be greatly reduced by appropriate training methods. Recent advances in the development of software for the therapy of dyslexia give rise to the hope that specialised CALL systems for different age groups and types of dyslexia will help to treat this condition early and effectively.
 
Technologies for augmentative alternative communication can perform an important function in therapy since any improvement of communication for language-impaired patients opens new ways for the treatment of causal or collateral conditions. Expected progress in LT, together with advances in miniaturisation and prosthetics, will open new ways for helping people who cannot naturally enjoy the benefits of communication.

\subsection[Language Technology as a Key-Enabling Technology]{LT as a Key-Enabling Technology}
\label{sec:lang-techn-as-key-enabling-technology}

The wide range of novel or improved applications in our shared vision represent only a fragment of the countless opportunities for LT to change our work and everyday life. Language-proficient technology will enable or enhance applications wherever language is present. It will change the production, management, and use of patents, legal contracts, medical reports, recipes, technical descriptions, and scientific texts, and it will permit many new voice applications such as automatic services for the submission of complaints and suggestions, for accepting orders, and for counselling in customer-care, e-government, education, community services, etc.   

With so many applications and application areas, we may be tempted to doubt that there is a common technology core. And indeed there has been a trend of excessive diversification in LT software development and many tools can only be used for only one purpose. This limitation is different from the way humans learn their language: once we have learned our mother tongue we can easily obtain new skills, always employing the core knowledge acquired during childhood. We learn to read, write, skim texts, summarise, outline, proof-read, edit, and translate.
 
Currently we are witnessing a promising trend in LT giving rise to hope for faster progress. Instead of relying on highly specialised components, powerful core technologies are reused for many applications. We can now compose lists of components and tools that we need for every language since these will be adapted for and integrated into many applications. In addition, we have also identified lists of core data (such as text and speech corpora) and language descriptions (such as lexicons, thesauri and grammars) needed for a wide spectrum of purposes.

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.71\textwidth]{../_media/LT-maturity}
  \caption{By the year 2020, Language Technology will have become a key enabling technology}
  \label{fig:lt-in-2020}
\end{figure*}

In IT we can differentiate between application technologies, such as credit-card readers, and enabling technologies, such as microprocessors, that are needed for multiple types of applications. In hardware technology, certain key-enabling technologies have been identified. These are indispensable for projected essential progress (e.\,g., nanotechnology, microelectronics and semiconductors, biotechnology). Similar key-enabling technologies exist on the software side, such as database technology or network technology. Considering the broad range of LT-enabled applications and their potential impact on business and society, LT is certainly becoming a key enabling technology for future generations of IT (see Figure~\ref{fig:lt-in-2020}). In contrast to some of the other key enabling technologies listed above, Europe has not yet lost a leadership role in the field. There is no reason to be discouraged or even paralysed by the strong evidence of interest and expertise on the side of major commercial players in the US. In software markets the situation can change fast.

If Europe does not take a decisive stand for a substantial commitment to LT research and innovation in the years to come, we may as well give up any ambition in the future of IT altogether because there is no other software sector in which European research can benefit from a similar combination of existing competitive competence, recognised economic potential, acknowledged societal needs, and determined political obligation toward our unique wealth of languages.
\end{multicols}

\clearpage

%\addtocontents{toc}{\protect\pagebreak}

% --------------------------------------------------------------------------

\ssection[Language Technology 2020: Priority Research Themes]{Language Technology 2020:\newline The META-NET Priority Research Themes}
\label{sec:pts}

\begin{multicols}{2}
\subsection{Introduction}
\label{sec:pt-introduction}

For decades it has been obvious that one of the last remaining frontiers of IT is still separating our rapidly evolving technological world of mobile devices, computers and the internet from the most precious and powerful asset of mankind, the human mind, the only system capable of thought, knowledge and emotion. Although we use computers to write, telephones to chat and the web to search for knowledge, IT has no direct access to the meaning, purpose and sentiment behind our trillions of written and spoken words. This is why technology is unable to summarise a text, answer a question, respond to a letter and to translate reliably. In many cases it cannot even correctly pronounce a simple English sentence.

Visionaries such as Ray Kurzweil, Marvin Minsky and Bill Gates have long predicted that this border would eventually be overcome by artificial intelligence including language understanding whereas science fiction such as the Star Trek TV series suggested attractive ways in which technology would change our lives, by establishing the fantastic concept of an invisible computer that you have a conversation with and that is able to react to the most difficult commands and also of technology that can reliably translate any human and non-human language.

Many companies had started much too early to invest in language technology research and development and then lost faith after a long period without any tangible progress. During the years of apparent technological standstill, however, research continued to conquer new ground. The results were a deeper theoretical understanding of language, better machine-readable dictionaries, thesauri and grammars, specialised efficient language processing algorithms, hardware with increased computing power and storage capacities, large volumes of digitised text and speech data and new methods of statistical language processing that could exploit language data for learning hidden regularities governing our language use.

We do not yet possess the complete know-how for unleashing the full potential of language technology as essential research results are still missing. Nevertheless, the speed of research keeps increasing and even small improvements can already be exploited for innovative products and services that are commercially viable. We are witnessing a chain of new products for a variety of applications entering the market in rapid succession.

These applications tend to be built on dedicated computational models of language processing that are specialised for a certain task. People, on the other hand, apply the basic knowledge of the language they have acquired during the first few years of their socialisation, throughout their lives to many different tasks of varying complexity such as reading, writing, skimming, summarising, studying, editing, arguing, teaching. They even use this knowledge for the learning of additional languages. After people have obtained proficiency in a second language, they can already translate simple sentences more fluently than many machine translation systems, whereas truly adequate and stylistically acceptable translation is a highly skillful art gained by special training.

Today, no text technology software can translate and check for grammatical correctness and no speech technology software could recognise all the sentences it can read aloud if they were spoken by people in their normal voices. But increasingly we observe a reuse of core components and language models for a wide variety of purposes. It started with dictionaries, spell checkers and text-to-speech tools. Google Translate, Apple's Siri and IBM Watson still do not use the same technologies for analysing and producing language, because the generic processing components are simply not powerful enough to meet their respective needs. But many advanced research systems already utilise the same tools for syntactic analysis. This process is going to continue.

In ten years or less, basic language proficiency is going to be an integral component of any advanced IT. It will be available to any user interface, service and application development. Additional language skills for semantic search, knowledge discovery, human-technology communication, text analytics, language checking, e-learning, translation and other applications will employ and extend the basic proficiency. The shared basic language competence will ensure consistency and interoperability among services. Many adaptations and extensions will be derived and improved through sample data and interaction with people by powerful machine learning techniques.

In the envisaged big push toward realising this vision by massive research and innovation, the technology community is faced with three enormous challenges:

\begin{enumerate}
\item \emph{Richness and diversity.} A serious challenge is the sheer number of languages, some closely related, others distantly apart. Within a language, technology has to deal with numerous dialects, sociolects, registers, professional jargons, genres and slangs.
\item \emph{Depth and meaning.} Understanding language is a complex process. Human language is not only the key to knowledge and thought, it also cannot be interpreted without certain shared knowledge and active inference. Computational language proficiency needs semantic technologies.
\item \emph{Multimodality and grounding.} Human language is embedded in our daily activities. It is combined with other modes and media of communication. It is affected by beliefs, desires, intentions and emotions and it affects all of these. Successful interactive language technology requires models of embodied and adaptive human interaction with people, technology and other parts of the world.
\end{enumerate}
 
It is fortunate for research and economy that the only way to effectively tackle the three challenges involves submitting the evolving technology continuously to the growing demands and practical stress tests of real world applications. Google's Translate, Apple's Siri, Autonomy's text analytics and scores of other products demonstrate that there are plenty of commercially viable applications for imperfect technologies. Only a continuous stream of technological innovation can provide the economic pull forces and the evolutionary environments for the realisation of the grand vision. 

In the remainder of the Chapter, we propose five major action lines of research and innovation:

\begin{itemize}
\item Three priority themes connected with powerful application scenarios that can drive research and innovation. These will demonstrate novel technologies in attractive show-case solutions of high economic and societal impact. They will open up numerous new business opportunities for European language-technology and -service providers.
\item A steadily evolving system of shared, collectively maintained interoperable core technologies and resources for the languages of Europe and selected economically relevant languages of its partners. These will ensure that our languages will be sufficiently supported and represented in the next generations of IT.
\item A pan-European language technology service platform for supporting research and innovation by testing and showcasing research results, integrating various services even including professional human services will allow SME providers to offer component and end-user services, and share and utilise tools, components and data resources. 
\end{itemize}

The three priority research themes are:

\begin{itemize}
\item \textbf{Translingual Cloud} -- generic and specialised federated cloud services for instantaneous reliable spoken and written translation among all European and major non-European languages.
\item \textbf{Social Intelligence} -- understanding and dialogue within and across communities of citizens, customers, clients and consumers to enable e-participation and more effective processes for preparing, selecting and evaluating collective decisions.
\item \textbf{Socially Aware Interactive Assistants} -- socially aware assistants that learn and adapt and that provide proactive and interactive support tailored to specific situations, locations and goals of the user through verbal and non-verbal multimodal communication.
\end{itemize}

These priority themes have been designed with the aim of turning our vision into reality and to letting Europe benefit from a technological revolution that will overcome barriers of understanding between people of different languages, between people and technology and between people and the knowledge of mankind. The themes connect societal needs with LT applications and roadmaps for the organisation of research, development and innovation. The priority themes cover the main functions of language: storing, sharing and using of information and knowledge, as well as improving social interaction among humans and enabling social interaction between humans and technology. As multilingualism is at the core of European culture and becoming a global norm, one theme is devoted to overcoming language barriers. 

The three themes have been thoughtfully selected in a complex process (see Appendix~\ref{vision-evolution} on p.~\pageref{vision-evolution}\,ff.) to ensure the needed market pull, the appropriate performance demands, the realistic testing environments and a sufficient level of public interest. The priority themes represent a mix of applications with respect to the various user communities such as small businesses, large enterprises, public administration and the public at large.

\subsection{Priority Theme 1: Translingual Cloud}
\label{sec:priority-theme-1-translation-cloud}

\subsubsection{Solutions for the EU Society}
\label{sec:solutions-eu-society-pt1}

The goal is a multilingual European society, in which all citizens can use any service, access all knowledge, enjoy all media and control any technology \emph{in their mother tongues}. This will be a world in which written and spoken communication is not hindered anymore by language barriers and in which even specialised high-quality translation will be affordable.
 
The citizen, the professional, the organisation, or the software application in need of cross-lingual communication will use a single, simple access point for channelling text or speech through a gateway that will instantly return the translations into the requested languages in the required quality and desired format.
 
Behind this access point will be a network of generic and special-purpose services combining automatic translation or interpretation, language checking, post-editing, as well as human creativity and quality assurance, where needed, for achieving the demanded quality. For high-volume base-line quality the service will be free for use but it will offer extensive business opportunities for a wide range of service and technology providers.

Selected components of this ubiquitous service are:

\begin{itemize}
\item use and provision platform for providers of computer-supported top-quality human translation, multilingual text authoring and quality assurance by experts
\item trusted service centres: certified service providers fulfilling highest standards for privacy, confidentiality and security of source data and translations
\item quality upscale models: services permitting instant quality upgrades if the results of the requested service levels do not yet fulfil the quality requirements
\item domain, task and genre specialisation models
\item translingual spaces: dedicated locations for ambient interpretation. Meeting rooms equipped with acoustic technology for accurate directed sound sensoring and emission
\end{itemize}

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.85\textwidth]{../_media/PT1}
  \caption{Priority Research Theme 1: Translingual Cloud}
  \label{fig:pt1-overview}
\end{figure*}

\subsubsection{Novel Research Approaches and Targeted Breakthroughs}
\label{sec:novel-rese-appr-pt1}

The main reason why high-quality machine translation (HQMT) has not been systematically addressed yet seems to be the Zipfian distribution of issues in MT: some improvements, the “low-hanging fruit”, can be harvested with moderate effort in a limited amount of time. Yet, many more resources and a more fundamental, novel scientific approach -- that eventually runs across several projects and also calls -- are needed for significant and substantial improvements that cover the phenomena and problems that make up the Zipfian long tail. This is an obstacle in particular for individual research centres and SMEs given their limited resources and planning horizon. Although recent progress in MT has already led to many new applications of this technology, radically different approaches are needed to accomplish the ambitious goal of this research including a true quality breakthrough. Among these new research approaches are:

\begin{itemize}
\item Systematic concentration on quality barriers, i.\,e., on obstacles for high quality
\item A unified dynamic-depth weighted-multidimensional quality assessment model with task profiling
\item Strongly improved automatic quality estimation
\item Inclusion of translation professionals and enterprises in the entire research and innovation process
\item Improved statistical models that go beyond the current ones and extract more dependencies from the data
\item Ergonomic work environments for computer-supported creative top-quality human translation and multilingual text authoring
\item Semantic translation paradigm by extending statistical translation with semantic data such as linked open data, ontologies including semantic models of processes and textual inference models
\item Exploitation of strong monolingual analysis and generation methods and resources
\item Modular combinations of specialised analysis, generation and transfer models, permitting accommodation of registers and styles (including user-generated content) and also enabling translation within a language (e.\,g., between specialists and laypersons).
\end{itemize}

The expected breakthroughs will include:

\begin{itemize}
\item High-quality text translation and reliable speech translation (including a modular analysis-transfer-generation translation technology that facilitates reuse and constant improvement of modules)
\item Seemingly creative translation skills by analogy-driven transfer models
\item Automatic subtitling and voice over of films
\item Ambient translation
\end{itemize}

\begin{figure*}[htbp]
  \centering
  \small
  \begin{tabular}{@{}p{2.5cm}p{4cm}p{4cm}p{4cm}@{}} \toprule\addlinespace
    \multicolumn{1}{c}{Research Priority} & \multicolumn{1}{c}{Phase 1: 2013-2014} & \multicolumn{1}{c}{Phase 2: 2015-2017} & \multicolumn{1}{c}{Phase 3: 2018-2020} \\ \addlinespace\midrule\addlinespace
    Immediate affordable translation in any needed quality level (from sufficient to high) & Development of necessary monolingual language tools (analysis, generation) driven by MT needs; exploitation of novel ML techniques for MT purposes, using large LR and semantic resources, including Linked Open Data and other naturally occuring semantic and knowledge  resources (re-purposing for MT and NLP use); experiment with novel metrics, automated, human-centered, or hybrid; use EU languages, identify remaining gaps (LR resources, tools) & Concentrate on HQMT systems using results of Phase 1; deepen development of MT-related monolingual tools; employ novel techniques aimed at HQMT, combination of systems, domain adaptation, cross-language adaptation; develop showcases for novel translation workflow; use novel metrics identified as correlated with the aims of HQMT; continue development on EU languages, identify needs for non-EU languages (MT-related) and their gaps & Deployment of MT systems in particular applications requiring HQMT, such as technology export, government and public information systems, private services, medical applications etc., using novel translation workflows where appropriate; application- and user-based evaluation driven engagement of core and supplemental technologies; coverage of EU languages and other languages important for EU business and policy \\ \addlinespace
    Delivering multi-media content in any language (captioning, subtitling, dubbing) & Multi-media system prototypes, combining language, speech, image and video analysis; employing novel techniques (machine learning, cross-fertilisation of features across media types); targeted evaluation metrics for system quality assessment related to MT; aimed at EU languages with sufficient resources; data collection effort to support multi-media analysis & Prototype applications in selected domains, such as public service (parliament recordings, sports events, legal proceedings) and other applications (tv archives or movie delivery, online services at content providers); continued effort at multimedia analysis, adding languages as resources become available & Deployment of large-scale applications for multi-media content delivery, public and/or private, in selected domains; development of online services for captioning, subtitling, dubbing, including on-demand translation); new languages for outside-of-the-EU delivery, continued improvement of EU languages \\ \addlinespace
Cross-lingual knowledge management and linked open data & Publication of multilingual language resources as linked open data as well as linking of resources across languages; develop ontology translation components that can localise ontologies and linked datasets to different languages & Develop an ecosystem of NLP tools and services that leverage the existing multilingual resources on linked open data; develop new generation of MT technology that can profit from semantic data and linked open data & Develop methods that allow querying linked open data in different languages \\ \addlinespace
Content analytics & \dots & \dots & \dots \\ \addlinespace
Synchronous and asynchronous interpretation & \dots & \dots & \dots \\ \addlinespace
Translingual collaborative spaces & \dots & \dots & \dots \\ \addlinespace\bottomrule
  \end{tabular}
  \caption{Priority Theme 1 -- Translingual Cloud: Preliminary Roadmap}
  \label{fig:pt1-roadmap}
\end{figure*}

\subsubsection{Solution and Realisation}
\label{sec:solut-techn-real-pt1}

The envisaged technical solutions will benefit from new trends in IT such as software as a service, cloud computing, linked open data and semantic web, social networks, crowd-sourcing etc. For MT, a combination of translation brokering on a large scale and translation on demand is promising. The idea is to streamline the translation process such that it becomes simpler to use and more transparent for the end user, and at the same time respects important factors such as subject domain, language, style, genre, corporate requirements and user preferences. Technically, what is required is maximum interoperability of all components (corpora, processing tools, terminology, knowledge, maybe even pre-trained translation models) and a cloud or server/service farm of specialised language technology services for different needs (text and media types, domains, etc.) offered by SMEs, large companies or research centres.

A platform has to be designed and implemented for the resource and evaluation demands of large-scale collaborative MT research. An initial inventory of language tools and resources as well as extensive experience in shared tasks and evaluation has been obtained in several EU-funded projects. Together with LSPs, a common service layer supporting research workflows on HQMT must be established. As third-party (customer) data is needed for realistic development and evaluation, intellectual property rights and legal issues must be taken into account from the onset. The infrastructures to be built include:

\begin{itemize}
\item Service clouds with trusted service centres
\item Interfaces for services (APIs)
\item Workbenches for supporting creative translations
\item Novel translation workflows (and improved links to content production and authoring)
\item Showcases such as ambient and embedded translation
\end{itemize}

\subsubsection{Impact}
\label{sec:impact-pt1}

HQMT in the cloud will ensure and extend the value of the digital information space in which everyone can contribute in her own language and be understood by members of other language communities. It will assure that diversity will no longer be a challenge, but a welcome enrichment for Europe both socially and economically. Based on the new technology, language-transparent web and language-transparent media will help realise a truly multilingual mode of online and media interaction for every citizen regardless of age, education, profession, cultural background, language proficiency or technical skills. Showcase applications areas are:

\begin{itemize}
\item Multilingual content production (media, web, technical, legal documents)
\item Cross-lingual communication, document translation and search
\item Real-time subtitling and translating speech from live events
\item Mobile interactive interpretation for business, social services, and security
\item Translation workspaces for online services
\end{itemize}

\subsubsection{Organisation of Research}
\label{sec:organ-rese-pt1}

Several very large cooperating and competing lead projects will share an infrastructure for evaluation, resources (data and base technologies), and communication. Mechanisms for reducing or terminating partner involvements and for adding new partners or subcontracted contributors should provide the needed flexibility. A number of smaller projects, including national and regional projects, will provide building blocks for particular languages, tasks, component technologies or resources. A special scheme will be designed for involving EC-funding, member states, industrial associations, and language communities.
 
Two major phases from 2015 to mid 2017 and from mid 2017 to 2020 are foreseen. Certain services such as multilingual access to web-information across European languages should be transferred to implementation and testing at end of phase 2017. Internet-based real-time speech translation for a smaller set of languages will also get into service at this time as well as HQMT for selected domains and tasks. A major mid-term revision with a thorough analytical evaluation will provide a possible breakpoint for replanning or termination.
 
A close cooperation of language technology and professional language services is planned. In order to overcome the quality boundaries we need to identify and understand the quality barriers. Professional translators and post-editors are required whose judgements and corrections will provide insights for the analytical approach and data for the bootstrapping methodology. The cooperation scheme of research, commercial services and commercial translation technology is planned as a symbiosis since language service professionals or advanced students in translation studies or related programmes working with and for the developing technology will at the same time be the first test users analytically monitored by the evaluation schemes. This symbiosis will lead to a better interplay of research and innovation.

Although the research strand will focus on advances in translation technology for innovation in the language and translation service sector, a number of other science, technology and service areas need to be integrated into the research from day one. Some technology areas such as speech technologies, language checking, authoring systems, analytics, generation and content management systems need to be represented by providers of state-of-the-art commercial products.
 
Supporting research and innovation in LT should be accompanied by policy making in the area of multilingualism, but also in digital accessibility. Overcoming language barriers can greatly influence the future of the EU. Solutions for better communication and for access to content in the users' native languages would reaffirm the role of the EC to serve the needs of the EU citizens. A connection to the infrastructure programme CEF could help to speed up the transfer of research results to badly needed services for the European economy and public.

At the same time, use cases should cover areas in which the European social and societal needs massively overlap with business opportunities to achieve funding investment that pays back, ideally public-private partnerships.
 
Concerted activities sharing resources such as error corpora or test suites and challenges or shared tasks in carefully selected areas should be offered to accelerate innovation breakthrough and market-readiness for urgently needed technologies.

\subsection[Priority Theme 2: Social Intelligence and e-Participation]{Priority Theme 2:\newline Social Intelligence and e-Participation}
\label{sec:priority-theme-2-social-intelligence}

\subsubsection{Solutions for the EU Society}
\label{sec:solutions-eu-society-pt2}

The central goal behind this theme is to use information technology and the digital content of the web for improving effectiveness and efficiency of decision-making in business and society. 
 
The quality, speed and acceptance of individual and collective decisions is the single main factor for the success of social systems such as enterprises, public services, communities, states and supranational organisations. The growing quantity and complexity of accessible relevant information poses a serious challenge to the efficiency and quality of decision processes. IT provides a wide range of instruments for intelligence applications. Business intelligence, military intelligence or security intelligence applications collect and pre-process decision-relevant information. Analytics programmes search the data for such information and decision support systems evaluate and sort the information and apply problem-specific decision rules. Although much of the most relevant information is contained in texts, text analytics programmes today only account for less than 1\% of the more than 10 billion US\$ business intelligence and analytics market. Because of their limited capabilities in interpreting texts, mainly business news, reports and press releases, their findings are still neither comprehensive nor reliable enough.
 
Social intelligence builds on improved text analytics methodologies but goes far beyond the analysis. One central goal is the analysis of large volumes of social media, comments, communications, blogs, forum postings etc.~of citizens, customers, patients, employees, consumers and other stakeholder communities. Part of the analysis is directed to the status, opinions and acceptance associated with the individual information units. As the formation of collective opinions and attitudes is highly dynamic, new developments need to be detected and trends analysed. Emotions play an important part in individual actions such as voting, buying, supporting, donating and in collective opinion formation, the analysis of sentiment is a crucial component of social intelligence.  
 
Social intelligence can also support collective deliberation processes. Today any collective discussion processes involving large numbers of participants are bound to become intransparent and incomprehensible rather fast. By recording, grouping, aggregating and counting opinion statements, pros and cons, supporting evidence, sentiments and new questions and issues, the discussion can be summarised and focussed. Decision processes can be structured, monitored, documented and visualised, so that joining, following and benefitting from them becomes much easier. The efficiency and impact of such processes can thus be greatly enhanced.
 
Since many collective discussions will involve participants in several countries, e.\,g., EU member states or enterprise locations, cross-lingual participation needs to be supported \cite{ombudsman2012}. Special support will also be provided for participants not mastering certain group-specific or expert jargons and for participants with disabilities affecting their comprehension.

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.85\textwidth]{../_media/PT2}
  \caption{Priority Research Theme 2: Social Intelligence and e-Participation}
  \label{fig:pt1-overview}
\end{figure*}

\subsubsection{Novel Research Approaches and Targeted Breakthroughs}
\label{sec:novel-rese-appr-pt2}

A key enabler will be language technologies that can map large, heterogeneous, and, to a large extent, unstructured volumes of online content to actionable representations that support decision making and analytics tasks. Such mappings can range from the relatively shallow to the relatively deep, encompassing for example coarse-grained topic classification at the document or paragraph level or the identification of named entities, as well as in-depth syntactic, semantic and rhetorical analysis at the level of individual sentences and beyond (paragraph, chapter, text, discourse or sets of texts) or the resolution of co-reference or modality cues within and across sentences.

Language technologies such as, for example, information extraction, data mining, automatic linking and summarisation have to be made interoperable with modern knowledge representation approaches and semantic web methods such as ontological engineering. Drawing expertise from related areas such as knowledge management, information sciences, or social sciences is an important prerequisite to meet the challenge of modelling social intelligence, see \cite{ltds2012}. A new research approach should target the bottleneck of knowledge engineering by:

\begin{itemize}
\item Semantification of the web: bridging between the semantic parts and islands of the web and the traditional web containing unstructured data;
\item Merging and integrating textual data with social network and social media data, especially along the dimension of time;
\item Aligning and making comparable different genres of content like mainstream-news, social media (blogs, twitter, facebook etc.), academic texts, archives etc.;
\item Extracting semantic representations from social media content, i.\,e., creating representations for reasoning and inferencing;
\item Taking metadata and multimedia data into account.
\end{itemize}

The following list contains specific targeted breakthroughs to be sought in this scenario:

\begin{itemize}
\item Social intelligence by detecting and monitoring opinions, demands, needs and problems;
\item Detecting diversity of views, biases along different dimensions (e.\,g., demographic) etc.~including temporal dimension (i.\,e., modelling evolution of opinions);
\item Support for both decision makers and participants;
\item Problem mining and problem solving;
\item Support of collective deliberation and collective knowledge accumulation;
\item Vastly improved approaches to sentiment detection and sentiment scoring (going beyond the approach that relies on a list of positive and negative keywords);
\item Introducing genre-driven text and language-processing (different genres need to be processed differently);
\item Personalised recommendations of e-participation topics to citizens;
\item Proactive involvement in e-participation activities;
\item Understanding influence diffusion across social media (identifying drivers of opinion spreading);
\item More sophisticated methods for topic and event detection that are tightly integrated with the Semantic Web and Linked Open Data.
\item Modelling content and opinion flows across social networks;
\item Evaluation of methods by analytic/quantitative and sociological/qualitative means.
\end{itemize}

\subsubsection{Solution and Realisation}
\label{sec:solut-techn-real-pt2}

Individual solutions should be assembled from a repository of generic monolingual and cross-lingual language technologies, packaging state-of-the-art techniques in robust, scalable, interoperable, and adaptable components that are deployed across sub-tasks and sub-projects, as well as across languages where applicable (e.\,g., when the implementation of a standard data-driven technique can be trained for individual languages). These methods need to be combined with powerful analytical approaches that can aggregate all relevant data to support analytic decision making and develop new access metaphors and task-specific visualisations.
 
By robust we mean technologically mature, engineered and scalable solutions that can perform high-throughput analysis of web data at different levels of depth and granularity in line with the requirements of their applications. Technology should be able to work with heterogeneous sources, ranging from unstructured (arbitrary text documents of any genre) to structured (ontologies, linked open data, databases).

To accomplish interoperability we suggest a strong semantic bias in the choice and design of interface representations: to the highest degree possible, the output (and at deeper levels of analysis also input) specifications of component technologies should be interpretable semantically, both in relation to natural language semantics (be it lexical, propositional, or referential) and extra-linguistic semantics (e.\,g., taxonomic world or domain knowledge). For example, grammatical analysis (which one may or may not decompose further into tagging, syntactic parsing, and semantic role labelling) should make available a sufficiently abstract, normalised, and detailed output, so that downstream processing can be accomplished without further recourse to knowledge about syntax. Likewise, event extraction or fine-grained, utterance-level opinion mining should operate in terms of formally interpretable representations that support notions of entailment and, ultimately, inference.

Finally, our adaptability requirement on component technologies addresses the inherent heterogeneity of information sources and communication channels to be processed. Even in terms of monolingual analysis only, linguistic variation across genres (ranging from carefully edited, formal publications to spontaneous and informal social media channels) and domains (as in subject matters) often calls for technology adaptation, where even relatively mature basic technologies (e.\,g., part-of-speech taggers) may need to be customised or re-trained to deliver satisfactory performance. Further taking into account variation across downstream tasks, web-scale language processing typically calls for different parameterisations and trade-offs (e.\,g., in terms of computational cost vs.~breadth and depth of analysis) than an interactive self-help dialogue scenario. For these reasons, relevant trade-offs need to be documented empirically, and component technologies accompanied with methods and tools for adaptation and cost-efficient re-training, preferably in semi- and un-supervised settings.
 
The technical solutions needed include:

\begin{itemize}
\item Technologies for decision support, collective deliberation and e-participation.
\item A large public discussion platform for Europe-wide deliberation on pressing issues such as energy policies, financial system, migration, natural disasters, etc.
\item Visualisation of social intelligence-related data and processes for decision support (for politicians, health providers, manufacturers, or citizens).
\item High-throughput, web-scale content analysis techniques that can process multiple different sources, ranging from unstructured to completely structured, at different levels of granularity and depth by allowing to trade-off depth for efficiency as required.
\item Mining e-participation content for recommendations, summarisation and proactive engagement of less active parts of population.
\item Detection and prediction of events and trends from content and social media networks.
\item Extraction of knowledge and semantic integration of social content with sensory data and mobile devices (in near-real-time).
\item Cross-lingual technology to increase the social reach and approach cross-culture understanding.
\end{itemize}

We suggest to structure the research along at least the six lines shown in Figure~\ref{fig:pt2-roadmap}.

\begin{figure*}[htb]
  \centering
  \small
  \begin{tabular}{@{}p{2.5cm}p{4cm}p{4cm}p{4cm}@{}} \toprule\addlinespace
    \multicolumn{1}{c}{Research Priority} & \multicolumn{1}{c}{Phase 1: 2013-2014} & \multicolumn{1}{c}{Phase 2: 2015-2017} & \multicolumn{1}{c}{Phase 3: 2018-2020} \\ \addlinespace\midrule\addlinespace
    Social influence and incentives & Modelling social diversity of views across languages and cultures & Modelling social influence and incentives  through game theoretic approaches using data from texts and social networks & Holistic modelling of society (or its segments) through observing a variety of data sources \\ \addlinespace
    Information tracking & Tracking dynamics of information diffusion across languages, cultures and media & Transforming textual and social network streams into actionable deep knowledge representations & Prediction of future events and identification of causal relationships from textual and social streams \\ \addlinespace
    Multimodal data processing & Joining textual data and social networks, including spatial and temporal dimensions & Joining textual and social data with unstructured sources like sensor data (smart cities), video, images, audio & Detecting inconsistencies, gaps and completeness of collected knowledge from textual and social sources \\ \addlinespace
    Visualisation and user interaction & Visualisation of textual and social dynamics & Adaptive human-computer interfaces boosting specific aims in interaction & Adaptive interaction systems for communication with the whole or parts of society \\ \addlinespace
    High-throughput analysis & Scalable processing of multi-modal data (Big Data) & Real-time modelling and reasoning on massive textual and social streams & Algorithms and toolkits being able to deal with global scale analytics and reasoning with multimodal data \\ \addlinespace
    Knowledge-driven text analysis & Develop named-entity taggers that scale to entities described in linked open data resources; develop methods that exploit linked open data for improved disambiguation. & Develop a new generation of information extraction tools that are able to reliably extract from texts all semantic relations defined in, e.\,g., DBPedia & NLP systems are able to deal with linked open data and Semantic Web ontologies to analyse text at the meaning level and draw appropriate inferences \\  \addlinespace\bottomrule
  \end{tabular}
  \caption{Priority Theme 2 -- Social Intelligence and e-Participation: Preliminary Roadmap}
  \label{fig:pt2-roadmap}
\end{figure*}

\subsubsection{Impact}
\label{sec:impact-pt2}

The 21st century presents us with multiple challenges including efficient energy consumption, global warming and financial crises. It is obvious that no single individual can provide answers to challenging problems such as these, nor will top-down imposed measures find social acceptance as solutions. Language technology will enable a paradigm shift in transnational public deliberation. The European Ombudsman recently realised \cite{ombudsman2012} that there are problems and gaps in the way public debates and consultation are usually held in Europe -- language technology can improve the situation altogether and bring about a paradigm shift in that regard.
 
The applications and technologies discussed in this section will change how business adapts and communicates with their customers. It will increase transparency in decision-making processes, e.\,g., in politics and at the same time give more power to the citizen. As a by-product, the citizens are encouraged to become better informed in order to make use of their right to participate in a reasonable way. Powerful analytical methods will help European companies to optimise marketing strategies or foresee certain developments by extrapolating on the basis of current trends. Leveraging social intelligence for informed decision making is recognised as crucial in a wide range of contexts and scenarios:

\begin{itemize}
\item Organisations will better understand the needs, opinions, experiences, communication patterns, etc.~of their actual and potential customers so that they can react quickly to new trends and optimise their marketing and customer communication strategies.
\item Companies will get the desparately needed instruments to exploit the knowledge and expertise of their huge and diverse workforces, the wisdom of their own crowds, which are the most highly motivated and most closely affected crowds.
\item Political decision makers will be able to analyse public deliberation and opinion formation processes in order to react swiftly to ongoing debates or important, sometimes unforeseen events.
\item Citizens and customers get the opportunity (and necessary information) to participate and influence political, economic and strategic decisions of governments and companies, ultimately leading to more transparency of decision processes.
\end{itemize}

Thus, leveraging collective and social intelligence in developing new solutions to these 21st century challenges seems a promising approach in such domains where the complexity of the issues under discussion is beyond the purview of single individuals or groups.

The research and innovation will provide technological support for emerging new forms of issue-based, knowledge-enhanced and solution-centred participatory democracy involving large numbers of expert- and non-expert stakeholders distributed over large areas, using multiple languages. At the same time the resulting technologies will be applicable to smaller groups and also interpersonal communication as well, even though different dynamics of information exchange can be foreseen.

The research to be carried out and technologies to be developed in this priority theme will also have a big influence on the Big Data challenge and how we will make sense of huge amounts of data in the years to come. What we learn from processing language is the prime tool for processing the huge and intractable data streams that we will be confronted with in the near future.

\subsubsection{Organisation of Research}
\label{sec:organ-rese-pt2}

Research in this area touches upon political as well as business interests and at the same time is scalable in reach from the regional to the European scale. Therefore, it is necessary to identify business opportunities and potential impact for society at different levels and to align EU level research with efforts on the national level. Furthermore, this priority theme calls for large-scale, incremental, and sustained development and innovation across multiple disciplines (especially language technology and semantic technologies) and, within each community, a certain degree of stacking and fusion of approaches. Therefore, research organisation needs to create strong incentives for early and frequent exchange of technologies among all players involved. A marketplace for generic component technologies and a service-oriented infrastructure for adaptation and composition must be created, to balance performance-based steering and self-organisation among clusters of contributing players. In this ecosystem of technology providers and integrators, component uptake and measurable contributions against the targeted breakthrough of the priority theme at large should serve as central measures of success.

\subsection{Priority Theme 3: Socially Aware Interactive Assistants}
\label{sec:priority-theme-3-interactive-assistant}

\subsubsection{Solutions for the EU Society}
\label{sec:solutions-eu-society-pt3}

Socially aware interactive assistants are conversational agents. Their socially-aware behaviour is a result of combining analysis methods for speech, non-verbal and semantic signals.

Now is the time to develop and make operational socially aware, multilingual assistants that support people interacting with their environment, including human-computer, human-artificial agent (or robot), and computer-mediated human-human interaction. The assistants must be able to act in various environments, both indoor (such as meeting rooms, offices, appartments), outdoor (streets, cities, transportation, roads) and virtual environments (such as the web, virtual worlds, games), and also be able to communicate, exchange information and understand other agents' intentions. They must be able to adapt to the user's needs and environment and have the capacity to learn incrementally from all interactions and other sources of information.
 
The ideal socially aware multilingual assistant can interact naturally with humans, in any language and modality. It can adapt and be personalised to individual communication abilities, including special needs (for the visual, hearing, or motor impaired), affections, or language proficiencies. It can recognise and generate speech incrementally and fluently. It is able to assess its performance and recover from errors. It can learn, personalise itself and forget. It can assist in language training and education, and provide synthetic multimedia information analytics. It recognises people’s identity, and their gender, language or accent. If the agent is embodied in a robot, it can move, manipulate objects, and interact with people.

This priority theme includes several core components:

\begin{itemize}
\item Interacting naturally with humans (in communication, education, games, etc.) in an implicit (proactive) or explicit (spoken dialogue and/or gesticulation) manner based on robust analysis of human user identity, age, gender, verbal and nonverbal behaviour, and social context;
\item Using language in connection with other communication modalities (visual, tactile, haptic);
\item Conscious of its capabilities and self-learning;
\item Exhibiting robust performance everywhere (indoor/outdoor, augmented reality);
\item Overcoming handicap obstacles by means of suitable technologies (sign language understanding, assistive applications, etc.);
\item Interacting naturally with and in groups (in social networks, with humans or artificial agents/robots);
\item Exhibiting multilingual proficiency (speech-to-speech translation, interpretation in meetings and videoconferencing, cross-lingual information access);
\item Referring to written support (transcription, close-captioning, reading machines, ebooks);
\item Providing access to knowledge (answers to questions, shared knowledge in discussion);
\item Providing personalised training (computer-assisted language learning, e-learning).
\end{itemize}

Initial steps in the right direction have already been taken -- again, by US companies. Apple's intelligent assistant Siri is available on the iPhone, Google's interactive speech technologies can be used on Android and iOS devices. Recently, Microsoft announced -- in a letter sent to shareholders by Microsoft CEO Steve Ballmer -- that it wants to focus on the development of ``new form factors that have increasingly natural ways to use them including touch, gestures and speech''. Analysing this announcement, user interface expert Bill Meisel ``never expected to see mentions of natural user interfaces and machine learning in a short message to shareholders by the CEO of one of the largest companies in the U.S. Their mention as focus areas suggests that areas once viewed as leading-edge technology have achieved mainstream importance, to the degree that their successful deployment can impact the future of a major company.'' \cite{meisel12}. Meisel concludes that all three companies (Apple, Google, Microsoft) are currently ``developing integrated ecosystems that can tightly couple our human intelligence with computer intelligence across a range of products. And they have the budgets to make it happen.'' Again, Europe has to ask itself the question if we want to leave this huge field to three US companies or if the combined expertise of our continent's language technology experts is better suited to build interactive, socially aware assistants for the speakers and users of our many different languages and cultures.

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.85\textwidth]{../_media/PT3}
  \caption{Priority Research Theme 3: Socially Aware Interactive Assistants}
  \label{fig:pt1-overview}
\end{figure*}

\subsubsection{Novel Research Approaches and Targeted Breakthroughs}
\label{sec:novel-rese-appr-pt3}

In addition to significantly improving core speech and language technologies, the development of socially aware interactive assistants requires several research breakthroughs. With regard to speech recognition, accuracy (open vocabulary, any speaker) and robustness (noise, cross-talking, distant microphones) have to be improved. Methods for self-assessment, self-adaptation, personalisation, error-recovery, learning and forgetting information, and also for moving from recognition to understanding have to be developed. Concerning speech synthesis, voices have to be made more natural and expressive, control parameters have to be included for linguistic meaning, speaking style, emotion etc. They also have to be equipped with methods for incremental conversational speech, including filled pauses and hesitations. Likewise, speech recognition, synthesis and understanding have to be integrated, including different levels of evaluation and different levels of automated annotation.

Human communication is multimodal (including speech, facial expressions, body gestures, postures, etc.), crossmodal and fleximodal: it is based on pragmatically best suited modalities. Semantic and pragmatic models of human communication have to be developed. These have to be context-aware and model situational inter-depedencies between context and modalities for arriving at robust communication analysis (multimodal content analytics, infering knowledge from multiple sensory modalities). They have to be able to detect and recover interactively from mistakes, learning continuously and incrementally. Parsing has to model temporal inter-dependencies within and between modalities in order to maximise the assistant's human-communication-prediction ability. In order to be able to design technologies, adequate semantically and pragmatically annotated language and multimodal resources have to be produced.

A common push has to be made towards more natural dialogue. This includes, among others, the recognition and production of paralinguistics (prosody, visual cues, emotion) and a better understanding of socio-emotional functions of communicative behaviour, including group dynamics, reputation and relationship management. More natural dialogue needs more advanced dialogue models that are proactive (not only reactive), that are able to detect that recognised speech is intended as a machine command, they have to be able to interpret silence as well as direct and indirect speech acts (including lies and humour). Another prerequisite for more natural dialogue is the ability of the assistant to personalise itself to the user's preferences. The digital assistant has to operate in a transparent way and be able to participate in multi-party conversations and make use of other sensory data (GPS, RFID, cameras etc.).

There is also a strong connection to the first priority theme: the multilingual assistant should be able to do speech-to-speech translation in human-human-interaction (e.\,g., in meetings) and to deal with different languages, accents and dialects effectively. Systems developed should also cover at least all official languages of the EU and several regional languages.

\subsubsection{Solution and Realisation}
\label{sec:solut-techn-real-pt3}

The technological and scientific state-of-the-art is at a stage that finally allows tackling the development of socially aware multilingual assistants. Progress in machine learning, including adaptation, unsupervised learning from data streams, continuous learning, and transfer learning makes it possible automatically to learn certain capabilities from data. In addition, existing language and multimodal resources enable the bootstrapping of systems. Furthermore, there is interdisciplinary progress made in, e.\,g., social signal processing and also knowledge representation including approaches such as the Semantic Web and Linked Open Data -- especially inferences and automatic reasoning on such data sets are an important prerequisite for the technologies devised here.
 
Technological advances are continuously being achieved in the vision-based human behaviour analysis and synthesis fields. Ubiquitous technologies are now widely available. User-centric approaches have been largely studied and crowd-sourcing is used more and more. Quantitative and objective language technology and human-behaviour understanding technology evaluations, allowing for assessing a technological readiness level (TRL), are carried out more widely, as best practice, and language resources and publicly-available annotated recordings of human spontaneous behaviour are now available.
 
However, there are prohibitive factors. Technology evaluation is still limited and not conducted for all languages. There is limited availability of language resources; the necessary resources do not exist yet for all languages. Publicly-available recordings of spontaneous (rather than staged) human behaviour are sparse, especially when it comes to continuous synchronised observations of multi-party interactions. Limited progress of the technology for automatic understanding of social behaviour like rapport, empathy, envy, conflict, etc., is mainly attributed to this lack of suitable resources. In addition, we still have limited knowledge of human language and human behaviour perception processes. Automated systems often face theoretical and technological complexity of modelling and handling these processes correctly.

\begin{figure*}[htb]
  \centering
  \small
  \begin{tabular}{@{}p{2.5cm}p{4cm}p{4cm}p{4cm}@{}} \toprule\addlinespace
    \multicolumn{1}{c}{Research Priority} & \multicolumn{1}{c}{Phase 1: 2013-2014} & \multicolumn{1}{c}{Phase 2: 2015-2017} & \multicolumn{1}{c}{Phase 3: 2018-2020} \\ \addlinespace\midrule\addlinespace
    Interacting naturally with agents & Provide usable human interface, reliable speech recognition, natural and intelligible speech synthesis, limited understanding and dialogue capabilities & Provide usable dialogue interface, context and dialogue aware speech recognition and synthesis; recognise and produce emotions,  understanding capabilities, context aware dialogue, using other sensors & Provide multiparty (human-agents) interface, multiple voices, mimicking, advanced understanding and advanced personalised dialogue (indirect speech acts, incl.~prosodics, lies, humor) \\ \addlinespace
    Using language and other modalities & Multimodal interaction (speech, facial expression, gesture, body postures) & Multimodal dialogue, fusion and fission & Fleximodal dialogue, identification of best suited modalities \\ \addlinespace
    Conscious of its performing capacities & Confidence in hearing/understanding, recovering from mistakes & Ability to learn continuously and incrementally from mistakes by interaction & Unsupervised learning/forgetting \\ \addlinespace
    Multilingual proficiency & Ensure availability or portability to major EU languages; recognise which language is spoken; multilingual access to multilingual information & More languages, accents and dialects; recognise dialects, accents; exploit limited resources; crosslingual access to information & Speech translation in human-human interactions (multiple speakers speaking multiple languages); cross-cultural support; learn new language with small effort \\ \addlinespace
    Resources & Install infrastructure, benchmark data, semantically annotated data (multimodal), dialogue data & Use infrastructure, more data, more languages & Use infrastructure, more data, more languages \\ \addlinespace
    Evaluation & Benchmark evaluation; measures and protocols for automated speech synthesis, dialogue systems, speech translation evaluation & Measure of progress; more languages & Measure of progress; more languages \\ \addlinespace\bottomrule
  \end{tabular}
  \caption{Priority Theme 3 -- Socially-Aware Interactive Assistants: Preliminary Roadmap}
  \label{fig:pt3-roadmap}
\end{figure*}

\subsubsection{Impact}
\label{sec:impact-pt3}

The impact of this priority theme will be wide-ranging. It will impact the work environment and processes, creativity and innovation, leisure and entertainment, and the private life. Several societal and economical facts call for, but also allow for, improved and more natural interaction between humans and the real world through machines. The ageing society requests ambient intelligence. Globalisation involves the capacity to interact in many languages, and offers a huge market for new products fully addressing this multilingual necessity.
 
The automation of society implies more efficiency and a 24/7 availability of services and information, while green technologies, such as advanced videoconferencing, need to be prioritised. The continuously reduced costs and speed improvement of hardware allow for affordable and better technologies, that can now easily be made available online through app stores.
 
At the same time we still face prohibitive factors. The cultural, political and economical dimensions of language are well perceived, but its technical dimension is not. There is still a psychological barrier for communicating with machines, although this gets more and more common through the use of smartphones and applications such as Skype or Facetime.

\subsubsection{Organisation of Research}
\label{sec:organ-rese-pt3}

In order to improve research efficiency within a public-private partnership, the preferred infrastructure were to handle the various applications in connection with the cooperative development of technologies, including the evaluation of progress, and the production of the language and human naturalistic behaviour resources which are necessary for development and testing.
 
To maximise impact, it is necessary to make a substantial effort in the development of integrated systems based on open architectures, and a multilingual middleware to enable the developed functionalities to be incorporated in a wide range of software. This might best be achieved through a small number of coordinating projects, attached to a federation of strategic projects with complementary goals. These projects should be objective-driven, with clear research, technology and exploitation milestones, coordinated by an on-going road-mapping effort.
 
This includes the production of adequate language and human naturalistic behaviour corpora, semantically annotated including prosodic and non-verbal behavioural cues. This also includes the production (acquisition and annotation) of dialogue corpora from the real world, which implies an incremental system design, and either the use of synchronised continuous observations of all involved parties, or the use of similar data available online (conversations, talk shows).
 
Dialogue systems evaluation still needs more research on the choice of adequate metrics and protocols. The multilingual dimension that is targeted implies the availability of language resources and language technology evaluation for all languages. Handling them all together reduces the overall effort, given the possibility to use the same best practices, tools and protocols.

\subsection{Core Language Resources and Technologies}
\label{sec:sharing-resources-and-results}

% Serge: Terminology as one key aspect of, especially, translation:
%
% Terminology is key for industry-specific communication. Companies within the industry cannot communicate if they use different terminology. Information delivery in a foreign language is impossible without the right words that mean the right things.
% Delivery of the information to all the citizens of Europe is impossible without pan-European terminology for key concepts, entities and actions that carry the meaning of this cross-country and cross-language communication.
% Terminology is key for (a) Quality of machine translation; (b) Productivity and consensus of the copywriters, translators, editors and readers; (c) Live development of the language and new concepts that emerge in business, technology and society.
% - Link up to linked open data, semantic web, open terminology databases etc.

% Such PET should be one of the key, essential elements of linguistic infrastructure of Europe.

% 1.	Recognize the importance of terminology for all aspects of the digital multilingual future;
% 2.	Provision space for PET (both technological and financial) in the future multilingual service Cloud;
% 3.	Create pan-European centralized multilingual terminology portal for communities to work on important, socially significant terminology for multilingual Europe on centralized technology, data and service platform;
% 4.	This portal will be building knowledge base that will later be used for pan-European MT effort.

The three priority research themes share a large and heterogeneous group of core technologies for language analysis and production that provide development support through basic modules and datasets (see Figure~\ref{fig:priority-themes}, p.~\pageref{fig:priority-themes}). To this group belong tools and technologies such as, among others, tokenisers, part-of-speech taggers, syntactic parsers, tools for building language models, information retrieval tools, machine learning toolkits, speech recognition and speech synthesis engines, and integrated architectures such as GATE and UIMA. Many of these tools depend on specific datasets (i.\,e., language resources), for example, very large collections of linguistically annotated documents (monolingual or multilingual, aligned corpora), treebanks, grammars, lexicons, thesauri, terminologies, dictionaries, ontologies and language models. Both tools and resources can be rather general or highly task- or domain-specific, tools can be language-independent, datasets are, by definition, language-specific. As complements to the core technologies and resources there are several types of resources, such as error-annotated corpora for machine translation or spoken dialogue corpora, that are specific to one or more of the three priority themes.

A key component of this research agenda is to collect, develop and make available core technologies and resources through a shared infrastructure so that the research and technology development carried out in all themes can make use of them. Over time, this approach will improve the core technologies, as the specific research will have certain requirements on the software, extending their feature sets, performance, accuracy etc.~through dynamic push-pull effetcs. Conceptualising these technologies as a set of shared core technologies will also have positive effects on their sustainability and interoperability. Also, many European languages other than English are heavily under-resourced, i.\,e., there are no or almost no resources or basic technologies available \cite{LWP2012}.

The European academic and industrial technology community is fully aware of the need for sharing resources such as language data (e.\,g., corpora), language descriptions (e.\,g., lexicons, thesauri, grammars), tools (e.\,g., taggers, stemmers, tokenisers) and core technology components (e.\,g., morphological, syntactic, semantic processing) as a basis for the successful development and implementation of the priority themes. Initiatives such as FLaReNet \cite{flarenetsra2011} and CLARIN have prepared the ground for a culture of sharing, META-NET's open resource exchange infrastructure, META-SHARE, is providing the technological platform as well as legal and organisational schemes. All language resources and basic technologies will be created under the core technologies umbrella. The effort will revolve around the following axes: Infrastructure; Coverage, Quality, Adequacy; Language Resources Acquisition; Openness; Interoperability.

\subsubsection{Infrastructure}
\label{sec:infrastructure}

It is imperative to maintain and further to develop META-SHARE. Broad participation by the whole language technology community is essential in maintaining and extending the infrastructure so that acceptance is ensured. META-SHARE will be the key instrument to make language resources available, visible and accessible, to facilitate their sharing and exchange.

Among the important aspects for the next evolutionary steps of the META-SHARE infrastructure are the following: definition of the basic data and software resources that should populate META-SHARE, multilingual coverage, the capacity to attract providers of useful resources or raw data sets, improvements in sharing mechanisms, and collaborative working practices between R\&D and commercial users. There must also be a business-friendly framework to stimulate commercial use of resources, based on a sound licensing facility. Close cooperation with the three priority themes is of vital importance, especially for defining the set of needed core technologies and resources.

META-SHARE is not limited to data. Instead, it has to be seen as an international hub of resources and technologies for speech and language services from industries and communities. The development and proposal of tools and web services, including evaluation protocols and collaborative workbenches is deemed essential. The accumulation and sharing of resources and tools in a single place would lower the R\&D costs for new applications in new language resource domains.

Sustainability covers preservation, accessibility, and operability (among other things). Collecting and preserving knowledge in the form of existing resources should be a key priority. A sustainability analysis must be part of a resource specification phase. Funding agencies should make a sustainability plan mandatory for projects concerned with the production of language resources.

\subsubsection{Coverage, Quality, Adequacy}
\label{sec:cover-qual-adeq}

Innovation in LT crucially depends on language resources but currently there are not enough available resources to satisfy the needs of all languages, quantitatively and qualitatively. Language resources should be produced and made available for every language, every register, every domain to guarantee full coverage and high quality (see Figure~\ref{fig:lr-lt-coverage}). New methods of shared or distributed resource development can be exploited to achieve better coverage. It is important to assess the availability of existing resources with respect to their adequacy to applications and technology requirements. This involves assessing the maturity of the technologies for which new resources should be developed. Basic language resource kits should be supported and developed for all languages and, at least, key applications.

Automatic techniques should be promoted to guarantee quality through error detection and confidence assessment. The promotion of validation and evaluation can play a valuable role in fostering quality improvement. Evaluation should encompass technologies, resources, guidelines and documentation. But like the technologies it addresses, evaluation is constantly evolving, and new, more specific measures using innovative methodologies are needed to evaluate the reliability of language resources, while maximal use of existing tools should be ensured for the validation of resources.

Lists of basic language technologies should be compiled that should be either made available or researched and implemented for all languages covered by this agenda. These should include tools such as sentence boundary detection modules, tokenisers, lemmatisers, taggers, parsers, word/phrase aligners etc.~as obligatory components for each language. These should also include resources needed for making the modules work for a given language. Other aspects are quality thresholds (minimum accuracy, speed, open availability, interoperability etc.) and cross-lingual evaluation campaigns. After partial attempts at these in the past (e.\,g., BLARK and ELARK, shared tasks such as CLEF, EuroMatrix Marathons, IWSLT, Morpho-Olympics etc.) a more coordinated, sustainable and also wider attempt is needed. 

A Language Resources Impact Factor (LRIF) should be defined in order to enforce the practice of citation of resources on the model of scientific paper authoring and to calculate the actual research impact of resources.  A reference model for creating resources will help address the current shortage of resources in terms of breadth (languages and applications) and depth (quality and volume).

In addition to the, putting it in general terms, unification of approaches mentioned above, a set of shared resources and technologies should be compiled for all the languages to be supported through the future initiative. The specifics of this shared set of dictionaries, text and speech corpora, terminologies, ontologies, lexicons, taggers etc.~remain to be discussed and determined. It is important that they follow the same basic principles, cover not only general language but also several specific domains tailored to the priority themes, will be interlinked (for multilingual applications) and made available as free, public data sets for research and commercial purposes. The creation of such a shared set of base resources and technologies is imperative for the future European multilingual information society --~currently there are many European languages that do not even have a corresponding corpus yet that fulfills certain requirements. National corpora only exist for a handful of languages, many of these corpora are not readily available for research purposes. 

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.95\textwidth]{../_media/europeImproveLT}
  \caption{Towards appropriate and adequate coverage of language resources and technologies for Europe}
  \label{fig:lr-lt-coverage}
\end{figure*}

\subsubsection{Language Resources Acquisition}
\label{sec:lang-reso-acqu}

Re-use and re-purposing should be encouraged to ensure the reuse of development methods and existing tools. With production costs constantly increasing, there is a need to invest in innovative production methods that involve automatic procedures; strategies that approach or ensure full automation for high-quality resource production should be promoted. It is worth considering the power of social media to build resources, especially for those languages where no language resources built by experts exist yet.

There are several promising experiments in crowd-sourcing data collection tasks. Crowd-sourcing makes it possible to mobilise large groups of human talent around the world with just the right language skills so that we can collect what we need when we need it. For instance, it has been estimated that Mechanical Turk translation is 10 to 60 times less expensive than professional translation. A particularly sensitive case is that of less-resourced languages, where language technology should be developed rapidly to help minority-language speakers access education and the Information Society \cite{eldia12,maaya2012,ifa2008,ifa2011}. 

\subsubsection{Openness}
\label{sec:openness}

There is a strong trend towards open data, i.\,e., data that are easily obtainable and that can be used with few, if any, restrictions. Sharing data and tools has become a viable solution towards encouraging open data \cite{sellis2010}, and the community is strongly investing in facilities such as META-SHARE for the discovery and use of resources. These facilities could represent an optimal intermediate solution to respond to the needs for data variety, ease of retrieval, better data description and community-wide access, while at the same time assisting in clearing the intricate issues associated with intellectual property rights (see Section~\ref{sec:legal-aspects} for more details).

\subsubsection{Interoperability}
\label{sec:interoperability}

Interoperability of resources seeks to maximise the extent to which they are compatible and therefore integratable at various levels, so as to allow, for instance, the merging of data or tools coming from different sources. All stakeholders need to join forces to drive forward the use of existing and emerging standards, at least in the areas where there is some degree of consensus. 

\begin{figure*}[htb]
  \centering
  \small
  \begin{tabular}{@{}p{2.5cm}p{8cm}p{4cm}@{}} \toprule\addlinespace
    \multicolumn{1}{c}{Research Priority} & \multicolumn{1}{c}{Phase 1: 2013-2014} & \multicolumn{1}{c}{Phases 2 and 3: 2015-2020} \\ \addlinespace\midrule\addlinespace
    Infrastructure & Maintain and extend facility(-ies) for sharing resource data and tools; promote accurate and reliable documentation of resources through metadata; cooperation between infrastructure initiatives to avoid the duplication of effort & Automatically accumulate descriptions and resources; multilingual coverage, ease of conversion into uniform formats; integrate web services (SaaS) \\ \addlinespace
    Coverage, quality, adequacy & Increase number of resources to address LT and application needs; address formal and content quality by promoting evaluation and validation; promote evaluation and validation activities and the dissemination of their outcomes & Increase number of resources to address LT and application needs; provide HQ resources for all European languages \\ \addlinespace
    Acquisition & \multicolumn{2}{p{12.4cm}@{}}{Define and disseminate LR production best practices; enforce reusing and repurposing; towards the full automation of LR data production; methods for collaborative creation and extension of HQ resources, also to increase coverage; implement workflows of language processing services for acquisition of resources required for the implementation of the priority themes; bridge acquisition methods with linked open data and big data; share the effort for production of LRs between international bodies and individual countries} \\ \addlinespace
    Openness & \multicolumn{2}{p{12.4cm}@{}}{Educate key players with basic legal know-how; elaborate specific, simple and harmonised licensing solutions for data resources; promote copyright exception for research purposes; develop legal and technical solutions for privacy protection; opt for openness of resources, especially publicly funded ones; ensure that publicly funded resources are publicly available free of charge; clear IPR at the early stages of production; try to ensure that re-use is permitted} \\ \addlinespace
    Interoperability & \multicolumn{2}{p{12.4cm}@{}}{Standardisation activities, make standards operational and put them in use; establish permanent Standards Watch; promote and disseminate standards to students and young researchers; encourage/enforce use of best practices or standards in production projects; identify new mature areas for standardisation and promote joint efforts between R\&D and industry} \\ \addlinespace\bottomrule
  \end{tabular}
  \caption{Core language resources and technologies: Preliminary Roadmap}
  \label{fig:lrlt-roadmap}
\end{figure*}

\subsubsection{Organisation of Research}
\label{sec:org-research-pt4}

In order to optimise the efficiency of shared core technologies for language analysis and production as well as the further development of the infrastructure, maximise the infrastructure's impact, and ensure that requirements for research and development are met at the necessary depth for all languages in all priority themes, the organisation of this shared agenda theme should adopt the following principles: It is necessary to invest in the further development of an integrated infrastructure (i.\,e., META-SHARE) based on an open architecture, enabling the sharing and further development of resources. The infrastructure should support technology-specific challenges and shared tasks in order to accelerate innovation breakthrough and market-readiness for desperately needed technologies. Concerted activities and policies facilitating the sharing of resources overcoming all stumbling blocks on the way to technical, organisational and legal interoperability should be supported. EU level research must be aligned and tightly coordinated with efforts on the national levels, so that coverage and language-specific developments are efficiently achieved. An important aspect of this coordination effort is concerned with the META-NET White Paper Series \cite{LWP2012}: in the 30 different white papers we have concrete and specific assessments of the language- and country-specific situation with regard to demands and technology gaps. The next step is to address and to fill these gaps with high-quality and robust core technologies and language resources.

%\begin{itemize}
%\item This platform should enable resources, data and processing services to be incorporated in, or called by a wide range of application software.
%\item To boost the automation of the language resource acquisition process, thus increasing coverage, quality and adequacy, a small number of coordinating projects attached to a federation of strategic projects with complementary goals can be foreseen. These projects should be objective-driven, with clear research, technology and exploitation milestones, coordinated by an ongoing road-mapping effort.
%\item In order to increase research efficiency within a public-private partnership, the preferred infrastructure should handle the various applications in connection with the cooperative development of technologies, including regular objective evaluation of technology progress, and the production of the appropriate resources which are necessary to develop and test the various technologies.
%\end{itemize}

% ------- End of Stelios' text

\subsection{A European Service Platform for Language Technologies}
\label{sec:europ-service-platform}

% Possible Names and Acronyms for the Platform:
%
% EuroLang:   European Language(s) Platform
% PEL:        Platform for European Languages
% PELT:       Platform for European Language Technology
% CompCom:    Computers and Communication
% LUCKIE SKY: Platform for Language Understanding, Communication, Knowledge, Inference and Emotion

We argue for and recommend the design and implementation of an ambitious large-scale platform as a central motor for research and innovation in the next phase of IT evolution and as a ubiquitous resource for the multilingual European society. The platform will be used for testing, show casing, proof-of-concept demonstration, avant-garde adoption, experimental and operational service composition, and fast and economical service delivery to enterprises and end-users (see Figure~\ref{fig:platform-overview}).
 
The proposed creation of a powerful cloud or sky computing platform (see Section~\ref{sec:cloud-sky-computing}) for a wide range of services dealing with human language, knowledge and emotion will not only benefit the individual and corporate users of these technologies but also the providers. Large-scale ICT infrastructures and innovation clusters such as this suggested platform are also foreseen in the Digital Agenda for Europe (see \cite{DA2010}, p.~24).
 
\textbf{Users} will be able to receive customised integrated services without having to install, combine, support and maintain the software. They will have access to specialised solutions even if they do not use these regularly.
 
\textbf{Language technology providers} will have ample opportunity to offer stand-alone or integrated services.
 
\textbf{Providers of language services} rendered by human language professionals will be able to use the platform for enhancing their services by means of appropriate technology and for providing their services stand-alone or integrated into other application services.
 
\textbf{Researchers} will have a virtual laboratory for testing, combining, and benchmarking their technologies and for exposing them in realistic trials to real tasks and users.
 
\textbf{Providers of services} that can be enabled or enhanced by text and speech processing will utilise the platform for testing the needed LT functionalities and for integrating them into their own solutions.

\textbf{Citizens and corporate users} will enjoy the benefits of language technology early and at no or reasonable costs through a large variety of generic and specialised services offered at a single source.

In order to allow for the gigantic range of foreseeable and currently not yet foreseeable solutions, the infrastructure will have to host all relevant simple services, including components, tools and data resources, as well as various layers or components of higher services that incorporate simpler ones. META-SHARE can play an important role in the design of the platform (see Section~\ref{sec:sharing-resources-and-results}).
 
A top layer consists of \textbf{language processing} such as text filters, tokenisation, spell, grammar and style checking, hyphenation, lemmatising and parsing. At a slightly deeper level, services will be offered that realise some degree and form of \textbf{language understanding} including entity and event extraction, opinion mining and translation. Both basic language processing and understanding will be used by services that support \textbf{human communication} or realise human-machine interaction. Part of this layer are question answering and dialogue systems as well as email response applications. Another component will bring in services for processing and storing \textbf{knowledge} gained by and used for understanding and communication. This part will include repositories of linked data and ontologies, as well as services for building, using and maintaining them. These in turn permit a certain range of rational capabilities often attributed to a notion of intelligence. The goal is not to model the entire human intelligence but rather to realise selected forms of \textbf{inference} that are needed for utilising and extending knowledge, for understanding and for successful communication. These forms of inference permit better decision support, pro-active planning and autonomous adaptation. A final part of services will be dedicated to \textbf{human emotion}. Since people are largely guided by their emotions and strongly affected by the emotions of others, truly user-centred IT need facilities for detecting and interpreting emotion and even for expressing emotional states in communication. 

We consider the paradigm of federated cloud services or sky computing with its emerging standards such as OCCI, OVM and CDMI and toolkits such a OpenNebula as the appropriate approach for realising the ambitious infrastructure. All three priority areas of this SRA will be able to contribute to and at the same time draw immense benefits from this platform. There are strong reasons for aiming at a single service platform for the three areas and for the different types of technologies. They share many basic components and they need to be combined for many valuable applications, including the selected showcase solutions of the three areas.

\begin{figure*}[htbp]
  \center
  \includegraphics[width=0.9\textwidth]{../_media/Platform}
  \caption{European Service Platform for Language Technologies}
  \label{fig:platform-overview}
\end{figure*}

% Because of its components (language, understanding, communication, knowledge, inference and emotion) we subsume the entire set of services under the acronym LUCKIE.  
 
\subsubsection*{Implementation of the Platform}
\label{sec:implementation-of-platform}

The creation of this platform has to be supported by public funding. Because of the high requirements concerning performance, reliability, user support, scalability, persistence as well as data protection and conformance with privacy regulation, the platform needs to be established by a consortium with strong commercial partners and also be operated by this consortium or a commercial contractor. A similar platform with slightly different desiderata and functionalities is currently built under the name Helix-Nebula for the Earth Sciences with the help of the following commercial partners: Atos, Capgemini, CloudSigma, Interoute, Logica, Orange Business Services, SAP, SixSq, Telefonica, Terradue, Thales, The Server Labs and T-Systems. Partners are also the Cloud Security Alliance, the OpenNebula Project and the European Grid Infrastructure. These are working together with major research centres in the Earth Sciences to establish the targeted federated and secure high-performance computing cloud platform.
 
The intended platform for LT and neighbouring fields would be intended for a mix of commercial and non-commercial services. It would be cost-free for all providers of non-commercial services (cost-free and advertisement-free) including research systems, experimental services and freely shared resources but it would raise revenues by charging a proportional commission on all commercially provided services. In order to reduce dependence on individual companies and software products, the base technology should be supplied by open toolkits and standards such as OpenNebula and OCCI.  
 
For each priority research theme, chances for successful showcasing and successful commercial innovation will increase tremendously if usable services of required strength and reliability could be offered on such a platform.
 
The platform will considerably lower the barrier for market entry for innovative technologies, especially for products and services offered by SMEs. Still, these stakeholders may not have the resources, expertise, and time to create the necessary interfaces to integrate their results into real-life services, let alone the overarching platform itself. There is still a gap between research prototypes and products that have been engineered and tested for robust applications. Moreover, many innovative developments require access to special kinds of language resources such as recordings of spoken commands to smartphones, which are difficult to get for several reasons.
 
Thus the service platform will be an important instrument for supporting the entire innovation chain, but, in addition, interoperability standards, interfacing tools, middle-ware, and reference service architectures need to be developed and constantly adapted. Many of these may not be generic enough to serve all application areas, so that much of the work in resource and service integration will have to take place in the respective priority theme research actions.

\subsection{Legal Challenges}
\label{sec:legal-aspects}

Legal challenges are involved on multiple levels in our future research and technology plans as described in this agenda. One of the key challenges for our community and also for the policy makers is to push for the development of a common legal framework that would facilitate resource sharing efforts abiding by the law, benefiting from the adoption of “fair use” principles and appropriate copyright exceptions. It is of utmost importance that legislation regarding resource use and resource acquisition be harmonised, and even standardised, for all types of language resources, and that free use be allowed, at least for research or non-profit purposes (see Section~\ref{sec:sharing-resources-and-results}).

Other areas in which we are facing or in which we expect legal challenges are the ``trust'' features of the European Language Technology Platform, which needs to exhibit a maximum level of data security in order to protect confidential documents (from contracts to patient data), or novel methods of acquiring written or spoken data for language resources. Any grant of access to language resources should ideally include not only the right to read the relevant content but also to allow transformative uses, dissemination and distribution of such resources and their derivatives, according to the needs and policies of language resources owners and users. Not only the acquisition but also the sharing and distribution of language resources is constantly hindered or completely disabled by legal aspects which should ideally be resolved once and for all. Legal issues such as these are severe stumbling blocks that can bring innovation to a complete standstill. In addition, content or approaches to data privacy or security that are legal in one country may be illegal in another. These aspects can be partially addressed on the software level (for example, through appropriate metadata records that reflect different legal realms) but should ideally be harmonised on the European or global level.

META-NET favours and aligns itself with the growing open data and open source movement and the idea of opening up data, resources and technologies (especially those whose development was supported through public funding) instead of locking them away. META-NET advocates the use of a model licensing scheme with a firm orientation towards the creation of an openness culture and the relevant ecosystem for language resources.

\subsection{Languages to be Supported}
\label{sec:languages-to-be-supported}

While our study ``Europe's Languages in the Digital Age'' had a look at 30 selected European languages (see Section~\ref{sec:lwp}, p.~\pageref{sec:lwp}\,ff.), the research and technology development programme specified in this agenda has a much broader scope in terms of languages to be supported. The set of languages to be reflected with corresponding technologies include not only the currently 23 official languages of the European Union but also recognised and unrecognised regional languages and the languages of associated countries or non-member states. Equally important are the minority and immigrant languages that are in active use by a significant population in Europe (for Germany, these are, among others, Turkish and Russian; for the UK, these include Bengali, Urdu/Hindi and Punjabi). An important set of languages outside our continent are those of important political and trade partners such as, for example, Chinese, Indonesian, Japanese, Korean, Russian, and Thai. META-NET already has good working relationships with several of the respective official bodies, especially EFNIL (European Federation of National Institutions for Language), NPLD (Network to Promote Linguistic Diversity, \cite{eldia12}), and also the Maaya World Network for Linguistic Diversity.

The concrete composition of languages to be supported by this agenda's research programme up until the year 2020 and beyond, depends on the concrete composition of participating countries and regions and also on the specific nature of the funding instruments used and combined for realising the ambituous plan. It remains to be discussed what it means for a language to be supported through this strategic programme; most probably, the level of support will have to be determined through a concrete set of specific resources and specific base technologies that need to be researched and developed for a given language and that need to fulfill certain requirements (with regard to, among others, coverage, precision, quality, speed etc.). The next level of support would, then, be determined by including a language in one or more of the priority research themes.

Not all countries have the required expertise or human resources to take care of the technology support for their languages. For example, in Iceland there is not a single position in Language Technology at any Icelandic university or college and there is only one company that works in this area. Those colleagues who work on LT at universities and research institutes come from either language departments or computer science departments; their main duties are not directly related to Language Technology, still they managed to produce a few basic technologies and resources but advanced types of resources do not exist at all for Icelandic, nor do they for many other under-resourced languages. This is why we need to intensify research and establish techniques, methods and instruments for research and knowledge transfer so that colleagues in countries such as Iceland can benefit as much as possible for their own language from the research carried out in other countries for other languages. Bootstrapping the set of core language technologies and resources for all languages spoken in Europe is not a matter of a few countries joining forces but a challenge on the European scale that must be addressed accordingly to avoid digital exclusion and secure future business development.

META-NET realises that Europe is a multi-ethnic region in which many more languages than only the official ones are spoken. Therefore, it is important not only to carry out research and technology development on the official and a few additional unofficial languages but also to work on those languages that are in active use by a significant part of the population, in order to address the severe issue of linguistic ghettoisation and finally to bring about a truly multilingual European information society.

As regards funding this strategic programme we suggest an approach that involves multiple stakeholders, especially the European Union, the Member States, Associated Countries, other countries and also regions, not only in Europe but ultimately also on other continents. Research on advanced, sophisticated monolingual technologies is to be supported by the respective countries' funding agencies primarily. Research on multilingual technologies and also research on basic technologies and resources for under-resourced languages needs to be supported by the European Union along with the respective countries and regions. Specific procedures for research and knowledge transfer need to be agreed upon and put into action so that the speakers of these languages can benefit from our activities as much and as quickly as possible. In order to provide basic technology support for those languages spoken in Europe with active hubs of research outside our continent, connections to the leading research centres need to be established or intensified so that Europe can benefit from technologies that have been developed by these centres. If technologies exist, funding schemes need to be established so that these technologies can be adopted, if necessary, to the standards that will be put into practice in Europe in the years to come, especially with regard to sharing, distributing, data formats, APIs and inclusion in the European Language Technology Platform.

\subsection{Structure and Principles of Research Organisation}
\label{sec:struct-princ-research-org}

From the description of the three priority themes one can easily see that the proposed research strands overlap in technologies and challenges -- this is intended. The overlap reflects the coherence and maturation of the field. At the same time, the resulting division of labour and sharing of resources and results is a precondition for the realisation of this highly ambitious programme.

\begin{figure*}[htb]
  \center
  \includegraphics[width=0.75\textwidth]{../_media/PT-Rings}
  \caption{Scientific cooperation among the three priority research themes}
  \label{fig:priority-themes}
\end{figure*}
 
All three themes need to benefit from progress in core technologies of language analysis and production such as morphological, syntactic and semantic parsing and generation. But each of the three areas will concentrate on one central area of language technology: the Translingual Cloud will focus on cross-lingual technologies such as translation and interpretation; the Social Intelligence strand will take care of knowledge discovery, text analytics and related technologies; the research dedicated to the Interactive Assistants will take on technologies such as speech and multimodal interfaces (see Figure~\ref{fig:priority-themes}).

Except for a few large national projects and programmes such as Technolangue and Quaero in France, Verbmobil and Theseus in Germany and DARPA Communicator and GALE in the US, the field of language technology does not have experience with research efforts of the magnitude and scope required for the targeted advances and plans in this SRA. Nevertheless, our technology area has to follow developments in other key engineering disciplines and speed up technology evolution by massive collaboration based on competitive division of labour and sharing of resources and results. In our reflection on optimal schemes for organising we tried to draw lessons from our own field's recent history and to capitalise on experience from other fields by adopting approaches that proved successful and evading encountered pitfalls.
 
The final model for the organisation of collaboration will have to be guided by a thoughtful combination of the following basic approaches.

\textbf{Flexible collaborative approach:} For each priority theme, one or several very large cooperating and competing lead projects will share an infrastructure for evaluation, communication and resources (data and base technologies). Mechanisms for reducing or terminating partner involvements and for adding new partners or subcontracted contributors should provide flexibility. A number of smaller projects including national and regional projects will provide building blocks for particular languages, tasks, component technologies or resources. A cooperation scheme will be designed for effectively and flexibly involving EC-funding, contributions from member states, industrial associations, and language communities, among others \cite{spector2012}. The choice of funding instruments will be determined in due time.

\textbf{Staged approach:} Two major phases are foreseen (2015-2017, 2018-2020). The major phases should be synchronised among the themes and also projects.   

\textbf{Evolutionary approach:} Instead of banking on one selected paradigm, competing approaches will be followed in parallel with shared schemes for evaluation, merging, adopting and discontinuing research threads so that the two elements of successful evolutionary research approaches, selection and cross-fertilisation, are exploited to the maximum extent possible.

\textbf{Analytical approach:} Instead of the currently predominant search for an ideal one-fits-all approach, the research will focus on observed quality barriers and not shun computationally expensive dedicated solutions for overcoming particular obstacles.

\textbf{Bootstrapping approach:} Better systems can be derived from more and better data and through new insights. In turn, improved systems can be used to gain better data and new insights. Thus the combination of the analytical evolutionary approach with powerful machine learning techniques will be the basis for a technology bootstrapping, which has been the by far most fruitful scheme for the development of highly complex technologies.

\textbf{Close cooperation with relevant areas of service and technology industries:} In order to increase chances of successful commercialisation and to obtain convincing and sufficiently tested demonstrations of novel applications, the relevant industrial sectors must be strongly integrated into the entire research cycle.

\textbf{Tighter research-innovation cycle:} Through the collaboration between research, commercial services and commercial technology industries, especially through the shared evaluation metrics and continuous testing, the usual push-model of technology transfer will hopefully be substituted by a pull-model, in which commercial technology users can ask for specific solutions. In the envisaged research scheme, incentives will be created for competing teams each composed of researchers, commercial users and commercial developers by the participating enterprises for initiating successful innovations.

\textbf{Interdisciplinary approach:} A number of science, technology and service areas need to be integrated into the research from day one. Some technology areas such as speech technologies, language checking and authoring systems need to be represented by providers of state-of-the-art commercial products.

Supporting research and innovation in language technology should be accompanied by policy making in the area of multilingualism, but also in digital accessibility. Overcoming language barriers can greatly influence the future of the EU and the whole planet \cite{maaya2012,ifa2008,ifa2011}. Solutions for better communication and for access to content in the native languages of the users would reaffirm the role of the EC to serve the needs of the EU citizens. A substantial connection to the infrastructural program CEF could help to speed up the transfer of research results to badly needed services for the European economy and public. At the same time, use cases should cover areas where the European societal needs massively overlap with business opportunities to achieve funding investment that pays back, ideally public-private partnerships.
 
The coordination among the three research strands poses administrative challenges. Because of the described interdependencies and also because of the need to maintain and improve the obtained level of cohesion and community spirit in the European Language Technology community, a coordinating body is needed. Whether such an entity is jointly carried by the three areas or by a separate support project, needs to be determined in the upcoming discussion on the appropriate support instruments for the identified research priorities.
\end{multicols}

% --------------------------------------------------------------------------

\clearpage

\ssection[Towards a Shared European Programme for Multilingual Europe 2020]{Towards a Shared European Programme for Multilingual Europe 2020}
\label{sec:conclusions}

\begin{multicols}{2}

\subsection{Summary}
\label{sec:final-summary}

In this Strategic Research Agenda META-NET recommends setting up a large, multi-year programme on language technologies to build the technological foundations for a truly multilingual Europe. We suggest to concentrate future efforts in this field on three priority research themes: Translingual Cloud; Social Intelligence and e-Participation; Socially-Aware Interactive Assistants. We also suggest to concentrate on two additional themes. On the one hand there is the overarching issue of researching and further developing core language resources and base technologies that are needed by the three priority themes and that, for many of Europe's languages, do not exist yet. On the other, we recommend to design and to implement the European Language Technology Platform as a means to collect and to offer all language technology-related applications and services, designed and built in Europe for the European citizen.

The research strands and associated sets of applications we suggest to build in the next ten years are of utmost importance for Europe. Through these technologies we will be able to overcome language barriers in spoken and written communication, we will be able to carry out country- and language-border-crossing debates and we will enable new forms and means of communication. We are confident that the impact of our technologies will be so immense that they will be able to help establishing a sense of a European identity in the majority of European citizens. The research plan described in this agenda will generate a countless number of opportunities, it will significantly participate to Europe's future growth and will secure Europe's position in many global markets.

\subsection{Specific Roadmaps}
\label{sec:roadmaps}

The roadmaps presented in this Strategic Research Agenda provide indicative information as regards the actual research lines and phases within the priority themes. The roadmaps show the current state of discussion within META-NET and our recommendations how to move forward. Upcoming EC-funded projects will continue work on the roadmaps, preparing more detailed and more concrete phases. The project QTLaunchPad, which started in June 2012 and which puts an emphasis on quality translation, is taking care of pushing forward the roadmap for the Translingual Cloud priority theme (Section~\ref{sec:priority-theme-1-translation-cloud}). It is expected that two or three additional projects which will be funded under the final FP7 call, starting in late 2013, will take care of the roadmaps for the two other priority themes (Sections~\ref{sec:priority-theme-2-social-intelligence} and~\ref{sec:priority-theme-3-interactive-assistant}) and most likely also the European Language Technology Platform (Section~\ref{sec:europ-service-platform}). Only when more details are known with regard to the available research steps and interdependencies and also the potential funding instruments can our plans and the shared programme be specified in a more detailed way. For the field of language technology the scope of the shared programme is unprecedented: we recommend to set up a ten-year programme in a total of five areas, involving the European Union and additional countries.

\subsection{Towards A Shared European Programme}
\label{sec:towards-shar-europ}

The plans foreseen in this SRA can be successfully realised and implemented using several different measures and instruments, for example, through clusters of projects or a certain number of coordinated projects. Due to the scope and duration of the suggested action, our preferred option is to set up a shared programme between the European Commission and the Member States as well as Associated Countries. First steps along those lines have been taken at META-NET's META-FORUM 2012 conference in Brussels, Belgium, on June 21, 2012, when representatives of several European funding agencies (Bulgaria, Czech Republic, France, Hungary, The Netherlands, Slovenia) who participated in a panel discussion on this topic, unanimously expressed the urgent need for setting up such a shared programme \cite{mf2012}.

A sizable portion of the research proposed in this SRA under the umbrella of the three priority themes is to be carried out in the Horizon 2020 programme. The European service platform for language technologies is a very good fit for the Connecting Europe Facility programme (CEF) while large parts of the core technologies for language analysis and production, especially monolingual base resources and technologies, are good candidates for support through national and regional programmes (see Section~\ref{sec:languages-to-be-supported}). Furthermore, it is important to include the technological needs and innovative ideas of Europe's SMEs, bigger companies and the startup scene in the further shaping of the shared programme. 

The shared programme will include a carefully planned governance structure. First steps towards establishing a structure have already been taken within META-NET. The network of excellence has an Executive Board with currently 12 members, the operations of the network and its bodies are specified in the META-NET Statutes \cite{statutes2012}. Furthermore, a legal person for the META-NET network was established. This legal person, META-TRUST AISBL, is an international non-profit organisation under Belgian law \cite{metatrust2012}. These proven and established structures can be used as starting points for the governance structure of the future programme but we are open to any suggestions for modifications, especially as the final governance structure will also be partially determined by the concrete funding instruments to be used for establishing the programme. The main responsibilities of the governance structure will be to perform checks, to monitor and to evaluate progress and to maintain and to modify the strategic agenda and roadmaps. All major research strands and paths specified in the roadmaps will be complemented with evaluation campaigns that set quality levels for the implemented technologies. These evaluation campaigns will act as major quality assurance instruments so that the research and development results comply with industry expectations and performance standards.

There are several options how to organise the research proposed in this strategic agenda. In June 2012 we have started discussing two possible instruments within META-NET that mainly aim at establishing a shared European programme -- other options still have to be screened; new options might emerge from the Horizon 2020 and CEF programmes. The two candidate instruments are an Article 185 Initiative (see Section~\ref{sec:article-185-init}) and a Contractual Public-Private Partnership (PPP, see Section~\ref{sec:contr-ppp}).

\subsubsection{Article 185 Initiative}
\label{sec:article-185-init}

To quote Article 185 of the Treaty of the Functioning of the European Union (TFEU): ``In implementing the multiannual framework programme, the Union may make provision, in agreement with the Member States concerned, for participation in research and development programmes undertaken by several Member States [\dots].''  Currently there are four joint programmes running as Article 185 Initiatives \cite{A185}: Ambient Assisted Living (AAL), Baltic Sea research (Bonus), a programme in the field of metrology (EMRP) and a programme for research performing SMEs and their partners (Eurostars).

A key idea behind Article 185 is to coordinate national programmes in order to reduce the fragmentation of research efforts carried out on the national or regional level. Among the goals to be achieved are to reach critical mass in certain research areas, to ensure better use of scarce resources and to find common answers and approaches to common needs and interests. Member states are given the opportunity to exchange good practice, to avoid unnecessary overlaps of efforts, to exchange information and expertise and to learn from each other.

The Seventh Framework Programme states that an Article 185 Initiative can be launched in areas to be identified in close association with the Member States on the basis of a series of criteria: relevance to EU objectives; the clear definition of the objective to be pursued and its relevance to the objectives of the Framework Programme; presence of a pre-existing basis (existing or envisaged research programmes); European added value; critical mass, with regard to the size and the number of programmes involved and the similarity of activities they cover; efficiency of Article 185 as the most appropriate means for achieving the objectives. Each Article 185 Initiative is set up individually through a decision of the European Parliament and of the European Council, following a proposal from the European Commission. The implementation requires the establishment or existence of a legal Dedicated Implementation Structure (DIS) which should exist before the Council's decision. The DIS takes care of programme management and calls for proposals, selection of projects and follow-ups and financial management.

\subsubsection{Contractual Public-Private Partnership}
\label{sec:contr-ppp}

While many details of the upcoming programme Horizon 2020 are still under discussion, Contractual PPPs are currently emerging as the primary model to implement parts of the programme objectives with regard to sizeable, roadmap-based research and innovation efforts within the technology pillar of H2020, drawing also on resources beyond the EU support and related matching funds. The EC's proposal for Horizon 2020 states that ``greater impact should also be achieved by combining Horizon 2020 and private sector funds within public-private partnerships in key areas where research and innovation could contribute to Europe's wider competitiveness goals and help tackle societal challenges'' \cite{H2020prop}.  PPPs are an important mechanism for focusing research and innovation, ensuring stakeholders engagement and, above all, for improving the impact of EU support on Europe's competitiveness, growth and jobs creation (see \cite{DA2010}, p.~24). A public-private partnership is defined as ``a partnership where private sector partners, the Union and, where appropriate, other partners, commit to jointly support the development and implementation of a research and innovation programme or activities''. Similar instruments are JTIs (Joint Technology Initiatives), ETPs (European Technology Platforms) and institutional PPPs which are a counterpart to Contractual PPPs.

For Contractual PPPs, a Contractual Agreement is foreseen between the EC and private and public partners that specifies the objectives of the partnership, commitments of the partners, target outputs and the activities that require support from Horizon 2020. PPPs are to be identified in an open and transparent way based on all of the following criteria: the added value of action at Union level; the scale of impact on industrial competitiveness, sustainable growth and socio-economic issues; the long-term commitment from all partners based on a shared vision and clearly defined objectives; the scale of the resources involved and the ability to leverage additional investments in research and innovation; a clear definition of roles for each of the partners and agreed key performance indicators over the period chosen (see \cite{H2020prop}, p.~21). 

Setting up a contractual PPP does not require a decision in the European Parliament.  

\subsection{Conclusions}
\label{sec:funding-conclusions}

The research plans specified in this SRA are, among others, a good match for an Article 185 Initiative and also for a Contractual PPP. It remains to be discussed which instrument is considered the most appropriate one to realise and implement the three priority research themes, the set of core technologies and shared resources and also the European service platform for language technology. Due to the scope, size and duration of the shared programme, a combination of instruments could also be a promising avenue, for example, to fund the actual research to be carried out in the three priority themes through Horizon 2020 and to concentrate on CEF concerning the development of the European Language Technology Platform.

% FIXME: Following are a few good reasons why this SRA should be implemented through a A185I
% Multilingualism is an important topic and a high societal challenge within the EU. By definition, language technology needs major investments as there are substantial amounts of research efforts needed to prepare and create technologies for every language. Industrial coverage by SMEs plays an important role. The member states, associated countries and also regions are interested to support their languages. The European Union is interested to enable their citizens and businesses to communicate with one another. The bodies of the European Union (EC, EP, ECJ, EPO, ENISA etc.) are interested in supporting their own technological needs with regard to communication and multilingual technologies. 

\end{multicols}

\clearpage

% --------------------------------------------------------------------------

\appendix
\addtocontents{toc}{\protect\bigskip}

% ===========================================================================

\ssection[References]{References}

\begin{footnotesize}
\bibliographystyle{unsrt}
\bibliography{sra_references}
\end{footnotesize}

\clearpage

% ===========================================================================

\ssection[List of Key Contributors]{List of Key Contributors}
\label{sec:list-of-contributors}

\begin{small}
The experts listed in the following contributed to this Strategic Research Agenda (54\% from language technology user or provider industries, 46\% from language technology research, 4\% from national or international institutions). The Strategic Research Agenda was edited by the \href{http://www.meta-net.eu/vision/technology-council-members/all}{META Technology Council}.
\end{small}

% Gesamt:    190
%
% Industry:  102
% Academia:   87
% Other:       8 (EPO, JRC, Ministry of Defense, France)

\begin{multicols}{3}
\begin{footnotesize}
  \begin{enumerate}
    \raggedright{
      \item Sophia Ananiadou, U.~of Manchester, UK
      \item Sanne Andresen, Ordbogen, DK
      \item Toni Badia, Barcelona Media, ES
      \item Antonio Balvet, U.~of Lille, FR
      \item Michaela Bartelt, Electronic Arts, GER/USA
      \item Christoph Bauer, ORF, AT
      \item Matthias Bärwolff, Tazaldoo, GER
      \item Caterina Berbenni-Rehm, Promis, LUX
      \item Juanjo Bermudez, Lingua e-Solutions SL, ES
      \item Henriette Edvarda Berntsen, Tansa, NO
      \item Nozha Boujemaa, INRIA, FR
      \item Hervé Bourland, IDIAP, CH
      \item Antonio Branco, U.~of Lisbon, PT
      \item Andrew Bredenkamp, acrolinx, GER
      \item Anton Bregar, PL
      \item Gerhard Budin, U.~of Vienna, AT
      \item Axel Buendia, Spir.\,Ops, FR
      \item Paul Buitelaar, DERI, IE
      \item Aljoscha Burchardt, DFKI, GER
      \item Will Burgett, Intel, USA
      \item Johannes Bursch, Daimler AG, GER
      \item Miriam Butt, U.~of Konstanz, GER
      \item Nicoletta Calzolari, Consiglio Nazionale delle Ricerche, IT
      \item Nick Campbell, Trinity College Dublin, IE
      \item Olga Caprotti, U.~of Gothenburg, SE
      \item Jean Carrive, INA, FR
      \item Khalid Choukri, ELDA, FR
      \item Philipp Cimiano, U.~of Bielefeld, GER
      \item Ann Copestake, U.~of Cambridge, UK
      \item Ido Dagan, Bar-Ilan University, IL
      \item Morena Danieli, Loquendo, IT
      \item Christophe Declercq, Imperial College, UK
      \item Claude de Loupy, Syllabs, FR
      \item Maarten de Rijke, U.~of Amsterdam, NL
      \item Koenraad De Smedt, U.~of Bergen, NO
      \item István Dienes, HU
      \item Alice Dijkstra, Nederlandse Organisatie voor Wetenschappelijk Onderzoek, NL
      \item Marin Dimitrov, Ontotext, BG
      \item Petar Djekic, SoundCloud, UK
      \item Bill Dolan, Microsoft, USA
      \item Rickard Domeij, Language Council of Sweden, SE
      \item Christoph Dosch, Institut für Rundfunktechnik, GER
      \item Christian Dugast, Tech2Biz, GER
      \item Ray Fabri, U.~of Malta, MT
      \item Marcello Federico, FBK, IT
      \item David Filip, Moravia, CZ
      \item Dan Flickinger, Stanford Univ., USA
      \item Gil Francopoulo, CNRS/LIMSI, IMMI, Tagmatica, FR
      \item Piotr W.~Fuglewicz, TiP, PL
      \item Robert Gaizauskas, U.~of Sheffield, UK
      \item Martine Garnier-Rizet, CNRS/LIMSI and IMMI, FR
      \item Simon Garrett, British Telecom, UK
      \item Stefan Geissler, Temis, GER
      \item Edouard Geoffrois, Ministry of Defense and French Nat.~Research Agency, FR
      \item Yota Georgakopolou, European Captioning Institute, UK
      \item Jost Gippert, U.~of Frankfurt, GER
      \item Mircea Giurgiu, U.~of Cluj-Napoca, RO
      \item Serge Gladkoff, Logrus International and GALA Standards Director, USA/RUS
      \item Daniel Grasmick, Lucy Software, GER
      \item Gregory Grefenstette, Exalead, FR
      \item Marko Grobelnik, Institut ``Jožef Stefan'', SI
      \item Joakim Gustafson, KTH Royal Institute of Technology, SE
      \item Thomas Hagen, Dictatr AS, NO
      \item Jan Hajic, Charles U.~Prague, CZ
      \item Paul Heisterkamp, Daimler AG, GER
      \item Mattias Heldner, KTH Royal Institute of Technology, SE
      \item Sebastian Hellmann, U.~of Leipzig, GER
      \item Manuel Herranz, PangeaMT, ES
      \item Theo Hoffenberg, Softissimo, FR
      \item Thomas Hofmann, Google, CH/USA
      \item Timo Honkela, Aalto University, FI
      \item Roman Jansen-Winkeln, Belingoo Media Group, LUX
      \item Krzysztof Jassem, Poleng, PL
      \item Keith Jeffery, Science and Technology Facilities Council, Rutherford Appleton Lab., UK
      \item Richard Jelinek, PetaMem GmbH, GER
      \item Kristiina Jokinen, U.~of Helsinki, FI
      \item Rebecca Jonson, Artificial Solutions, ES
      \item John Judge, Dublin City U./CNGL, IE
      \item Martin Kay, Stanford University, USA and Universität des Saarlandes, GER
      \item Melih Karakulukcu, Karakulukcu Consulting, TR
      \item Jussi Karlgren, Gavagai, FI
      \item Marc Kemps-Snijders, Meertens Instituut, NL
      \item Ilan Kernerman, K Dictionaries, IL
      \item Christopher Kermorvant, A2iA, FR
      \item Simon King, U.~of Edinburgh, UK
      \item Philipp Koehn, U.~of Edinburgh, UK
      \item Maria Koutsombogera, ILSP, GR
      \item Steven Krauwer, U.~of Utrecht, NL
      \item Verena Krawarik, APA, AT
      \item Stefan Kreckwitz, Across, GER
      \item Simon Krek, Institut ``Jožef Stefan'', SI
      \item Brigitte Krenn, OFAI, AT
      \item Sandra Kübler, Indiana University, USA
      \item Michal Küfhaber, Skrivanek, CZ
      \item Serg Kulikov, Russian Acad.~of Sciences, RUS
      \item Jimmy Kunzmann, EML, GER
      \item Gunn Inger Lyse Samdal, U.~of Bergen, SE
      \item Bernardo Magnini, FBK, IT
      \item Gudrun Magnusdottir, ESTeam, SE
      \item Elisabeth Maier, CLS Communication, CH
      \item Joseph Mariani, CNRS/LIMSI and IMMI, FR
      \item Penny Marinou, Litterae Trans, GR
      \item Margaretha Mazura, EMF, UK/BE
      \item John McNaught, U.~of Manchester, UK
      \item Erhan Mengusoglu, Mantis, TR
      \item Wolfgang Menzel, U.~of Hamburg, GER
      \item Roger Moore, U.~of Sheffield, UK
      \item Sukumar Munshi, Across, GER
      \item Bart Noe, Jabbla, BE
      \item Torbjørn Nordgård, LINGIT AS, NO
      \item Jan Odijk, U.~of Utrecht, NL
      \item Stephan Oepen, U.~of Oslo, NO
      \item Karel Oliva, Czech Acad.~of Sciences, CZ
      \item Mehmed Özkan, Bogazici University, TR
      \item Maja Pantic, Imperial College London, UK
      \item Niko Papula, Mutilizer, FI
      \item Alexandre Passant, DERI, IE
      \item Pavel Pecina, Dublin City U./CNGL, IE
      \item Manfred Pinkal, Universität des Saarlandes, GER
      \item Stelios Piperidis, ILSP, GR
      \item László Podhorányi, Vodafone, HU
      \item Jörg Porsiel, VW, GER
      \item Gabor Proszeky, Morphologic, HU
      \item Artur Raczynski, European Patent Office, GER
      \item Jens Erik Rasmussen, Mikroverkstedet, NO
      \item Georg Rehm, DFKI, GER
      \item Steve Renals, U.~of Edinburgh, UK
      \item Peter Revsbech, Ordbogen, DK
      \item Giuseppe Riccardi, U.~of Trento, IT
      \item Daniel Ridings, Mikroverkstedet AS, LINGIT AS, NO
      \item Eirikur Rögnvaldsson, U.~of Iceland, IS
      \item Philippe Rohou, ERCIM, FR
      \item Günther Roscher, ICS Dr.~G.~Roscher GmbH, GER
      \item Johann Roturier, Symantec, IE
      \item Dimitris Sabatakakis, Systran, FR
      \item David Sadek, Institute Telecom, FR
      \item Sergi Sagàs, MediaPro, ES
      \item Felix Sasaki, W3C and DFKI, GER
      \item Jana Šatková, ACP Traductera, CZ
      \item Maneerat Sawasdiwat, Rajamangala U.~of Technology, TH
      \item David Schlangen, U.~of Bielefeld, GER
      \item Jörg Schütz, Bioloom, GER
      \item Bjørn Seljebotn, Nynodata, NO
      \item Max Silberztein, Université de Franche-Comté, FR
      \item Mirko Silvestrini, Rapidrad, IT
      \item Ruud Smeulders, Rabo Bank, NL
      \item Svetlana Sokolova, ProMT, RUS
      \item Ralf Steinberger, JRC, EC, IT
      \item Juan Manuel Soto, Fonetic, ES
      \item Lucia Specia, U.~of Sheffield, UK
      \item C.\,M.~Sperberg-McQueen, BlackMesa Technologies, USA
      \item Peter Spyns, Flemish Government, BE
      \item Maxim Stamenov, Bulgarian Acad.~of Sciences, BG
      \item Kerstin Steffen, Maravision, ES
      \item Volker Steinbiss, RWTH Aachen and Accipio, GER
      \item Rudi Studer, KIT, GER
      \item Katerina Stuparicova, Charles U.~Prague, CZ
      \item Daniel Tapias, Sigma Tech, ES
      \item Alessandro Tescari, Pervoice, IT
      \item Lori Thicke, Translators without Borders and Lexcelera, FR
      \item Gregor Thurmair, Linguatec, GER
      \item Rudy Tirry, Lionbridge, BE
      \item Attila Törcsvári, Arcanum Development, HU
      \item Diana Trandabat, U.~of A.\,I.~Cuza, RO
      \item Isabel Trancoso, INESC-ID, PT
      \item Dan Tufis, Romanian Acad., RO
      \item Hans Uszkoreit, DFKI and Universität des Saarlandes, GER
      \item Erik van der Goot, Joint Research Center, EC, IT
      \item Peggy van der Kreeft, Deutsche Welle, GER
      \item Jaap van der Meer, TAUS, NL
      \item René van Erk, Wolters Kluwer, NL
      \item Josef van Genabith, Dublin City U./CNGL, IE
      \item Arjan van Hessen, Twente U.~and Telecats, NL
      \item David van Leeuwen, TNO and Radboud University, NL
      \item Andrejs Vasiljevs, Tilde, LV
      \item Michel Vérel, VecSys, FR
      \item Kjersti Drøsdal Vikøren, Standard Norge AS, NO
      \item Bo Vincents, Ankiro, DK
      \item Claire Waast, EDF, FR
      \item Philippe Wacker, EMF, UK/BE
      \item Wolfgang Wahlster, DFKI, GER
      \item Alex Waibel, KIT, GER and CMU, Jibbigo, USA
      \item Jürgen Wedekind, U.~of Copenhagen, DK
      \item André Wlodarczyk, U.~of Charles De Gaulle, FR
      \item Feiyu Xu, DFKI, GER
      \item Annie Zaenen, U.~of Stanford, USA
      \item Jakub Zavrel, Textkernel, NL
      \item Patricia Zimmermann, SpeechConcept GmbH, GER
      \item Elie Znaty, VecSys, FR
      \item Chenqing Zong, Chinese Acad.~of Sciences, CN
    }
  \end{enumerate}
\end{footnotesize}
\end{multicols}
  
\clearpage

% ===========================================================================

\ssection[Milestones and History of the Strategic Research Agenda]{Milestones and History}
\label{vision-evolution}

\begin{small}
The META-VISION process within META-NET started in early 2010, its main aim was to produce this Strategic Research Agenda. Hundreds of representatives from academia, industry, official institutions, policy makers, politicians, journalists and the language communities have contributed to this process (see Appendix~\ref{sec:list-of-contributors}). In this section we give an overview of the meetings at which the SRA or important components on the way towards the SRA have been presented and discussed (key meetings marked in bold typeface). 
%
Important milestones in the process towards this SRA include five documents: the three Vision Reports prepared by the three domain-specific Vision Groups (see Figure~\ref{fig:towards-sra}, p.~\pageref{fig:towards-sra}), a general Vision Paper \cite{Meta1}, and a Priority Themes Paper \cite{LT2020} in which the technology visions are specified in a more concrete way. All reports, papers and discussions that took place in the process have been reflected in the Strategic Research Agenda. The documents are available online at \url{http://www.meta-net.eu/vision}.
\end{small}

\begin{footnotesize}
\begin{enumerate}
\item FLaReNet Forum, Barcelona, Spain, Feb.~11/12, 2010
\item Language Technology Days 2010, Luxembourg, March 22/23, 2010
\item EAMT 2010, Saint-Raphael, France, May 27/28, 2010
\item theMETAnk, Berlin, Germany, June 4/5, 2010
\item Translingual Europe 2010, Berlin, Germany, June 7, 2010
\item Localization World, Berlin, Germany, June 8/9, 2010
\item Multisaund Seminar, Istanbul, Turkey, June 16-18, 2010
\item \textbf{Vision Group ``Text Translation and Localisation''} (1st meeting), Berlin, Germany, July 23, 2010
\item \textbf{Vision Group ``Media and Information Services''} (1st meeting), Paris, France, Sep.~10, 2010
\item \textbf{Vision Group ``Interactive Systems''} (1st meeting), Paris, France, Sep.~10, 2010
\item ICT 2010, Brussels, Belgium, September 27-29, 2010
\item \textbf{Vision Group ``Text Translation and Localisation''} (2nd meeting), Brussels, Belgium, Sep.~29, 2010
\item \textbf{Vision Group ``Interactive Systems''} (2nd meeting), Prague, Czech Republic, Oct.~5, 2010
\item Languages and the Media 2010, Berlin, Germany, October 7, 2010
\item HLT: The Baltic Perspective, Riga, Latvia, October 7/8, 2010
\item LISA Forum Europe, Budapest, Hungary, October 13, 2010
\item \textbf{Vision Group ``Media and Information Services''} (2nd meeting), Barcelona, Spain, Oct.~15, 2010
\item EFNIL 2010, Thessaloniki, Greece, Nov.~3, 2010
\item Interact Presidential Summit, Moffett Field, USA, Nov.~8-9, 2010
\item \textbf{META Technology Council} (1st meeting), Brussels, Belgium, Nov.~16, 2010
\item Language question in research: English vs.~national languages?, Finnish Parliament, Helsinki, Nov.~17, 2010
\item \textbf{META-FORUM 2010: ``Challenges for Multilingual Europe''}, Brussels, Belgium, Nov.~17/18, 2010
\item Oriental-Cocosda 2010, Kathmandu, Nepal, Nov.~24-25, 2010
\item The International Workshop on Spoken Language Translation (IWSLT), Paris, France, Dec.~2/3, 2010
\item Meeting of the LT Berlin working group, Berlin, Germany, Dec.~9, 2010
\item Language Technology for Multilingual Applications, European Parliament, Luxembourg, Jan.~27, 2011
\item Opening of German/Austrian W3C Office at DFKI Berlin, Berlin, Germany, Feb.~10, 2011
\item Japanese Workshop for Machine Translation, Tokyo, Japan, Feb.~23, 2011
\item Meeting of Representatives of European Language Councils, Copenhagen, Denmark, March 08, 2011
\item TRALOGY, Paris, France, March 3/4, 2011
\item \textbf{Vision Group ``Interactive Systems''} (3rd meeting), Rotterdam, The Netherlands, March 28, 2011
\item \textbf{Vision Group ``Media and Information Services''} (3rd meeting), Vienna, Austria, April 1, 2011
\item Meeting of the LT Berlin working group, Berlin, Germany, April 4, 2011
\item W3C Workshop, Content on the multilingual web, Pisa, Italy, April 5, 2011
\item \textbf{Vision Group ``Translation and Localisation''} (3rd meeting), Prague, Czech Republic, April 7/8, 2011
\item Attensity Forum 2011, Berlin, Germany, May 6, 2011
\item \textbf{META Technology Council} (2nd meeting), Venice, Italy, May 25, 2011
\item FLaReNet Forum, Venice, May 26-27, 2011
\item Multisaund Seminar, Bursa, Turkey, June 13-14, 2011
\item META-NET Workshop at ICANN 2011: Context in Machine Translation,
Espoo, Finland, June 14, 2011
\item Speech Processing Conference, Tel Aviv, Israel, June 21-22, 2011
\item \textbf{META-FORUM 2011: ``Solutions for Multilingual Europe''}, Budapest, Hungary, June 27/28, 2011
\item Media for All, London, June 29-July 1, 2011
\item EUROLAN 2011 Summer School, Cluj-Napoca, Romania, Aug.~28-Sep.~4, 2011
\item Interspeech 2011, Firenze, Italy, Aug.~28-31, 2011
\item RANLP 2011, Hissar, Bulgaria, Sep.~12-14, 2011
\item Multilingual Web Workshop, Limerick, Ireland, Sep.~21/22, 2011
\item ML4HMT Workshop at MT Summit, Xiamen, China, Sep.~19-23, 2011
\item Workshop Language Technology for a Multilingual Europe at GSCL 2011, Hamburg, Germany, Sep.~27, 2011
\item GSCL 2011: Multilingual Resources and Multilingual Applications, Hamburg, Germany, Sep.~28-30, 2011
\item \textbf{META Technology Council} (3rd meeting), Berlin, Germany, Sep.~30, 2011
\item Workshop on IPR and Metadata by META-NORD, Helsinki, Finland, Sep.~30, 2011
\item META-NET Network Meeting and General Assembly, Berlin, Germany, Oct.~21/22, 2011
\item NPLD Assembly, Eskilstuna, Sweden, Oct.~25/26, 2011
\item EFNIL 2011, London, UK, Oct.~26, 2011
\item Oriental-Cocosda 2011, Hsinchu, Taiwan, Oct.~26-28, 2011
\item SIMC 2011 International Maaya Symposium on Multilingualism in the Cyberspace, Brasilia, Brasil, Nov.~7-9, 2011
\item IJCNLP 2011, Chiang Mai, Thailand, Nov.~9-13, 2011
\item ML4HMT-11 Workshop, Barcelona, Spain, Nov.~19, 2011
\item LTC 2011, Poznan, Poland, Nov.~25-27, 2011
\item GALA Conference, Monaco, March 26-29, 2012
\item EACL 2012, Avignon, France, April 23-27, 2012
\item CESAR Roadshow Event, Sofia, Bulgaria, May 2, 2012
\item LREC 2012, Istanbul, Turkey, May 21-27, 2012
\item CESAR Roadshow Event, Bratislava, Slovakia, June 7/8, 2012
\item Multilingual Web Workshop, Dublin, Ireland, June 11, 2012
\item \textbf{META Technology Council} (4th meeting), Brussels, Belgium, June 19, 2012
\item \textbf{META-FORUM 2012: ``A Strategy for Multilingual Europe''}, Brussels, Belgium, June 20/21, 2012
\item CHAT 2012 Workshop, Madrid, Spain, June 22, 2012
\item Language, Technologies and the Future of Europe, Riga, Latvia, September 21, 2012
\item Linguistic Technologies in the Research in Romania and in the Diaspora, Bucharest, Romania, September 26/27, 2012
\item CESAR Roadshow Event, Warsaw, Poland, September 27/28, 2012
\item Workshop on LT and Innovation, Oslo, Norway, October 15, 2012
\item EFNIL 2012, Budapest, Hungary, October 25/26, 2012
\item CESAR Roadshow Event, Belgrade, Serbia, October 29, 2012
\item European Languages in the Age of Technology -- quo vadis?, Vilnius, Lithuania, November 14, 2012
\item Workshop The Portuguese Language in the Digital Age, Lisbon, Portugal, November 16, 2012
\item SIMC III, Conference of the Maaya World Network for Linguistic Diversity, Paris, France, November 21-23, 2012
\item Workshop A Roadmap for the Digital Survival of Maltese, Malta, November 24, 2012
\item Translating and the Computer Conference, London, UK, November 29/30, 2012
\end{enumerate}
\end{footnotesize}

\begin{figure*}[htb]
  %\colorrule{grey3}{\textwidth}{1.5pt}
  \center
  \includegraphics[width=0.77\textwidth]{../_media/Timeline}
  \caption{The three phases of the META-VISION process}
  \label{fig:sra-timeline}
  %\colorrule{grey3}{\textwidth}{1.5pt}
\end{figure*}
 
\begin{figure*}[htb]
  %\colorrule{grey3}{\textwidth}{1.5pt}
  \center
  \includegraphics[width=0.77\textwidth]{../_media/Towards-SRA}
  \caption{Steps towards the Strategic Research Agenda for Multilingual Europe 2020}
  \label{fig:towards-sra}
  %\colorrule{grey3}{\textwidth}{1.5pt}
\end{figure*}

\clearpage

% --------------------------------------------------------------------------

\ssection[About META-NET]{About META-NET}
\label{sec:app-meta-net}

% FIXME: Comment from Serge Gladkoff.
%
% Serge möchte hier natürlich wegen GALA mehr Prominenz für Verbände. Daher einfach hier in diesem Appendix die Mitgliedsbasis von META etwas genauer erläutern und evtl. vollständig auflisten in sehr kleiner Schrift und mit ein paar wichtigen Attributen (Forschung vs. Industrie, Land etc.).
%
%%  Adding language industry to the picture: getting LSPs, Associations, Industry Bodies, initiatives involved
% Modern economy is driven forward by free market. Free market is a “boiling ocean” of commercial entities of all kinds and scale. These entities are active agents of change, and display self-organization. They form industry associations, initiatives, communities, discussions. All these structures and phenomena facilitate further development of the market. Companies work with their industries via associations. Visionary individuals launch initiatives supported by the funding from those convinced. Educational and research institutions create knowledge by teaching students and doing the research. Government bodies must facilitate this “boiling soup” where life is born.
% SRA must not only focus on technology, it should also care for the society and the industries by cooperating with industry bodies, groups and communities. Social communication about the importance of SRA is of essence. With this view in mind, the theme “social intelligence and participation” can and must be used to advance the program and the future itself, that is to be not only the goal, but also the vehicle of the Program.

% SUGGESTION:
% 1.	Amend SRA with the section “Working with the society and the industry: engaging the people who are capable to be agents of change and want to be engaged.”
% 2.	Provision space for communities, groups and Associations in future research agenda and development process. In a way it’s already happening with META Technology Council itself and LT-Innovate Program, but why don’t we make this “official”. Concrete measures, programs and plans must be thought out in order to get all those constituencies properly involved, and it is also a matter of research and trial.

\begin{multicols}{2}
  \textbf{META-NET} is a Network of Excellence partially funded by the European Commission \cite{rehm2011}.  The network currently consists of 60 members in 34 European countries. META-NET forges the Multilingual Europe Technology Alliance (\textbf{META}), a growing community of currently more than 650 language technology companies, research centres and professionals. META-NET fosters the technological foundations for a multilingual European information society that: 1.~makes communication and cooperation possible across languages; 2.~grants all Europeans equal access to information and knowledge regardless of their language; 3.~builds upon and advances functionalities of networked information technology.

The network supports a Europe that unites as a single digital market and information space. It stimulates and promotes multilingual technologies for all European languages. These technologies support automatic translation, content production, information processing and knowledge management for a wide variety of subject domains and applications. They also enable intuitive language-based interfaces to technology ranging from household electronics, machinery and vehicles to computers and robots.

Launched on 1 February 2010, META-NET is conducting various activities in its three lines of action META-VISION, META-SHARE and META-RESEARCH. In addition, META-NET cooperates with more than 40 European projects, many research organisations, companies, language communities and industry associations.

\textbf{META-VISION} fosters a dynamic and influential stakeholder community that unites around a shared vision and strategic research agenda (SRA). The main focus of this activity is to build a coherent and cohesive LT community in Europe by bringing together representatives from highly fragmented and diverse groups of stakeholders. White Papers were produced for 30 languages, each one describing the status of one language with respect to its state in the digital era and existing technological support \cite{LWP2012}. The technology vision described in this agenda was bootstrapped through three sectorial Vision Groups. 

\textbf{META-SHARE} creates an open, distributed facility for exchanging and sharing resources. The peer-to-peer network of repositories will contain language data, tools and services that are documented with metadata and organised in standardised categories. The resources can be accessed and uniformly searched. The available resources include free, open-source materials as well as restricted, commercially available, fee-based items.  

\textbf{META-RESEARCH} builds bridges to related technology fields. This activity seeks to leverage advances in other fields and to capitalise on innovative research that can benefit language technology. The action line focuses on conducting leading-edge research in machine translation, collecting data, preparing data sets and organising language resources for evaluation purposes; compiling inventories of tools and methods; and organising workshops and training events for members of the community.

\begin{center}
  \includegraphics[width=0.42\textwidth]{../_media/action-lines}  
\end{center}

\vfill
%\centerline{office@meta-net.eu -- http://www.meta-net.eu}
\textbf{\centerline{office@meta-net.eu -- http://www.meta-net.eu}}
\end{multicols}

\clearpage

% ===========================================================================

\ssection[Members of META-NET]{Members of META-NET}
\label{metanetmembers}

\small

\begin{longtable}{@{}lp{137mm}@{}}
Austria & Zentrum für Translationswissenschaft, Universität Wien: Gerhard Budin\\ \addlinespace 
Belgium & Centre for Processing Speech and Images, University of Leuven: Dirk van Compernolle \\ \addlinespace
& Computational Linguistics and Psycholinguistics Research Centre, University of Antwerp: \newline Walter Daelemans\\ \addlinespace
Bulgaria & Institute for Bulgarian Language, Bulgarian Academy of Sciences: Svetla Koeva \\ \addlinespace
Croatia & Institute of Linguistics, Faculty of Humanities and Social Science, University of Zagreb: Marko Tadić \\ \addlinespace
Cyprus & Language Centre, School of Humanities: Jack Burston \\ \addlinespace
Czech Republic & Institute of Formal and Applied Linguistics, Charles University in Prague: Jan Hajič \\ \addlinespace
Denmark & Centre for Language Technology, University of Copenhagen: Bolette Sandford Pedersen, \newline Bente Maegaard\\ \addlinespace
Estonia & Institute of Computer Science, University of Tartu: Tiit Roosmaa, Kadri Vider\\ \addlinespace
Finland & Computational Cognitive Systems Research Group, Aalto University: Timo Honkela\\ \addlinespace
& Department of Modern Languages, University of Helsinki: Kimmo Koskenniemi, Krister Lindén \\ \addlinespace
France & Centre National de la Recherche Scientifique, Laboratoire d'Informatique pour la Mécanique et les Sciences de l'Ingénieur and Institute for Multilingual and Multimedia Information: Joseph Mariani \\ \addlinespace
& Evaluations and Language Resources Distribution Agency: Khalid Choukri\\ \addlinespace
& Laboratory of Computer Science, University of Le Mans: Holger Schwenk\\ \addlinespace
& Laboratoire Informatique d'Avignon, University of Avignon: Georges Linares\\ \addlinespace
Germany & Language Technology Lab, DFKI: Hans Uszkoreit, Georg Rehm\\ \addlinespace 
& Human Language Technology and Pattern Recognition, RWTH Aachen University: Hermann Ney \\ \addlinespace 
& Department of Computational Linguistics, Saarland University: Manfred Pinkal\\ \addlinespace
& Institute for Natural Language Processing, University of Stuttgart: Jonas Kuhn, Hinrich Schütze\\ \addlinespace
& Interactive Systems Lab, Karlsruhe Institute of Technology: Alex Waibel\\ \addlinespace 
Greece & R.C. “Athena”, Institute for Language and Speech Processing: Stelios Piperidis\\ \addlinespace
Hungary & Research Institute for Linguistics, Hungarian Academy of Sciences: Tamás Váradi\\  \addlinespace
& Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics: Géza Németh, Gábor Olaszy\\ \addlinespace
Iceland & School of Humanities, University of Iceland: Eiríkur Rögnvaldsson\\ \addlinespace
Ireland & School of Computing, Dublin City University: Josef van Genabith\\ \addlinespace
Italy & Consiglio Nazionale delle Ricerche, Istituto di Linguistica Computazionale “Antonio Zampolli”: \newline Nicoletta Calzolari\\ \addlinespace
& Human Language Technology Research Unit, Fondazione Bruno Kessler:  Bernardo Magnini\\ \addlinespace 
Latvia & Tilde: Andrejs Vasiļjevs\\ \addlinespace  
& Institute of Mathematics and Computer Science, University of Latvia: Inguna Skadiņa\\ \addlinespace
Lithuania & Institute of the Lithuanian Language: Jolanta Zabarskaitė\\ \addlinespace
Luxembourg & Arax Ltd.: Vartkes Goetcherian\\ \addlinespace
Malta & Department Intelligent Computer Systems, University of Malta: Mike Rosner\\ \addlinespace
Netherlands & Utrecht Institute of Linguistics, Utrecht University: Jan Odijk\\ \addlinespace  
& Computational Linguistics, University of Groningen: Gertjan van Noord\\ \addlinespace
Norway & Department of Linguistic, Literary and Aesthetic Studies, University of Bergen: Koenraad De Smedt\\ \addlinespace  
& Department of Informatics, Language Technology Group, University of Oslo:  Stephan Oepen \\ \addlinespace
Poland & Institute of Computer Science, Polish Academy of Sciences: Adam Przepiórkowski, Maciej Ogrodniczuk \\ \addlinespace
& University of Łódź: Barbara Lewandowska-Tomaszczyk, Piotr Pęzik\\ \addlinespace
& Dept.~of Comp.~Linguistics and Artificial Intelligence, Adam Mickiewicz University: Zygmunt Vetulani \\ \addlinespace
Portugal & University of Lisbon: António Branco, Amália Mendes \\ \addlinespace 
& Spoken Language Systems Laboratory, Institute for Systems Engineering and Computers: Isabel Trancoso \\ \addlinespace
Romania & Faculty of Computer Science, University Alexandru Ioan Cuza of Iași: Dan Cristea \\ \addlinespace
& Research Institute for Artificial Intelligence, Romanian Academy of Sciences:  Dan Tufiș \\ \addlinespace
Serbia  & University of Belgrade, Faculty of Mathematics: Duško Vitas, Cvetana Krstev,  Ivan Obradović \\ \addlinespace
& Pupin Institute: Sanja Vranes \\ \addlinespace  
Slovakia & Ľudovít Štúr Institute of Linguistics, Slovak Academy of Sciences: Radovan Garabík \\ \addlinespace 
Slovenia & Jožef Stefan Institute: Marko Grobelnik \\ \addlinespace 
Spain & Barcelona Media: Toni Badia, Maite Melero \\ \addlinespace  
& Aholab Signal Processing Laboratory, University of the Basque Country:  Inma Hernaez Rioja \\ \addlinespace 
& Center for Language and Speech Technologies and Applications, Universitat Politècnica de Catalunya:  Asunción Moreno \\ \addlinespace 
& Department of Signal Processing and Communications, University of Vigo:  Carmen García Mateo \\ \addlinespace 
& Institut Universitari de Lingüística Aplicada, Universitat Pompeu Fabra: Núria Bel \\ \addlinespace 
Sweden & Department of Swedish, University of Gothenburg: Lars Borin \\ \addlinespace 
Switzerland & Idiap Research Institute: Hervé Bourlard \\ \addlinespace 
Turkey & Tübitek Bilgem: Mehmet Ugur Dogan \\ \addlinespace 
UK & School of Computer Science, University of Manchester: Sophia Ananiadou \\ \addlinespace  
& Institute for Language, Cognition and Computation, Center for Speech Technology Research, University of Edinburgh: Steve Renals \\ \addlinespace 
& Research Institute of Informatics and Language Processing, University of Wolverhampton:\newline Ruslan Mitkov \\ \addlinespace
& Department of Computer Science, University of Sheffield: Rob Gaizauskas\\ 
\end{longtable}
\normalsize

\renewcommand*{\figureformat}{}
\renewcommand*{\captionformat}{}

\begin{figure*}[h]
  \center
  \includegraphics[width=\textwidth]{../_media/meta-net_team.jpg}
  \caption{About 100 language technology experts -- representatives of the countries and languages represented in META-NET -- discussed and finalised the key results and messages of the White Paper Series at a META-NET meeting in Berlin, Germany, on October 21/22, 2011.}
  \medskip
\end{figure*}

\clearpage

% ===========================================================================

%\ssection[Members of META]{Members of META}
%\label{metamembers}

% FIXME: Include a very tightly typeset list of the 650+ META members

%\clearpage

% ===========================================================================

% \input{sra_funding_situation}

% ===========================================================================

\ssection[Abbreviations and Acroynms]{Abbreviations and Acronyms}
\label{sec:acronyms}

% Reference acronyms with \acs{AI} or \acl{AI} (acs: short form; acl: long form)

\begin{multicols}{2}
  \begin{acronym}
    \acro{AI}{Artificial Intelligence}
    \acro{API}{Application Programming Interface}
    \acro{CALL}{Computer-Assisted Language Learning}
    \acro{CAT}{Computer-Aided Translation}
    \acro{CEF}{Connecting Europe Facility} 
    \acro{CMS}{Content Management System}
    \acro{EFNIL}{European Federation of National Institutions for Language}
    \acro{ETP}{European Technology Platform}
    \acro{GALA}{Globalization and Localization Association}
    \acro{GPS}{Global Positioning System}
    \acro{HQMT}{High-Quality Machine Translation}
    \acro{HLT}{Human Language Technology}
    \acro{HTML}{Hypertext Markup Language}
    \acro{IaaS}{Infrastructures as a Service}
    \acro{IR}{Information Retrieval}
    \acro{ISO}{International Organization for Standardization}
    \acro{ICT}{Information and Communication Technology}
    \acro{IT}{Information Technology}
    \acro{JTI}{Joint Technology Initiative}
    \acro{LR}{Language Resource}    
    \acro{LSP}{Language Service Provider}    
    \acro{LT}{Language Technology}
    \acro{META}{Multilingual Europe Technology Alliance}
    \acro{ML}{Machine Learning}
    \acro{MT}{Machine Translation}
    \acro{NLP}{Natural Language Processing}
    \acro{NPLD}{Network to Promote Linguistic Diversity}
    \acro{PaaS}{Platforms as a Service}
    \acro{PHP}{PHP: Hypertext Preprocessor}
    \acro{PPP}{Public-Private Partnership}
    \acro{RSS}{RDF Site Summary; Really Simple Syndication}
    \acro{SME}{Small and Medium Enterprises}
    \acro{SaaS}{Software as a Service}
    \acro{SRA}{Strategic Research Agenda}
    \acro{TFEU}{Treaty of the Functioning of the European Union}
    \acro{TM}{Translation Memory}
    \acro{TMS}{Translation Management System}
    \acro{WWW}{World Wide Web}
    \acro{W3C}{World Wide Web Consortium}
  \end{acronym}
\end{multicols}

% ===========================================================================

\makespine

\end{document}