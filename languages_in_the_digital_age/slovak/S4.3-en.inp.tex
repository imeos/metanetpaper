Building Language Technology applications involves a range of subtasks that do not always surface at the level of interaction with the user, but provide significant service functionalities ‘under the hood’ of the system. Therefore, they constitute important research issues that have become individual sub-disciplines of Computational Linguistics in academia. 

\underbar{Question answering} has become an active area of research, for which annotated \underbar{corpora} have been built and scientific competitions have been started. The idea is to move from a keyword-based search (to which the engine responds with a whole collection of potentially relevant documents) to the scenario of the user asking a concrete question and the system providing a single answer: ‘At what age did Neil Armstrong step on the moon?’ – ’38’. While this is obviously related to the aforementioned core area Web Search, question answering nowadays is primarily an umbrella term for research questions such as what \emph{types} of questions should be distinguished and how they should be handled, how a set of documents that potentially contain the answer can be analysed and compared (do they give conflicting answers?), and how specific information – the answer – can be reliably extracted from a document, without unduly ignoring the context. 

This is in turn related to the \underbar{information extraction} (IE) task, an area that was extremely popular and influential at the time of the ‘statistical turn’ in Computational Linguistics in the early 1990s. IE aims at identifying specific pieces of information in specific classes of documents; this could be e.g. the detection of the key players in company takeovers as reported in newspaper stories. Another scenario that has been worked on is reports on terrorist incidents, where the problem is to map the text to a template specifying the perpetrator, the target, time and location of the incident and the results of the incident. Domain-specific template-filling is the central characteristic of IE, which for this reason is another example of a ‘behind the scenes’ technology that constitutes a well-demarcated research area but for practical purposes then needs to be embedded into a suitable application environment. 

The JBOWL (Java Bag-Of-Words Library) software library was developed at the Centre for Information Technologies (FEI-CIT) in Košice for the support of NLP and Text Mining applications. JBOWL is a modular system enabling the maintenance of textual documents. It provides functions and the means of supporting the processing of natural language texts (e.g., tokenization, morphological analysis, lemmatisation, disambiguation, syntactic analysis based on ATN networks, clustering and phrase identification, term weighting and indexing) as well as the knowledge discovery and mining from unstructured textual documents. In addition, the system provides implementations of several algorithms of controlled and uncontrolled machine learning with customizable input parameters and methods for evaluating the quality of Text Mining models.

\boxtext{The software library was developed at the Centre for Information Technologies in Košice to maintain textual documents}

Two ‘borderline’ areas, which sometimes play the role of a standalone application and sometimes that of a supportive, ‘under the hood’ component are \underbar{text summarisation} and \underbar{text generation}. Summarisation, obviously, refers to the task of making a long text short, and is offered for instance as a functionality within MS Word. It works largely on a statistical basis by first identifying ‘important’ words in a text (that is, for example, words that are highly frequent in this text but markedly less frequent in general language use) and then determining those sentences that contain many important words. These sentences are then marked in the document, or extracted from it, and are taken to constitute the summary. In this scenario, which is by far the most popular one, summarisation equals sentence extraction: the text is reduced to a subset of its sentences. All commercial summarisers make use of this idea. An alternative approach, to which some research is devoted, is to actually synthesise \emph{new} sentences, i.e., to build a summary of sentences that need not show up in that form in the source text. This requires a certain amount of deeper understanding of the text and therefore is much less robust. All in all, a text generator is in most cases not a stand-alone application but embedded into a larger software environment such as a clinical information system where patient data is collected, stored and processed, and report generation is just one of many functions.
